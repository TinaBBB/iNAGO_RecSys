{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\programdata\\anaconda3\\lib\\site-packages (1.21.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in c:\\programdata\\anaconda3\\lib\\site-packages (from geopy) (1.50)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask-restful\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/83/d0d33c971de2d38e54b0037136c8b8d20b9c83d308bc6c220a25162755fd/Flask_RESTful-0.3.8-py2.py3-none-any.whl\n",
      "Collecting aniso8601>=0.82\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/e4/787e104b58eadc1a710738d4e418d7e599e4e778e52cb8e5d5ef6ddd5833/aniso8601-8.0.0-py2.py3-none-any.whl (43kB)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\lib\\site-packages (from flask-restful) (2018.9)\n",
      "Requirement already satisfied: six>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask-restful) (1.12.0)\n",
      "Requirement already satisfied: Flask>=0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask-restful) (1.0.2)\n",
      "Requirement already satisfied: click>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask-restful) (7.0)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask-restful) (0.14.1)\n",
      "Requirement already satisfied: Jinja2>=2.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask-restful) (2.10)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask-restful) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=2.10->Flask>=0.8->flask-restful) (1.1.1)\n",
      "Installing collected packages: aniso8601, flask-restful\n",
      "Successfully installed aniso8601-8.0.0 flask-restful-0.3.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask-restful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyopenssl\n",
      "  Using cached https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyopenssl) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyopenssl) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=2.8->pyopenssl) (1.12.2)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl) (2.19)\n",
      "Installing collected packages: pyopenssl\n",
      "Successfully installed pyopenssl-19.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user -U pyopenssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "#from scipy import integrate\n",
    "import statistics as stats\n",
    "#import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "import scipy.sparse as sparse\n",
    "import sys\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy import distance\n",
    "from geopy import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resource allows more segreggated \n",
    "from flask import Flask, request\n",
    "from flask_restful import Resource, Api\n",
    "from sqlalchemy import create_engine\n",
    "from json import dumps\n",
    "from flask import jsonify\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewJson = \"..\\\\data\\\\Export_CleanedReview.json\"\n",
    "#reviewJsonWithClosedRes = \"..\\\\data\\\\Export_CleanedReviewWithClosedRes.json\"\n",
    "#reviewJsonToronto = \"..\\\\data\\\\Export_TorontoData.json\"\n",
    "#reviewJsonToronto = \"..\\\\data\\\\Cleaned_Toronto_Reviews.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Select top frenquent user and top frequenty restaurants that had at least 1 review >= 4 stars (Kickking out users that gave all  reviews <=3 and restaurants that never got start >= 4 stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe_csv(path, name):\n",
    "    return pd.read_csv(path+name)\n",
    "\n",
    "def load_numpy_csr(path, name):\n",
    "    return load_npz(path+name).tocsr()\n",
    "\n",
    "def load_numpy(path, name):\n",
    "    return np.load(path+name)\n",
    "\n",
    "def loadDict(path, fileName, trainOrTest='train'):\n",
    "    # json_fileName = \"{:s}.json\".format(fileName)\n",
    "    # Read data from file:\n",
    "    if(trainOrTest == 'train'):\n",
    "        dataDict = json.load(open(path+fileName))\n",
    "    else:\n",
    "        dataDict = json.load(open(path+fileName))\n",
    "    return dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_yelp_df(path = 'data/', filename = 'Export_CleanedReview.json', sampling=False, top_user_num=7000, top_item_num=5000):\n",
    "#     \"\"\"\n",
    "#     Get the pandas dataframe\n",
    "#     Sampling only the top users/items by density \n",
    "#     Implicit representation applies\n",
    "#     \"\"\"\n",
    "#     with open(filename,'r') as f:\n",
    "#         data = f.readlines()\n",
    "#         data = list(map(json.loads, data))\n",
    "    \n",
    "#     data = data[0]\n",
    "#     #Get all the data from the dggeata file\n",
    "#     df = pd.DataFrame(data)\n",
    "    \n",
    "#     df.rename(columns={'stars': 'review_stars', 'text': 'review_text', 'cool': 'review_cool',\n",
    "#                        'funny': 'review_funny', 'useful': 'review_useful'},\n",
    "#               inplace=True)\n",
    "\n",
    "#     df['business_num_id'] = df.business_id.astype('category').\\\n",
    "#         cat.rename_categories(range(0, df.business_id.nunique()))\n",
    "#     df['business_num_id'] = df['business_num_id'].astype('int')\n",
    "\n",
    "#     df['user_num_id'] = df.user_id.astype('category').\\\n",
    "#     cat.rename_categories(range(0, df.user_id.nunique()))\n",
    "#     df['user_num_id'] = df['user_num_id'].astype('int')\n",
    "\n",
    "#     df['timestamp'] = df['date'].apply(date_to_timestamp)\n",
    "\n",
    "#     if sampling:\n",
    "#         df = filter_yelp_df(df, top_user_num=top_user_num, top_item_num=top_item_num)\n",
    "#         # Refresh num id\n",
    "#         df['business_num_id'] = df.business_id.astype('category').\\\n",
    "#         cat.rename_categories(range(0, df.business_id.nunique()))\n",
    "#         df['business_num_id'] = df['business_num_id'].astype('int')\n",
    "        \n",
    "#         df['user_num_id'] = df.user_id.astype('category').\\\n",
    "#         cat.rename_categories(range(0, df.user_id.nunique()))\n",
    "#         df['user_num_id'] = df['user_num_id'].astype('int')\n",
    "# #     drop_list = ['date','review_id','review_funny','review_cool','review_useful']\n",
    "# #     df = df.drop(drop_list, axis=1)\n",
    "\n",
    "#     df = df.reset_index(drop = True)\n",
    "\n",
    "#     return df \n",
    "\n",
    "# def filter_yelp_df(df, top_user_num=7000, top_item_num=5000):\n",
    "#     #Getting the reviews where starts are above 3\n",
    "#     df_implicit = df[df['review_stars']>3]\n",
    "#     frequent_user_id = df_implicit['user_num_id'].value_counts().head(top_user_num).index.values\n",
    "#     frequent_item_id = df_implicit['business_num_id'].value_counts().head(top_item_num).index.values\n",
    "#     return df.loc[(df['user_num_id'].isin(frequent_user_id)) & (df['business_num_id'].isin(frequent_item_id))]\n",
    "\n",
    "# def date_to_timestamp(date):\n",
    "#     dt = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "#     return time.mktime(dt.timetuple())\n",
    "\n",
    "# def df_to_sparse(df, row_name='userId', col_name='movieId', value_name='rating',\n",
    "#                  shape=None):\n",
    "#     rows = df[row_name]\n",
    "#     cols = df[col_name]\n",
    "#     if value_name is not None:\n",
    "#         values = df[value_name]\n",
    "#     else:\n",
    "#         values = [1]*len(rows)\n",
    "\n",
    "#     return csr_matrix((values, (rows, cols)), shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rating-UI and timestamp-UI matrix from original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_timestamp_matrix(df, sampling=False, top_user_num=7000, top_item_num=5000):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #make the df implicit with top frenquent users and \n",
    "    #no need to sample anymore if df was sampled before \n",
    "    if sampling:\n",
    "        df = filter_yelp_df(df, top_user_num=top_user_num, top_item_num=top_item_num)\n",
    "\n",
    "    rating_matrix = df_to_sparse(df, row_name='user_num_id',\n",
    "                                 col_name='business_num_id',\n",
    "                                 value_name='review_stars',\n",
    "                                 shape=None)\n",
    "    \n",
    "    #Have same dimension and data entries with rating_matrix, except that the review stars are - user avg\n",
    "    ratingWuserAvg_matrix = df_to_sparse(df, row_name='user_num_id',\n",
    "                                 col_name='business_num_id',\n",
    "                                 value_name='reviewStars_userAvg',\n",
    "                                 shape=None)\n",
    "    \n",
    "    timestamp_matrix = df_to_sparse(df, row_name='user_num_id',\n",
    "                                    col_name='business_num_id',\n",
    "                                    value_name='timestamp',\n",
    "                                    shape=None)\n",
    "    \n",
    "    IC_matrix, IC_dictionary = get_I_C(df)\n",
    "#     ratingWuserAvg_matrix\n",
    "    return rating_matrix, timestamp_matrix, IC_matrix, IC_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_I_C(df):\n",
    "#     lst = df.categories.values.tolist()\n",
    "#     cat = []\n",
    "#     for i in range(len(lst)):\n",
    "#         if lst[i] is None:\n",
    "#             print(i)\n",
    "#         cat.extend(lst[i].split(', '))\n",
    "        \n",
    "#     unique_cat = set(cat)\n",
    "#     #     set categories id\n",
    "#     df_cat = pd.DataFrame(list(unique_cat),columns=[\"Categories\"])\n",
    "#     df_cat['cat_id'] = df_cat.Categories.astype('category').cat.rename_categories(range(0, df_cat.Categories.nunique()))\n",
    "#     dict_cat = df_cat.set_index('Categories')['cat_id'].to_dict()\n",
    "    \n",
    "#     df_I_C = pd.DataFrame(columns=['business_num_id', 'cat_id'])\n",
    "    \n",
    "#     for i in range((df['business_num_id'].unique().shape)[0]):\n",
    "#         df_temp = df[df['business_num_id'] == i].iloc[:1]\n",
    "#         temp_lst = df_temp['categories'].to_list()[0].split(\",\")\n",
    "#         for j in range(len(temp_lst)):\n",
    "#             df_I_C = df_I_C.append({'business_num_id' : i  , 'cat_id' : dict_cat[temp_lst[j].strip()]} , ignore_index=True)\n",
    "    \n",
    "#     IC_Matrix = df_to_sparse(df_I_C, row_name='business_num_id',\n",
    "#                                  col_name='cat_id',\n",
    "#                                  value_name=None,\n",
    "#                                  shape=None)    \n",
    "#     return IC_Matrix, dict_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct IC, IP, IR, ID... for Critiquing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_IP_matrix_dictionary(df,item_sim):\n",
    "#     # get an initial item price dataframe(without onehot encoding)\n",
    "#     # drop duplicates\n",
    "#     df_temp = df[['business_num_id', 'price']].drop_duplicates()\n",
    "#     # with nontype with string \"NaN\"\n",
    "#     df_temp.fillna(value = \"NaN\", inplace = True)\n",
    "    \n",
    "#     for i in tqdm(range(df_temp.shape[0])):\n",
    "#     # find all the items with no price\n",
    "#         if df_temp[df_temp['business_num_id'] == i]['price'].values[0] == \"NaN\":\n",
    "#             # get the index of the second large number in the similarity matrix\n",
    "#             temp_l = list(item_sim[i])\n",
    "#             index = [temp_l.index(x) for x in sorted(temp_l, reverse=True)[:2]][1]\n",
    "#             # get the dollar sign of the similar item\n",
    "#             dollar_of_sim_item = df_temp[df_temp['business_num_id'] == index]['price'].values[0]\n",
    "#             # replace the Nan\n",
    "#             df_temp.loc[df_temp['business_num_id'] == i,\"price\"] = dollar_of_sim_item\n",
    "\n",
    "#     # assign single dollar sign($) to the ones still with no price tag(since there is no items that are similar to this item)\n",
    "#     df_temp.loc[df_temp[\"price\"] == \"NaN\",\"price\"] = \"$\"\n",
    "\n",
    "#     # One hot encoding\n",
    "#     #note that the last column is price__$$$$\n",
    "#     #cat_columns = [\"price\"]\n",
    "#     #df_processed = pd.get_dummies(df_temp, prefix_sep=\"_\",\n",
    "#     #                          columns=cat_columns)\n",
    "    \n",
    "#     df_processed = df_temp.copy()\n",
    "#     df_processed['Price'] = df_processed.apply (lambda row: len(row.price), axis=1)\n",
    "    \n",
    "#     #drop the $ column\n",
    "#     df_processed = df_processed.drop('price', 1)\n",
    "    \n",
    "#     #Adding additional column of price label, range 1-4\n",
    "#     #df_preprocessed['Price_label'] = df.apply (lambda row: label_price(row), axis=1)\n",
    "#     df_processed.set_index(\"business_num_id\", drop=True, inplace=True)\n",
    "#     I_P_dictionary = df_processed.to_dict()['Price']\n",
    "#     df_processed.reset_index(level=0, inplace=True)\n",
    "    \n",
    "#     return df_processed, I_P_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_IS_dictionary(df):\n",
    "#     df_IS = df[['business_num_id', 'business_stars']].drop_duplicates()\n",
    "#     df_IS.set_index(\"business_num_id\", drop=True, inplace=True)\n",
    "#     IS_dictionary = df_IS.to_dict()['business_stars']\n",
    "#     df_IS.reset_index(level=0, inplace=True)\n",
    "    \n",
    "#     return IS_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a list of prediction matrix\n",
    "def get_ID_dictionary(df,prediction_matrix,intersection):\n",
    "    ID_dictionary = dict()\n",
    "    length = len(prediction_matrix)\n",
    "    \n",
    "    for j in tqdm(range(length)):\n",
    "        #Save the coordinates of the business id to a dictionary \n",
    "        coordinateDict = yaml.safe_load(df[df[\"business_num_id\"] == prediction_matrix[j]].iloc[0].coordinates)\n",
    "    \n",
    "        #Load the business latitude and longitude\n",
    "        test_point = Point(coordinateDict['latitude'],coordinateDict['longitude'])\n",
    "\n",
    "        #Get the distance with the test point, unit in km \n",
    "        result = round(distance.distance(intersection,test_point).kilometers,1)\n",
    "\n",
    "        ID_dictionary[prediction_matrix[j]] = result\n",
    "        \n",
    "    return ID_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time ordered split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def time_ordered_splitModified(rating_matrix, ratingWuserAvg_matrix, timestamp_matrix, ratio=[0.5, 0.2, 0.3],\n",
    "#                        implicit=True, remove_empty=False, threshold=3,\n",
    "#                        sampling=False, sampling_ratio=0.1, trainSampling=1):\n",
    "#     \"\"\"\n",
    "#     Split the data to train,valid,test by time\n",
    "#     ratio:  train:valid:test\n",
    "#     threshold: for implicit representation\n",
    "#     \"\"\"\n",
    "    \n",
    "    \n",
    "#     if implicit:\n",
    "#         temp_rating_matrix = sparse.csr_matrix(rating_matrix.shape)\n",
    "#         temp_rating_matrix[(rating_matrix > threshold).nonzero()] = 1\n",
    "#         rating_matrix = temp_rating_matrix\n",
    "#         timestamp_matrix = timestamp_matrix.multiply(rating_matrix)\n",
    "#         #ratingWuserAvg_matrix = ratingWuserAvg_matrix.multiply(rating_matrix)\n",
    "\n",
    "#     nonzero_index = None\n",
    "\n",
    "#     #Default false, not removing empty columns and rows\n",
    "#     #Should not have this case, since users should have at least 1 record of 4,5 \n",
    "#     #And restuarant should have at least 1 record of 4,5 \n",
    "#     if remove_empty:\n",
    "#         # Remove empty columns. record original item index\n",
    "#         nonzero_index = np.unique(rating_matrix.nonzero()[1])\n",
    "#         rating_matrix = rating_matrix[:, nonzero_index]\n",
    "#         timestamp_matrix = timestamp_matrix[:, nonzero_index]\n",
    "#         ratingWuserAvg_matrix = ratingWuserAvg_matrix[:, nonzero_index]\n",
    "\n",
    "#         # Remove empty rows. record original user index\n",
    "#         nonzero_rows = np.unique(rating_matrix.nonzero()[0])\n",
    "#         rating_matrix = rating_matrix[nonzero_rows]\n",
    "#         timestamp_matrix = timestamp_matrix[nonzero_rows]\n",
    "#         ratingWuserAvg_matrix = ratingWuserAvg_matrix[nonzero_rows]\n",
    "\n",
    "#     user_num, item_num = rating_matrix.shape\n",
    "\n",
    "#     rtrain = []\n",
    "#     rtrain_userAvg = []\n",
    "#     rtime = []\n",
    "#     rvalid = []\n",
    "#     rvalid_userAvg = []\n",
    "#     rtest = []\n",
    "#     rtest_userAvg = []\n",
    "#     # Get the index list corresponding to item for train,valid,test\n",
    "#     item_idx_train = []\n",
    "#     item_idx_valid = []\n",
    "#     item_idx_test = []\n",
    "    \n",
    "#     for i in tqdm(range(user_num)):\n",
    "#         #Get the non_zero indexs, restuarants where the user visited/liked if implicit \n",
    "#         item_indexes = rating_matrix[i].nonzero()[1]        \n",
    "#         #Get the data for the user\n",
    "#         data = rating_matrix[i].data      \n",
    "#         #Get time stamp value \n",
    "#         timestamp = timestamp_matrix[i].data \n",
    "#         #Get review stars with user avg data \n",
    "#         if implicit == False:\n",
    "#             dataWuserAvg = ratingWuserAvg_matrix[i].data\n",
    "\n",
    "            \n",
    "#         #Non zero reviews for this user\n",
    "#         num_nonzeros = len(item_indexes)\n",
    "        \n",
    "#         #If the user has at least one review\n",
    "#         if num_nonzeros >= 1:\n",
    "#             num_test = int(num_nonzeros * ratio[2])\n",
    "#             num_valid = int(num_nonzeros * (ratio[1] + ratio[2]))\n",
    "#             valid_offset = num_nonzeros - num_valid\n",
    "            \n",
    "#             # Adding this for sampling for training set\n",
    "#             valid_offsetSample = int(valid_offset*trainSampling)\n",
    "#             test_offset = num_nonzeros - num_test\n",
    "            \n",
    "#             #Sort the timestamp for each review for the user\n",
    "#             argsort = np.argsort(timestamp)\n",
    "            \n",
    "#             #Sort the reviews for the user according to the time stamp \n",
    "#             data = data[argsort]\n",
    "            \n",
    "#             #Sort the review with user avg accoridng to the time stamp\n",
    "#             if implicit == False:\n",
    "#                 dataWuserAvg = dataWuserAvg[argsort]\n",
    "            \n",
    "#             #Non-zero review index sort according to time\n",
    "#             item_indexes = item_indexes[argsort]\n",
    "            \n",
    "#             #list of ratings, num of valid_offset index, index where there's non-zeros\n",
    "#             #if take from old to new\n",
    "#             #rtrain.append([data[:valid_offsetSample], np.full(valid_offsetSample, i), item_indexes[:valid_offsetSample]])\n",
    "#             #if take from new to old\n",
    "#             rtrain.append([data[valid_offset-valid_offsetSample:valid_offset], np.full(valid_offsetSample, i), item_indexes[valid_offset-valid_offsetSample:valid_offset]])\n",
    "#             rvalid.append([data[valid_offset:test_offset], np.full(test_offset - valid_offset, i),\n",
    "#                            item_indexes[valid_offset:test_offset]])\n",
    "#             rtest.append([data[test_offset:], np.full(num_test, i), item_indexes[test_offset:]])\n",
    "            \n",
    "#             if implicit == False:\n",
    "#                 #Now for the rating matrix that considers user average rating\n",
    "#                 #list of ratings, num of valid_offset index, index where there's non-zeros\n",
    "#                 #from old to new\n",
    "#                 #rtrain_userAvg.append([dataWuserAvg[:valid_offsetSample], np.full(valid_offsetSample, i), item_indexes[:valid_offsetSample]])\n",
    "#                 #take nearest\n",
    "#                 rtrain_userAvg.append([dataWuserAvg[valid_offset-valid_offsetSample:valid_offset], np.full(valid_offsetSample, i), item_indexes[valid_offset-valid_offsetSample:valid_offset]])                \n",
    "                    \n",
    "#                 rvalid_userAvg.append([dataWuserAvg[valid_offset:test_offset], np.full(test_offset - valid_offset, i),\n",
    "#                                item_indexes[valid_offset:test_offset]])\n",
    "                \n",
    "#                 rtest_userAvg.append([dataWuserAvg[test_offset:], np.full(num_test, i), item_indexes[test_offset:]])\n",
    "                \n",
    "#             item_idx_train.append(item_indexes[:valid_offsetSample])\n",
    "#             item_idx_valid.append(item_indexes[:test_offset])\n",
    "#             item_idx_test.append(item_indexes[test_offset:])\n",
    "            \n",
    "#         else:\n",
    "#             item_idx_train.append([])\n",
    "    \n",
    "#     rtrain = np.array(rtrain)\n",
    "#     rvalid = np.array(rvalid)\n",
    "#     rtest = np.array(rtest)\n",
    "   \n",
    "#     if implicit == False:\n",
    "#         rtrain_userAvg = np.array(rtrain_userAvg)\n",
    "#         rvalid_userAvg = np.array(rvalid_userAvg)\n",
    "#         rtest_userAvg = np.array(rtest_userAvg)\n",
    "\n",
    "#     #take non-zeros values, row index, and column (non-zero) index and store into sparse matrix\n",
    "#     rtrain = sparse.csr_matrix((np.hstack(rtrain[:, 0]), (np.hstack(rtrain[:, 1]), np.hstack(rtrain[:, 2]))),\n",
    "#                                shape=rating_matrix.shape, dtype=np.float32)\n",
    "#     rvalid = sparse.csr_matrix((np.hstack(rvalid[:, 0]), (np.hstack(rvalid[:, 1]), np.hstack(rvalid[:, 2]))),\n",
    "#                                shape=rating_matrix.shape, dtype=np.float32)\n",
    "#     rtest = sparse.csr_matrix((np.hstack(rtest[:, 0]), (np.hstack(rtest[:, 1]), np.hstack(rtest[:, 2]))),\n",
    "#                               shape=rating_matrix.shape, dtype=np.float32)\n",
    "    \n",
    "#     if implicit == False:\n",
    "#         rtrain_userAvg = sparse.csr_matrix((np.hstack(rtrain_userAvg[:, 0]), (np.hstack(rtrain_userAvg[:, 1]), np.hstack(rtrain_userAvg[:, 2]))),\n",
    "#                                    shape=rating_matrix.shape, dtype=np.float32)\n",
    "#         rvalid_userAvg = sparse.csr_matrix((np.hstack(rvalid_userAvg[:, 0]), (np.hstack(rvalid_userAvg[:, 1]), np.hstack(rvalid_userAvg[:, 2]))),\n",
    "#                                    shape=rating_matrix.shape, dtype=np.float32)\n",
    "#         rtest_userAvg = sparse.csr_matrix((np.hstack(rtest_userAvg[:, 0]), (np.hstack(rtest_userAvg[:, 1]), np.hstack(rtest_userAvg[:, 2]))),\n",
    "#                                   shape=rating_matrix.shape, dtype=np.float32)\n",
    "\n",
    "#     return rtrain, rvalid, rtest,rtrain_userAvg, rvalid_userAvg, rtest_userAvg, nonzero_index, timestamp_matrix, item_idx_train, item_idx_valid, item_idx_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_three_popularity_matrix(df_original,rtrain):\n",
    "    # get the list of popular items by ranking the number of reviews\n",
    "    numUsers = rtrain.shape[0]\n",
    "    numItems = rtrain.shape[1]\n",
    "    \n",
    "    dff_popular = df_original.copy()\n",
    "    dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "    popular_list_num_of_reviews = dff_popular[\"business_num_id\"].tolist()\n",
    "    \n",
    "    # get the list of popular items by ranking average rating score\n",
    "    dff_popular_rating = df_original.copy()\n",
    "    dff_popular_rating = dff_popular_rating.sort_values(by=[\"business_stars\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "    popular_list_avg_stars = dff_popular_rating[\"business_num_id\"].tolist()\n",
    "    \n",
    "    lst_temp = []\n",
    "    for item in tqdm(range(numItems)):\n",
    "        numOfUsersRated = len(rtrain.toarray()[:, item].nonzero()[0])\n",
    "        if numOfUsersRated <= 50:\n",
    "            lst_temp.append(item)\n",
    "    popular_list_avg_stars = [x for x in popular_list_avg_stars if x not in lst_temp]\n",
    "    \n",
    "    # get the popularity items by using the percentage liked method(number of liked items / total items)\n",
    "    predictionMatrix = np.zeros((numUsers , numItems))\n",
    "\n",
    "    # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "    vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "    rtrain_array = rtrain.toarray()\n",
    "    # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "    itemPopularity = np.zeros((numItems))\n",
    "    for item in range(numItems):\n",
    "        numOfUsersRated = len(rtrain_array[:, item].nonzero()[0])\n",
    "        numOfUsersLiked = len(vf(rtrain_array[:, item]).nonzero()[0])\n",
    "#         if numOfUsersRated == 0:\n",
    "        # set a threshold to filter out restaurants with very few reviews\n",
    "        if numOfUsersRated <= 30:\n",
    "            itemPopularity[item] = 0\n",
    "        else:\n",
    "            itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "    popular_list_liked_ratio = itemPopularity.argsort()\n",
    "    \n",
    "    return np.asarray(popular_list_num_of_reviews),np.asarray(popular_list_avg_stars),popular_list_liked_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get df for training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Item idex matrix stores the reivews starts\n",
    "#This function returns a list of index for the reviews included in training set \n",
    "def get_corpus_idx_list(df, item_idx_matrix):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    df: total dataframe\n",
    "    item_idx_matrix: train index list got from time_split \n",
    "    Output: row index in original dataframe for training data by time split\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    #For all the users: 5791\n",
    "    for i in tqdm(range(len(item_idx_matrix))):\n",
    "        \n",
    "        #find row index where user_num_id is i\n",
    "        a = df.index[df['user_num_id'] == i].tolist()\n",
    "        \n",
    "        #loop through the busienss id that the user i reviewed for in offvalid set \n",
    "        for item_idx in  item_idx_matrix[i]:\n",
    "            \n",
    "            #get the row index for reviews for business that the user liked in the train set\n",
    "            b = df.index[df['business_num_id'] == item_idx].tolist()\n",
    "            \n",
    "            #Find the index for which this user liked, one user only rate a business once\n",
    "            idx_to_add = list(set(a).intersection(b))\n",
    "            \n",
    "            if idx_to_add not in lst:\n",
    "                lst.extend(idx_to_add)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess using Term Frequency - CounterVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shenti10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shenti10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Stemming and Lemmatisation\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# Get corpus and CountVector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_words = ['not_the']\n",
    "stop_words = stop_words.union(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#Should 'because' added?\n",
    "def preprocess(df, reset_list = [',','.','?',';','however','but']):\n",
    "    corpus = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        text = df['review_text'][i]\n",
    "        change_flg = 0\n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        ##Convert to list from string, loop through the review text\n",
    "        text = text.split()\n",
    "        \n",
    "        #any sentence that encounters a not, the folloing words will become not phrase until hit the sentence end\n",
    "        for j in range(len(text)):\n",
    "            #Make the not_ hack\n",
    "            if text[j] == 'not':\n",
    "                change_flg = 1\n",
    "#                 print 'changes is made after ', i\n",
    "                continue\n",
    "            #if was 1 was round and not hit a 'not' in this round\n",
    "            if change_flg == 1 and any(reset in text[j] for reset in reset_list):\n",
    "                text[j] = 'not_' + text[j]\n",
    "                change_flg = 0\n",
    "#                 print 'reset at ', i\n",
    "            if change_flg == 1:\n",
    "                text[j] = 'not_' + text[j]\n",
    "        \n",
    "        #Convert back to string\n",
    "        text = \" \".join(text)\n",
    "        \n",
    "        #Remove punctuations\n",
    "#       text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        \n",
    "        #remove tags\n",
    "        text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "        \n",
    "        # remove special characters and digits\n",
    "        text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "        \n",
    "        ##Convert to list from string\n",
    "        text = text.split()\n",
    "        \n",
    "        ##Stemming\n",
    "        ps=PorterStemmer()\n",
    "        \n",
    "        #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in  \n",
    "                stop_words] \n",
    "        text = \" \".join(text)\n",
    "        corpus.append(text)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def train(matrix_train):\n",
    "    similarity = cosine_similarity(X=matrix_train, Y=None, dense_output=True)\n",
    "    return similarity\n",
    "\n",
    "def get_I_K(df, X, row_name = 'business_num_id', binary = True, shape = (121994,6000)):\n",
    "    \"\"\"\n",
    "    get the item-keyphrase matrix\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    #For each review history\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        #Get the array of frequencies for document/review i \n",
    "        arr = X[i].toarray() \n",
    "        nonzero_element = arr.nonzero()[1]  # Get nonzero element in each line, keyphrase that appears index \n",
    "        length_of_nonzero = len(nonzero_element) #number of important keyphrase that appears\n",
    "        \n",
    "        # df[row_name][i] is the item idex\n",
    "        #Get a list row index that indicates the document/review\n",
    "        rows.extend(np.array([df[row_name][i]]*length_of_nonzero)) ## Item index\n",
    "        #print(rows)\n",
    "        \n",
    "        #Get a list of column index indicating the key phrase that appears in i document/review\n",
    "        cols.extend(nonzero_element) ## Keyword Index\n",
    "        if binary:\n",
    "            #Create a bunch of 1s\n",
    "            vals.extend(np.array([1]*length_of_nonzero))\n",
    "        else:\n",
    "            #If not binary \n",
    "            vals.extend(arr[arr.nonzero()])    \n",
    "    return csr_matrix((vals, (rows, cols)), shape=shape)\n",
    "\n",
    "\n",
    "#Get a UI matrix if it's not item_similarity based or else IU\n",
    "def predict(matrix_train, k, similarity, item_similarity_en = False):\n",
    "    prediction_scores = []\n",
    "    \n",
    "    #inverse to IU matrix\n",
    "    if item_similarity_en:\n",
    "        matrix_train = matrix_train.transpose()\n",
    "        \n",
    "    #for each user or item, depends UI or IU \n",
    "    for user_index in tqdm(range(matrix_train.shape[0])):\n",
    "        # Get user u's prediction scores for all items\n",
    "        #Get prediction/similarity score for each user 1*num or user or num of items\n",
    "        vector_u = similarity[user_index]\n",
    "\n",
    "        # Get closest K neighbors excluding user u self\n",
    "        #Decending accoding to similarity score, select top k\n",
    "        similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "        \n",
    "        # Get neighbors similarity weights and ratings\n",
    "        similar_users_weights = similarity[user_index][similar_users]\n",
    "        \n",
    "        #similar_users_weights_sum = np.sum(similar_users_weights)\n",
    "        #print(similar_users_weights.shape)\n",
    "        #shape: num of res * k\n",
    "        similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "              \n",
    "        prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "        #print(prediction_scores_u)\n",
    "        \n",
    "        \n",
    "        prediction_scores.append(np.sum(prediction_scores_u, axis=0))\n",
    "        \n",
    "    res = np.array(prediction_scores)\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        res = res.transpose()\n",
    "    return res\n",
    "\n",
    "\n",
    "#Preidction score is UI or IU?\n",
    "def prediction(prediction_score, topK, matrix_Train):\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    #for each user\n",
    "    for user_index in tqdm(range(matrix_Train.shape[0])):\n",
    "        \n",
    "        #take the prediction scores for user 1 * num res\n",
    "        vector_u = prediction_score[user_index]\n",
    "        \n",
    "        #The restuarant the user rated\n",
    "        vector_train = matrix_Train[user_index]\n",
    "        \n",
    "        if len(vector_train.nonzero()[0]) > 0:\n",
    "            vector_predict = sub_routine(vector_u, vector_train, topK=topK)\n",
    "        else:\n",
    "            vector_predict = np.zeros(topK, dtype=np.float32)\n",
    "\n",
    "        prediction.append(vector_predict)\n",
    "\n",
    "    return np.vstack(prediction)\n",
    "\n",
    "def prediction_modified(prediction_score, matrix_Train, user_id, topK = 50):\n",
    "    prediction = []\n",
    "\n",
    "    #for each user\n",
    "    for user_index in tqdm(range(matrix_Train.shape[0])):\n",
    "        \n",
    "        #take the prediction scores for user 1 * num res\n",
    "        vector_u = prediction_score[user_index]\n",
    "        \n",
    "        #The restuarant the user rated\n",
    "        vector_train = matrix_Train[user_index]\n",
    "        \n",
    "        if len(vector_train.nonzero()[0]) > 0:\n",
    "            vector_predict = sub_routine_modified(vector_u, vector_train)\n",
    "        else:\n",
    "            vector_predict = np.zeros(topK, dtype=np.float32)\n",
    "\n",
    "        prediction.append(vector_predict)\n",
    "\n",
    "    return prediction[user_id]\n",
    "\n",
    "#topK: the number of restuarants we are suggesting \n",
    "#if vector_train has number, then the user has visited\n",
    "def sub_routine(vector_u, vector_train, topK=500):\n",
    "\n",
    "    #index where non-zero\n",
    "    train_index = vector_train.nonzero()[1]\n",
    "    \n",
    "    vector_u = vector_u\n",
    "    \n",
    "    #get topk + num rated res prediction score descending, top index \n",
    "    candidate_index = np.argpartition(-vector_u, topK+len(train_index))[:topK+len(train_index)]\n",
    "    \n",
    "    #sort top prediction score index in range topK+len(train_index) into vector_u`\n",
    "    vector_u = candidate_index[vector_u[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "    #deleted the rated res from the topk+train_index prediction score vector for user u \n",
    "    #Delete the user rated res index from the topk+numRated index\n",
    "    vector_u = np.delete(vector_u, np.isin(vector_u, train_index).nonzero()[0])\n",
    "\n",
    "    #so we only include the top K prediction score here\n",
    "    return vector_u[:topK]\n",
    "\n",
    "def sub_routine_modified(vector_u, vector_train):\n",
    "\n",
    "    #index where non-zero\n",
    "    train_index = vector_train.nonzero()[1]\n",
    "    \n",
    "    vector_u = vector_u\n",
    "    \n",
    "    #get topk + num rated res prediction score descending, top index \n",
    "    candidate_index = np.argpartition(-vector_u, -1)\n",
    "    \n",
    "    #sort top prediction score index in range topK+len(train_index) into vector_u`\n",
    "    vector_u = candidate_index[vector_u[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "    #deleted the rated res from the topk+train_index prediction score vector for user u \n",
    "    #Delete the user rated res index from the topk+numRated index\n",
    "    vector_u = np.delete(vector_u, np.isin(vector_u, train_index).nonzero()[0])\n",
    "\n",
    "    #so we only include the top K prediction score here\n",
    "    return vector_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recallk(vector_true_dense, hits, **unused):\n",
    "#     hits = len(hits.nonzero()[0])\n",
    "#     return float(hits)/len(vector_true_dense)\n",
    "\n",
    "\n",
    "# def precisionk(vector_predict, hits, **unused):\n",
    "#     hits = len(hits.nonzero()[0])\n",
    "#     return float(hits)/len(vector_predict)\n",
    "\n",
    "\n",
    "# def average_precisionk(vector_predict, hits, **unused):\n",
    "#     precisions = np.cumsum(hits, dtype=np.float32)/range(1, len(vector_predict)+1)\n",
    "#     return np.mean(precisions)\n",
    "\n",
    "\n",
    "# def r_precision(vector_true_dense, vector_predict, **unused):\n",
    "#     vector_predict_short = vector_predict[:len(vector_true_dense)]\n",
    "#     hits = len(np.isin(vector_predict_short, vector_true_dense).nonzero()[0])\n",
    "#     return float(hits)/len(vector_true_dense)\n",
    "\n",
    "\n",
    "# def _dcg_support(size):\n",
    "#     arr = np.arange(1, size+1)+1\n",
    "#     return 1./np.log2(arr)\n",
    "\n",
    "\n",
    "# def ndcg(vector_true_dense, vector_predict, hits):\n",
    "#     idcg = np.sum(_dcg_support(len(vector_true_dense)))\n",
    "#     dcg_base = _dcg_support(len(vector_predict))\n",
    "#     dcg_base[np.logical_not(hits)] = 0\n",
    "#     dcg = np.sum(dcg_base)\n",
    "#     return dcg/idcg\n",
    "\n",
    "\n",
    "# def click(hits, **unused):\n",
    "#     first_hit = next((i for i, x in enumerate(hits) if x), None)\n",
    "#     if first_hit is None:\n",
    "#         return 5\n",
    "#     else:\n",
    "#         return first_hit/10\n",
    "\n",
    "\n",
    "# def evaluate(matrix_Predict, matrix_Test, metric_names =['R-Precision', 'NDCG', 'Precision', 'Recall', 'MAP'], atK = [5, 10, 15, 20, 50], analytical=False):\n",
    "#     \"\"\"\n",
    "#     :param matrix_U: Latent representations of users, for LRecs it is RQ, for ALSs it is U\n",
    "#     :param matrix_V: Latent representations of items, for LRecs it is Q, for ALSs it is V\n",
    "#     :param matrix_Train: Rating matrix for training, features.\n",
    "#     :param matrix_Test: Rating matrix for evaluation, true labels.\n",
    "#     :param k: Top K retrieval\n",
    "#     :param metric_names: Evaluation metrics\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     global_metrics = {\n",
    "#         #\"R-Precision\": r_precision,\n",
    "#         #\"NDCG\": ndcg,\n",
    "#         #\"Clicks\": click\n",
    "#     }\n",
    "\n",
    "#     local_metrics = {\n",
    "#         #\"Precision\": precisionk,\n",
    "#         #\"Recall\": recallk,\n",
    "#         \"MAP\": average_precisionk\n",
    "#     }\n",
    "\n",
    "#     output = dict()\n",
    "\n",
    "#     num_users = matrix_Predict.shape[0]\n",
    "\n",
    "#     for k in atK:\n",
    "\n",
    "#         local_metric_names = list(set(metric_names).intersection(local_metrics.keys()))\n",
    "#         results = {name: [] for name in local_metric_names}\n",
    "#         topK_Predict = matrix_Predict[:, :k]\n",
    "\n",
    "#         for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "#             vector_predict = topK_Predict[user_index]\n",
    "#             if len(vector_predict.nonzero()[0]) > 0:\n",
    "#                 vector_true = matrix_Test[user_index]\n",
    "#                 vector_true_dense = vector_true.nonzero()[1]\n",
    "#                 hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "#                 if vector_true_dense.size > 0:\n",
    "#                     for name in local_metric_names:\n",
    "#                         results[name].append(local_metrics[name](vector_true_dense=vector_true_dense,\n",
    "#                                                                  vector_predict=vector_predict,\n",
    "#                                                                  hits=hits))\n",
    "#         results_summary = dict()\n",
    "#         if analytical:\n",
    "#             for name in local_metric_names:\n",
    "#                 results_summary['{0}@{1}'.format(name, k)] = round(results[name],4)\n",
    "#         else:\n",
    "#             for name in local_metric_names:\n",
    "#                 results_summary['{0}@{1}'.format(name, k)] = (round((np.average(results[name])),4),\n",
    "#                                                               round((1.96*np.std(results[name])/np.sqrt(num_users)),4))\n",
    "#         output.update(results_summary)\n",
    "\n",
    "#     global_metric_names = list(set(metric_names).intersection(global_metrics.keys()))\n",
    "#     results = {name: [] for name in global_metric_names}\n",
    "\n",
    "#     topK_Predict = matrix_Predict[:]\n",
    "\n",
    "#     for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "#         vector_predict = topK_Predict[user_index]\n",
    "\n",
    "#         if len(vector_predict.nonzero()[0]) > 0:\n",
    "#             vector_true = matrix_Test[user_index]\n",
    "#             vector_true_dense = vector_true.nonzero()[1]\n",
    "#             hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "#             # if user_index == 1:\n",
    "#             #     import ipdb;\n",
    "#             #     ipdb.set_trace()\n",
    "\n",
    "#             if vector_true_dense.size > 0:\n",
    "#                 for name in global_metric_names:\n",
    "#                     results[name].append(global_metrics[name](vector_true_dense=vector_true_dense,\n",
    "#                                                               vector_predict=vector_predict,\n",
    "#                                                               hits=hits))\n",
    "#     results_summary = dict()\n",
    "#     if analytical:\n",
    "#         for name in global_metric_names:\n",
    "#             results_summary[name] = round(results[name],4)\n",
    "#     else:\n",
    "#         for name in global_metric_names:\n",
    "#             results_summary[name] = (round(np.average(results[name]),4), round((1.96*np.std(results[name])/np.sqrt(num_users)),4))\n",
    "#     output.update(results_summary)\n",
    "\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass in a vector of predicted restaurant for this specific user\n",
    "#We specify the index of the recommended restaurant we want to display \n",
    "def displayRestaurantInfo(RecommendItem_Index, user_item_predictionMatrix,df,ID_dictionary):\n",
    "    #RecommendItem_Index: 0,1,2,3.. changes as user critiques the restaurant itself\n",
    "    print('------------------------------------------------------')\n",
    "    recommend_item = user_item_predictionMatrix[RecommendItem_Index]\n",
    "    print('Business_num_id: ', recommend_item)\n",
    "    print('Restaurant name:', df[df['business_num_id'] == recommend_item].name.unique()[0],\\\n",
    "      '\\nCuisine Type: ', df[df['business_num_id'] == recommend_item].categories.unique()[0],\\\n",
    "      '\\nPrice:', df[df['business_num_id'] == recommend_item].price.unique()[0],\\\n",
    "      '\\nRating:', df[df['business_num_id'] == recommend_item].business_stars.unique()[0],\\\n",
    "      '\\nDistance:', ID_dictionary[recommend_item], 'km'\n",
    "     )\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load original dataframe out of the review datastet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be replaced\n",
    "#df = get_yelp_df(path ='', filename=reviewJsonToronto, sampling= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"..\\\\data\\\\\"\n",
    "df = load_dataframe_csv(data_dir, \"Dataframe.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rating-UI matrix and timestepm-UI matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'reviewStars_userAvg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'reviewStars_userAvg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-442579418248>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrating_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamp_matrix\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mI_C_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIC_dictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_rating_timestamp_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# get ratingWuserAvg_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# rating_array = rating_matrix.toarray()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# user_average_array = rating_array.sum(axis = 1)/np.count_nonzero(rating_array,axis = 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-a30962594942>\u001b[0m in \u001b[0;36mget_rating_timestamp_matrix\u001b[1;34m(df, sampling, top_user_num, top_item_num)\u001b[0m\n\u001b[0;32m     16\u001b[0m                                  \u001b[0mcol_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'business_num_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                  \u001b[0mvalue_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'reviewStars_userAvg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                                  shape=None)\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     timestamp_matrix = df_to_sparse(df, row_name='user_num_id',\n",
      "\u001b[1;32m<ipython-input-36-aa1e4e1724b0>\u001b[0m in \u001b[0;36mdf_to_sparse\u001b[1;34m(df, row_name, col_name, value_name, shape)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalue_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'reviewStars_userAvg'"
     ]
    }
   ],
   "source": [
    "#rating_matrix, timestamp_matrix , I_C_matrix, IC_dictionary = get_rating_timestamp_matrix(df)\n",
    "\n",
    "# get ratingWuserAvg_matrix\n",
    "# rating_array = rating_matrix.toarray()\n",
    "# user_average_array = rating_array.sum(axis = 1)/np.count_nonzero(rating_array,axis = 1)\n",
    "# init_UI = np.zeros(rating_array.shape)\n",
    "# init_UI[rating_array.nonzero()] = 1\n",
    "\n",
    "#Creating rating with user average array array\n",
    "# for i in range(user_average_array.shape[0]):\n",
    "#     init_UI[i] = init_UI[i] * (user_average_array[i]-0.001) \n",
    "# user_average_array = init_UI\n",
    "# ratingWuserAvg_array = rating_array - user_average_array\n",
    "# ratingWuserAvg_matrix=sparse.csr_matrix(ratingWuserAvg_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC_dictionary = loadDict(data_dir, \"icDictionary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to get rtrain-UI matrix and valid and test.. item_index_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  del sys.path[0]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7000/7000 [00:01<00:00, 4944.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# rtrain_implicit, rvalid_implicit, rtest_implicit, rtrain_userAvg_implicit, rvalid_userAvg_implicit, rtest_userAvg_implicit, nonzero_index, rtime, item_idx_matrix_train_implicit,item_idx_matrix_valid_implicit, item_idx_matrix_test_implicit = time_ordered_splitModified(rating_matrix=rating_matrix, ratingWuserAvg_matrix=ratingWuserAvg_matrix, timestamp_matrix=timestamp_matrix,\n",
    "#                                                                      ratio=[0.5,0.2,0.3],\n",
    "#                                                                      implicit=True,\n",
    "#                                                                      remove_empty=False, threshold=3,sampling=False, \n",
    "#                                                                      sampling_ratio=0.1, trainSampling=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7000/7000 [00:01<00:00, 3920.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# rtrain, rvalid, rtest, rtrain_userAvg, rvalid_userAvg, rtest_userAvg, nonzero_index, rtime, item_idx_matrix_train,item_idx_matrix_valid, item_idx_matrix_test = time_ordered_splitModified(rating_matrix=rating_matrix, ratingWuserAvg_matrix=ratingWuserAvg_matrix, timestamp_matrix=timestamp_matrix,\n",
    "#                                                                      ratio=[0.5,0.2,0.3],\n",
    "#                                                                      implicit=False,\n",
    "#                                                                      remove_empty=False, threshold=3,\n",
    "#                                                                      sampling=False, sampling_ratio=0.1, \n",
    "#                                                                      trainSampling=0.95)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load rtrain as entire UI rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rtrain = rtrain + rvalid + rtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rtrain_implicit = rtrain_implicit + rvalid_implicit + rtest_implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7000x4996 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 196784 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrain= load_numpy_csr(data_dir, \"rtrain.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34972000\n"
     ]
    }
   ],
   "source": [
    "#print((rtrain_Load == rtrain).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TD-IDF to compute corpus and X (business vs. terms) TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 205968/205968 [01:12<00:00, 2829.57it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary to store business: review text\n",
    "dict_text = {}\n",
    "for i in range(len(corpus)):\n",
    "    if df['business_num_id'][i] not in dict_text:\n",
    "        dict_text[df['business_num_id'][i]] = corpus[i]\n",
    "    else:\n",
    "        temp = dict_text[df['business_num_id'][i]]\n",
    "        temp = temp + corpus[i]\n",
    "        dict_text[df['business_num_id'][i]] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list for the review text, where the row dimension = total business ids\n",
    "list_text = []\n",
    "for key in range(0,max(list(dict_text.keys()))+1) :\n",
    "    if key not in dict_text.keys():\n",
    "        list_text.extend([\"\"])\n",
    "    else:\n",
    "        list_text.extend([dict_text[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the X vector, where dimension is #business vs #terms like IK\n",
    "vectorizer = TfidfVectorizer(max_df=0.9,stop_words=stop_words, max_features=5000, ngram_range=(1,1))\n",
    "X_cleaned = vectorizer.fit_transform(list_text).toarray()\n",
    "X_cleaned_sparse = csr_matrix(X_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check keywords\n",
    "#print(vectorizer.get_feature_names())\n",
    "#keywordList = X_cleaned_sparse[50].nonzero()[1]\n",
    "#for word in keywordList:\n",
    "#    print(vectorizer.get_feature_names()[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing in the trained similarity matrx\n",
    "def individualKNNPrediction (similarityMatrix, predictionMatrix, kRange, validOrTestMatrix, itemBased=False):\n",
    "    \"Declaration for kRange = range(50,120,10)\"\n",
    "    #similarity = train(similarityMatrix)\n",
    "    MAP10 = {}\n",
    "    #Loop through the kvalues \n",
    "    for kValue in kRange:\n",
    "        if(itemBased==False):\n",
    "            user_item_p\n",
    "            rediction_score = predict(predictionMatrix, kValue, similarityMatrix, item_similarity_en= False)\n",
    "        else:\n",
    "            user_item_prediction_score = predict(predictionMatrix, kValue, similarityMatrix, item_similarity_en= True)\n",
    "        user_item_predict = prediction(user_item_prediction_score, 50, predictionMatrix)\n",
    "        user_item_res = evaluate(user_item_predict, validOrTestMatrix)\n",
    "        \n",
    "        \n",
    "        MAP10[kValue] = user_item_res.get('MAP@10')\n",
    "        \n",
    "    return MAP10\n",
    "\n",
    "def get_UC_Matrix(IC_Matrix,rtrain_implicit):\n",
    "    U_C_matrix_explicit = rtrain_implicit*IC_Matrix\n",
    "    U_C_matrix_implicit = getImplicitMatrix(U_C_matrix_explicit,3)\n",
    "    return U_C_matrix_explicit,U_C_matrix_implicit\n",
    "\n",
    "def getImplicitMatrix(sparseMatrix, threashold=0):\n",
    "    temp_matrix = sparse.csr_matrix(sparseMatrix.shape)\n",
    "    temp_matrix[(sparseMatrix > threashold).nonzero()] = 1\n",
    "    return temp_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing in the trained similarity matrx\n",
    "def KNNPrediction (similarityMatrix, predictionMatrix, kValue, validOrTestMatrix, itemBased=False):\n",
    "\n",
    "    if(itemBased==False):\n",
    "        user_item_prediction_score = predict(predictionMatrix, kValue, similarityMatrix, item_similarity_en= False)\n",
    "    else:\n",
    "        user_item_prediction_score = predict(predictionMatrix, kValue, similarityMatrix, item_similarity_en= True)\n",
    "    user_item_predict = prediction(user_item_prediction_score, 50, predictionMatrix)\n",
    "    user_item_res = evaluate(user_item_predict, validOrTestMatrix)\n",
    "\n",
    "        \n",
    "    return user_item_res.get('MAP@10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saveDictToJson(dictionary, fileName, trainOrTest='train'):\n",
    "#     json_fileName = \"{:s}.json\".format(fileName)\n",
    "#     if(trainOrTest == 'train'):\n",
    "#         json.dump(dictionary, open(\"crossValidation\\\\trainPerformance\\\\\"+json_fileName, 'w') )\n",
    "#     else:\n",
    "#         json.dump(dictionary, open(\"crossValidation\\\\testPerformance\\\\\"+json_fileName, 'w') )\n",
    "    \n",
    "\n",
    "# def loadDict(fileName, trainOrTest='train'):\n",
    "#     json_fileName = \"{:s}.json\".format(fileName)\n",
    "#     # Read data from file:\n",
    "#     if(trainOrTest == 'train'):\n",
    "#         dataDict = json.load( open(\"crossValidation\\\\trainPerformance\\\\\"+json_fileName))\n",
    "#     else:\n",
    "#         dataDict = json.load( open(\"crossValidation\\\\testPerformance\\\\\"+json_fileName))\n",
    "#     return dataDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item based recommend & critique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intersections\n",
    "yonge_and_finch = Point(\"43.779824, -79.415665\")\n",
    "bloor_and_bathurst = Point(\"43.665194,-79.411208\")\n",
    "queen_and_spadina = Point(\"43.648772,-79.396259\")\n",
    "bloor_and_yonge = Point(\"43.670409,-79.386814\")\n",
    "dundas_and_yonge = Point(\"43.6561,-79.3802\")\n",
    "spadina_and_dundas = Point(\"43.653004,-79.398082\")\n",
    "\n",
    "#Set intersection for test case:\n",
    "intersection = spadina_and_dundas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "IK_similarity = load_numpy(data_dir, 'IKbased_II_similarity.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IK TF-IDF\n",
    "#IK_MATRIX = X_cleaned_sparse\n",
    "#IK_similarity_original = train(IK_MATRIX)\n",
    "#IC_similarity = train(I_C_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4996/4996 [00:06<00:00, 745.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#Get IP dictionary\n",
    "#IP_df is the dataframe, IP_dictionary maps business_num_id with price range from 1-4\n",
    "#IP_df, IP_dictionary = get_IP_matrix_dictionary(df, IK_similarity)\n",
    "#IS_dictionary = get_IS_dictionary(df)\n",
    "ID_dictionary = get_ID_dictionary(df,list(set(df['business_num_id'])),intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load IS_dictionary, IP_dictionary, IK_similarity, I_C_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_dictionary = loadDict(data_dir, \"isDictionary.json\")\n",
    "IS_dictionary = {int(old_key): val for old_key, val in IS_dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_dictionary = loadDict(data_dir, \"ipDictionary.json\")\n",
    "IP_dictionary = {int(old_key): val for old_key, val in IP_dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_dictionary_load = loadDict(data_dir, \"idDictionary_spadinadundas.json\")\n",
    "ID_dictionary_load = {int(old_key): val for old_key, val in ID_dictionary_load.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_dictionary_load == ID_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "I_C_matrix = load_numpy_csr(data_dir, \"icmatrix.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4996/4996 [00:25<00:00, 193.29it/s]\n"
     ]
    }
   ],
   "source": [
    "user_item_prediction_score = predict(rtrain, 110, IK_similarity, item_similarity_en= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import explanation data and store it in the df_explanation file\n",
    "TorontoExplanation = \"..\\\\data\\\\Toronto_explanation.json\"\n",
    "with open(TorontoExplanation,'r') as f:\n",
    "    data = f.readlines()\n",
    "    data = list(map(json.loads, data))\n",
    "data = data[0]\n",
    "#Get all the data from the dggeata file\n",
    "df_explanation = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if item and categories are matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checkIfExhaustedList (current_user_item_predict, original_user_item_predict, critique_Res_list):\n",
    "#     message = ''\n",
    "#     if len(current_user_item_predict) == 0:\n",
    "#         print('Exhausted the recommendation list, fall back to initial preference')\n",
    "#         current_user_item_predict = [item for item in original_user_item_predict if item not in critique_Res_list]\n",
    "#         message = 'exhausted critiquing list, fall back'\n",
    "#     return current_user_item_predict, message\n",
    "\n",
    "def updateList (listTobeUpdated, listUsedToUpdate):\n",
    "    tempList = listTobeUpdated.copy()\n",
    "    tempList.append(listUsedToUpdate)\n",
    "    listUpdate = list(set(tempList))\n",
    "    \n",
    "    return listUpdate\n",
    "\n",
    "def exhaustFallBack(tempRecommendList):\n",
    "    ifExhaust = False\n",
    "    print(critiqueDictionary['critiqued_Res_AccrdName_list'])\n",
    "    #Exhausted recommendation list\n",
    "    if(len(tempRecommendList) == 0):\n",
    "        ifExhaust = True\n",
    "        print('Exhausted recommendation list, no matching restaurant after current critique')\n",
    "        \n",
    "        #update critiqued restaurant list according to name\n",
    "        #critiqueDictionary['critiqued_Res_AccrdName_list'] = updateList(critiqueDictionary['critiqued_Res_AccrdName_list'], \\\n",
    "        #                                                                critiqueDictionary['current_user_item_predict'][recommendIndex])\n",
    "        #Update critiqued restaurant total set\n",
    "        critiqueDictionary['current_user_item_predict'] = critiqueDictionary['current_user_item_predict'][recommendIndex+1 :]\n",
    "    print(critiqueDictionary['critiqued_Res_AccrdName_list'])\n",
    "    \n",
    "    return ifExhaust\n",
    "\n",
    "def updateExtendList (listTobeUpdated, listUsedToUpdate):\n",
    "    tempList = listTobeUpdated.copy()\n",
    "    tempList.extend(listUsedToUpdate)\n",
    "    listUpdate = list(set(tempList))\n",
    "    \n",
    "    return listUpdate\n",
    "\n",
    "#This method should generate a dictionary for the recommended item, to be used for API \n",
    "def constructRestaurantDict(RecommendItem_Index, user_item_predictionMatrix,df,ID_dictionary, additionalText='', empty=False):\n",
    "    restaurantInfo = {}\n",
    "    if empty:\n",
    "        restaurantInfo['business_id'] = \"empty\"\n",
    "        restaurantInfo['name'] = \"empty\"\n",
    "        restaurantInfo['cuisine'] = \"empty\"\n",
    "        restaurantInfo['price'] = \"empty\"\n",
    "        restaurantInfo['rating'] = \"empty\"\n",
    "        restaurantInfo['distance'] = \"empty\"\n",
    "        #Additional text sent back from the system \n",
    "        restaurantInfo['addText'] = \"empty\"\n",
    "    else:\n",
    "        businessId = user_item_predictionMatrix[RecommendItem_Index]\n",
    "        #print(businessId)\n",
    "        retrieveDF = df[df['business_num_id'] == businessId]\n",
    "        restaurantInfo['business_id'] = str(businessId)\n",
    "        restaurantInfo['name'] = str(retrieveDF.name.unique()[0])\n",
    "        restaurantInfo['cuisine'] = str(retrieveDF.categories.unique()[0])\n",
    "        restaurantInfo['price'] = str(retrieveDF.price.unique()[0])\n",
    "        restaurantInfo['rating'] = str(retrieveDF.business_stars.unique()[0])\n",
    "        restaurantInfo['distance'] = str(ID_dictionary[businessId]) + 'km'\n",
    "        #Additional text sent back from the system \n",
    "        restaurantInfo['addText'] = additionalText\n",
    "        \n",
    "        explanation_dict = df_explanation[df_explanation[\"business_id\"] == str(retrieveDF.business_id.unique()[0])].explanation.values[0]\n",
    "        exp_list = []\n",
    "        explanation_str = ''\n",
    "        for (k,v) in explanation_dict.items():\n",
    "            explanation_str+=v\n",
    "            exp_list.append(v)\n",
    "        explanation_str = exp_list[0] + \", \" + exp_list[1] + \" and \"+ exp_list[2]\n",
    "\n",
    "        restaurantInfo['explanation'] = explanation_str\n",
    "    \n",
    "    return restaurantInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter test user index: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7000/7000 [00:04<00:00, 1748.09it/s]\n"
     ]
    }
   ],
   "source": [
    "#Initialize\n",
    "testUser_index = int(input(\"Enter test user index: \"))\n",
    "#Get user item initial prediction vector \n",
    "test_user_item_predict = prediction_modified(user_item_prediction_score, rtrain, testUser_index)\n",
    "\n",
    "categoryList = list(IC_dictionary.keys())\n",
    "categoryList[:15]\n",
    "\n",
    "maxDistance = max(ID_dictionary, key=ID_dictionary.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter critique res list and critique res according to name if fall back to square one \n",
    "def fallBackSetup(critique_Res_list=[], critiqued_Res_AccrdName_list=[], critiqueDistance=2.0):\n",
    "    critique_distance = critiqueDistance\n",
    "    wanted_Category_index = -1\n",
    "    variableDictionary['critique_distance'] = critique_distance\n",
    "    variableDictionary['wanted_Category_index'] = wanted_Category_index\n",
    "    \n",
    "    #initialize critique dictionary \n",
    "    for listName in critiqueDictionary.keys():\n",
    "        critiqueDictionary[listName] = []\n",
    "        \n",
    "    critiqueDictionary['critique_Res_list'] = [key for (key, value) in ID_dictionary.items() if value > critique_distance].extend(critique_Res_list) \n",
    "    critiqueDictionary['critiqued_Res_AccrdName_list'] = critiqued_Res_AccrdName_list\n",
    "    critiqueDictionary['critiqued_Res_AccrdDistance_list'] = [key for (key, value) in ID_dictionary.items() if value > critique_distance]\n",
    "    critiqueDictionary['current_user_item_predict'] = [item for item in test_user_item_predict if item not in critique_Res_list]\n",
    "    \n",
    "    #Construct recommend business json, insert into dictionary\n",
    "    recBusinessJson = constructRestaurantDict(recommendIndex, current_user_item_predict,df,ID_dictionary)\n",
    "    print(recBusinessJson)\n",
    "    recommendResDict['recBusinessJson'] = recBusinessJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOST UP TO DATE ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business_id': '4501', 'name': 'Lai Wah Heen', 'cuisine': 'Dim Sum', 'price': '$$$', 'rating': '3.5', 'distance': '1.0km', 'addText': '', 'explanation': 'best chicken dim-sum dumpling, good excellent service and many excellent fine chinese restaurant'}\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5002/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Feb/2020 19:42:08] \"GET /business HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: {'feature': 'price', 'positiveOrNegative': 'positive', 'critiqueValue': 'cheaper'}\n",
      "4501\n",
      "3\n",
      "Critiqing price at range: ['$$$', '$$$$']\n",
      "[4501]\n",
      "[4501]\n",
      "Saving critiqued items at index:  [3458, 204, 4083, 417, 989] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Feb/2020 19:42:16] \"PUT /business HTTP/1.1\" 201 -\n"
     ]
    }
   ],
   "source": [
    "#Directly using global variables is fine, but you can only modify dictionary variables\n",
    "\n",
    "app = Flask(__name__)\n",
    "#Add resources to be much cleaner\n",
    "api = Api(app)\n",
    "\n",
    "#Initialize variable \n",
    "\n",
    "#Need to initialize to have only restaurants within 2.0km recommended, restaurants distance above 2.0 will be critiqued\n",
    "critique_distance = 2.0\n",
    "\n",
    "#list of restaurant don't wanted, initialized as restaurants distance <2.0km\n",
    "critique_Res_list = [key for (key, value) in ID_dictionary.items() if value > critique_distance] \n",
    "critique_Price_list = []\n",
    "ciritiqued_Rating_list = []\n",
    "#list of categories don't wanted - Accumulated \n",
    "critique_Cat_list = []\n",
    "\n",
    "#Used to fall back, when user inputs are conflicted, modified during the critiquing process\n",
    "critiqued_Res_AccrdName_list= []\n",
    "critiqued_Res_AccrdCuisine_list = []\n",
    "critiqued_Res_AccrdPrice_list = []\n",
    "critiqued_Res_AccrdStar_list = []\n",
    "critiqued_Res_AccrdDistance_list = [key for (key, value) in ID_dictionary.items() if value > critique_distance] \n",
    "\n",
    "#Categories that explicitly wanted, ONLY 1 FOR NOW\n",
    "wanted_Category_index = -1\n",
    "\n",
    "#Recommendation info\n",
    "recommendIndex = 0  \n",
    "\n",
    "#Initial user item vector for critiquing process \n",
    "current_user_item_predict = [item for item in test_user_item_predict if item not in critique_Res_list]\n",
    "\n",
    "#Construct initial recommendation\n",
    "recBusinessJson = constructRestaurantDict(recommendIndex, current_user_item_predict,df,ID_dictionary)\n",
    "print(recBusinessJson)\n",
    "\n",
    "#Following dictionaries are for retrieval \n",
    "\n",
    "#Construct constant variables dictionary\n",
    "variableDictionary = {\n",
    "    'critique_distance' : critique_distance,\n",
    "    'wanted_Category_index': wanted_Category_index\n",
    "    \n",
    "}\n",
    "\n",
    "#A dictionary that stores all the lists related with the critiquing process\n",
    "critiqueDictionary = {\n",
    "    'critique_Res_list': critique_Res_list,\n",
    "    'critique_Price_list':critique_Price_list,\n",
    "    'critique_Cat_list': critique_Cat_list,\n",
    "    'ciritiqued_Rating_list':ciritiqued_Rating_list,\n",
    "    'critiqued_Res_AccrdStar_list': critiqued_Res_AccrdStar_list,\n",
    "    'critiqued_Res_AccrdCuisine_list':critiqued_Res_AccrdCuisine_list,\n",
    "    'critiqued_Res_AccrdPrice_list':critiqued_Res_AccrdPrice_list,\n",
    "    'critiqued_Res_AccrdName_list': critiqued_Res_AccrdName_list,\n",
    "    'critiqued_Res_AccrdDistance_list':critiqued_Res_AccrdDistance_list,\n",
    "    'test_user_item_predict': test_user_item_predict,\n",
    "    'current_user_item_predict': current_user_item_predict\n",
    "    }\n",
    "\n",
    "#Storing the current recommended restaurant\n",
    "recommendResDict = {\n",
    "        'recBusinessJson': recBusinessJson\n",
    "}\n",
    "\n",
    "\n",
    "class Business(Resource):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.critique_Price_list = []\n",
    "        self.countVar = 0\n",
    "    \n",
    "    def get(self):\n",
    "        #return {'business name': data[0]['name']} # Fetches first column that is Employee ID\n",
    "        return recommendResDict['recBusinessJson']\n",
    "    \n",
    "    def post(self):\n",
    "        some_json  = request.get_json()\n",
    "        #put json object for the critiquing process \n",
    "        #Return newly computed object \n",
    "        return {'You sent': some_json}, 201\n",
    "    def put(self):\n",
    "        #Get the request json\n",
    "        request_json  = request.get_json()\n",
    "        print('Input data:', request_json)\n",
    "        \n",
    "        #put json object for the critiquing process \n",
    "        critique_feature = request_json.get('feature', 'none')\n",
    "        critique_posNeg = request_json.get('positiveOrNegative', 'none')\n",
    "        critique_value = request_json.get('critiqueValue', 'none')\n",
    "        if isinstance(critique_value, list):\n",
    "            critique_value = critique_value[0]\n",
    "        \n",
    "        #Error Handling - Shouldn't trigger if json format passed in properly \n",
    "        if critique_feature == 'none':\n",
    "            print('Critique Feature cannot be recognized')\n",
    "        if critique_posNeg == 'none':\n",
    "            print('Critique positive or negative category cannot be recognized')\n",
    "        \n",
    "        #Once user send this request, critique current item \n",
    "        #tempCritiqueRestList = critiqueDictionary['critique_Res_list'].copy()\n",
    "        #tempCritiqueRestList.append(critiqueDictionary['current_user_item_predict'][recommendIndex])\n",
    "        \n",
    "        #Put back into the dictionary \n",
    "        critiqueDictionary['critique_Res_list'].append(critiqueDictionary['current_user_item_predict'][recommendIndex])\n",
    "        critiqueDictionary['critiqued_Res_AccrdName_list'].append(critiqueDictionary['current_user_item_predict'][recommendIndex])\n",
    "        \n",
    "            \n",
    "        #initialize additional text to be passed back\n",
    "        additionalText = ''\n",
    "        #temporary updated recommendation list\n",
    "        tempRecommendList = []\n",
    "        #Scenario 1 - Critique Restaurant name \n",
    "        if 'name' in critique_feature:\n",
    "            \n",
    "            print(\"Saving critiqued item: \", critiqueDictionary['current_user_item_predict'][recommendIndex])      \n",
    "            additionalText = \"Saving critiqued item: \" + str(critiqueDictionary['current_user_item_predict'][recommendIndex])\n",
    "            \n",
    "            #update critiqued restaurant list according to name\n",
    "            #critiqueDictionary['critiqued_Res_AccrdName_list'] = updateList(critiqueDictionary['critiqued_Res_AccrdName_list'], \\\n",
    "            #                                                 critiqueDictionary['current_user_item_predict'][recommendIndex])\n",
    "            #Update critiqued restaurant total set\n",
    "            critiqueDictionary['current_user_item_predict'] = critiqueDictionary['current_user_item_predict'][recommendIndex+1 :]\n",
    "            \n",
    "            \n",
    "        #Scenario 2 - Negatively critique restaurant features \n",
    "        if ('cuisine' in critique_feature) and ('negative' in critique_posNeg):\n",
    "            \n",
    "            #Get current recommended restaurant cuisine type\n",
    "            currentCuisineType = recommendResDict['recBusinessJson']['cuisine'].split(',')\n",
    "            \n",
    "            #Find the correct category name the user want to critique in current recommended item categories\n",
    "            critiqueValue = [cuisine for cuisine in currentCuisineType if critique_value.strip().lower() in cuisine.lower()][0]\n",
    "            \n",
    "            #Retrieve critiquing category index\n",
    "            critiquied_Cat_Index = IC_dictionary[critiqueValue]\n",
    "            print('Saving negatively critiqued cuisine type:', critique_value, ', cuisine index: ', critiquied_Cat_Index)\n",
    "\n",
    "            #Save the newly critiqued cuisine type\n",
    "            critiqueDictionary['critique_Cat_list'] = critiqueDictionary['critique_Cat_list'].append(critiquied_Cat_Index)\n",
    "            \n",
    "            #Handling extreme case - critique categories previously requested \n",
    "            if critiquied_Cat_Index == variableDictionary['wanted_Category_index']:\n",
    "                #Reset wanted category index\n",
    "                variableDictionary['wanted_Category_index'] = -1\n",
    "                print('You are critiquing a cuisine type you previously requested\\n Fall back to initial preference')\n",
    "                additionalText = additionalText + '.You are critiquing a cuisine type you previously requested\\n Fall back to initial preference'\n",
    "                \n",
    "                #Restting the prediction list -.-? \n",
    "                critiqueDictionary['current_user_item_predict'] = \\\n",
    "                                        [item for item in critiqueDictionary['test_user_item_predict'] if \\\n",
    "                                         item not in critique_Res_list]\n",
    "\n",
    "            #Find list of restaurants to filter out \n",
    "            critiquedItemsList = list(I_C_matrix.getcol(critiquied_Cat_Index).nonzero()[0])\n",
    "            \n",
    "            #Updating the critiqued items to list\n",
    "            print('Saving critiqued items at index: ', critiquedItemsList[:5], '...')\n",
    "            templist = critiqueDictionary['critique_Res_list'].copy()\n",
    "            templist.extend(list(critiquedItemsList))\n",
    "            \n",
    "            #temporary updated recommend list \n",
    "            tempRecommendList = [item for item in critiqueDictionary['current_user_item_predict']\\\n",
    "                                          if item not in templist]\n",
    "            \n",
    "            #Check if exhausted list, if so clear out all restaurants \n",
    "            if exhaustFallBack(tempRecommendList):\n",
    "                additionalText = additionalText +'| Exhausted recommendation list, falling back to initial preference'\n",
    "                print('--FALLING BACK TO INITIAL PREFERENCE--')\n",
    "                fallBackSetup(critique_Res_list=critiqueDictionary['critique_Res_list'], \\\n",
    "                              critiqued_Res_AccrdName_list=critiqueDictionary['critiqued_Res_AccrdName_list'], \\\n",
    "                              critiqueDistance=2.0)\n",
    "            else:\n",
    "                #Update critique restaurant list \n",
    "                critiqueDictionary['critique_Res_list'] = list(set(templist))\n",
    "\n",
    "                #Update the list of restaurants critiqued by cuisin type\n",
    "                templist = critiqueDictionary.get('critiqued_Res_AccrdCuisine_list',[]).copy()\n",
    "                templist.extend(critiquedItemsList)\n",
    "                critiqueDictionary['critiqued_Res_AccrdCuisine_list'] = list(set(templist))\n",
    "\n",
    "                #Filter out critiqued items, sequence must remain the same, update current valid set \n",
    "                critiqueDictionary['current_user_item_predict'] = tempRecommendList.copy()\n",
    "\n",
    "            #Handle case where run out of items! - Fall Back!\n",
    "            #critiqueDictionary['current_user_item_predict'], message = checkIfExhaustedList(critiqueDictionary['current_user_item_predict'], \\\n",
    "            #                                                                       critiqueDictionary['test_user_item_predict'], \\\n",
    "            #                                                                       critiqueDictionary['critique_Res_list'])\n",
    "            #additionalText = additionalText + '. ' + message\n",
    "        \n",
    "        #Scenario 3 - Positively critique restaurant cuisine type \n",
    "        if 'cuisine' in critique_feature and 'positive' in critique_posNeg:\n",
    "            #Find the correct category within all the categories list - assuming exact word typed in \n",
    "            \"\"\"Add ERROR HANDLING HERE\"\"\"\n",
    "            positiveCritiquiCategory = [cuisine for cuisine in categoryList if \\\n",
    "                                        critique_value.strip().lower() in cuisine.lower()][0]\n",
    "\n",
    "            #Retrieve cuisine type index, 1 number  \n",
    "            positiveCritiquiedIndex = IC_dictionary[positiveCritiquiCategory]\n",
    "\n",
    "            #Get the preferred category index, replace existing ones\n",
    "            variableDictionary['wanted_Category_index'] = positiveCritiquiedIndex\n",
    "\n",
    "            #Retrieve items/restaurants matching item category \n",
    "            matchedResList = list(I_C_matrix.getcol(positiveCritiquiedIndex).nonzero()[0])\n",
    "            print('matching list:', matchedResList[:10])\n",
    "            \n",
    "            #additionalText = 'positive critique cuisine type' + str(positiveCritiquiCategory) + 'id:' + str(positiveCritiquiedIndex)\\\n",
    "            #                    +'critiquing business: ' +str(matchedResList[:5]) + '...'\n",
    "\n",
    "            #Check if user have previously critiqued - remove it \n",
    "            if critiqueDictionary['critique_Cat_list'] is not None and\\\n",
    "                (positiveCritiquiedIndex in critiqueDictionary['critique_Cat_list']):\n",
    "                templist = critiqueDictionary['critique_Cat_list']\n",
    "                templist.remove(positiveCritiquiedIndex)\n",
    "                critiqueDictionary['critique_Cat_list'] = templist\n",
    "\n",
    "                #Update critiqued restaurant list according to cuisine type \n",
    "                templist = critiqueDictionary['critiqued_Res_AccrdCuisine_list']\n",
    "                templist.remove(matchedResList)\n",
    "                critiqueDictionary['critiqued_Res_AccrdCuisine_list'] = templist\n",
    "\n",
    "                #UPDATE CRITIQUE RESTAURANT LIST \n",
    "                #In the matched restuarnt list and not critiqued under other criteria will be withdrawn from this list\n",
    "                critiqueDictionary['critique_Res_list'] = [item for item in critiqueDictionary['test_user_item_predict']\\\n",
    "                                                           if item not in matchedResList or \\\n",
    "                                    item in list(set(critiqueDictionary['critiqued_Res_AccrdName_list']+ \\\n",
    "                                                     critiqueDictionary['critiqued_Res_AccrdCuisine_list']+\\\n",
    "                                                     critiqueDictionary['critiqued_Res_AccrdStar_list']+ \\\n",
    "                                                     critiqueDictionary['critiqued_Res_AccrdDistance_list']))]\n",
    "            \n",
    "            tempRecommendList = [item for item in matchedResList if item not in critiqueDictionary['critique_Res_list']]\n",
    "            \n",
    "            #Check if exhausted recommendation list \n",
    "            if exhaustFallBack(tempRecommendList):\n",
    "                additionalText = additionalText +'| Exhausted recommendation list, no matching restaurant after current critique, discarding current critique'\n",
    "            else:    \n",
    "                #Update current valid set, make sure not in critiqued restaurant set \n",
    "                critiqueDictionary['current_user_item_predict'] = tempRecommendList.copy()\n",
    "            \n",
    "        #Scenario 4 - Negative critique restuarant price e.g. \"I don't want expensive restaurants\" OR positive \"I want cheaper\"\n",
    "        #Scenario 5 - Positively critique restaurant price, \"I want fine dining\", wanting more expensive restaurant \n",
    "        if 'price' in critique_feature:\n",
    "            \n",
    "            #Get current price label range in 1 - 4\n",
    "            currentPriceLabel = IP_dictionary[critiqueDictionary['current_user_item_predict'][recommendIndex]]\n",
    "            \n",
    "            #Get critique_price_list first\n",
    "            templist = critiqueDictionary.get('critique_Price_list', []).copy()\n",
    "            \n",
    "            #Update critiqued price list\n",
    "            if 'positive' in critique_posNeg and critique_value == 'more expensive':\n",
    "                templist.extend([price for price in range(1,currentPriceLabel+1,1)])\n",
    "                \n",
    "            #Negative or positive, cheaper     \n",
    "            else:     \n",
    "                templist.extend([price for price in range(currentPriceLabel,5,1)])\n",
    "            \n",
    "            #update critiqued_price_list by puting it back to the dictionary\n",
    "            critiqueDictionary['critique_Price_list'] = list(set(templist))\n",
    "\n",
    "            #Check if critiqued all price range, if exhausted, fall back \n",
    "            if len(critiqueDictionary['critique_Price_list']) == 4:\n",
    "                print('You have exhaused the price range option, showing the most', critique_value, 'option')\n",
    "                #Send feedback to front end\n",
    "                additionalText = 'You have exhaused the price range option, showing the most '+ critique_value + ' option'\n",
    "                \n",
    "                #Clear the previous critiqued restuarants based on price out of critiqued restuarant list \n",
    "                #POTENTIAL ISSUE HERE, MAY BE ERASING SOME RESTAURANTS CRITIQUED IN OTHER STEPS ... NEED TO RECHECK\n",
    "                critiqueDictionary['critique_Res_list'] = [item for item in critiqueDictionary['test_user_item_predict'] if\\\n",
    "                                    item in list(set(critiqueDictionary['critiqued_Res_AccrdName_list'] + \\\n",
    "                                                     critiqueDictionary['critiqued_Res_AccrdCuisine_list']+\\\n",
    "                                                     critiqueDictionary['critiqued_Res_AccrdStar_list'] + \\\n",
    "                                                     critiqueDictionary['critiqued_Res_AccrdDistance_list']))]\n",
    "\n",
    "                #Clear out the restuarants critiquied by price \n",
    "                critiqueDictionary['critiqued_Res_AccrdPrice_list'] = []\n",
    "\n",
    "                #Restore default critiquing price list \n",
    "                if critique_value == 'more expensive':\n",
    "                    critiqueDictionary['critique_Price_list'] = [1,2,3]\n",
    "                else:\n",
    "                    critiqueDictionary['critique_Price_list'] = [2,3,4]  \n",
    "                    \n",
    "            #printing and sending message to front end, the critiquing price range\n",
    "            print('Critiqing price at range:', ['$'*label for label in critiqueDictionary['critique_Price_list'] ])\n",
    "            #additionalText += 'Critiqing price at range:'+str(['$'*label for label in critiqueDictionary['critique_Price_list']])\n",
    "            \n",
    "            #Find the list of restaurants to critique \n",
    "            listCritiqueRestaurant = [key for (key, value) in IP_dictionary.items() if \\\n",
    "                                       value in critiqueDictionary['critique_Price_list']]\n",
    "            \n",
    "            #find temporary updated critique list    \n",
    "            tempCritiqueList = updateExtendList(critiqueDictionary['critique_Res_list'], listCritiqueRestaurant)\n",
    "            \n",
    "            tempRecommendList = [item for item in critiqueDictionary['current_user_item_predict']\\\n",
    "                                                               if item not in tempCritiqueList]\n",
    "            \n",
    "            #CHECK IF EXHAUSTED, if so clear out all restaurants \n",
    "            if exhaustFallBack(tempRecommendList):\n",
    "                additionalText = additionalText +'| Exhausted recommendation list, no matching restaurant after current critique, discarding current critique'\n",
    "            \n",
    "            else:\n",
    "                #Update the critiqued restaurant list\n",
    "                critiqueDictionary['critique_Res_list'] = tempCritiqueList.copy()\n",
    "\n",
    "                #Record the list of restaurants critiqued so far based on price \n",
    "                critiqueDictionary['critiqued_Res_AccrdPrice_list'] = updateExtendList(critiqueDictionary['critiqued_Res_AccrdPrice_list'], \\\n",
    "                                                           listCritiqueRestaurant)\n",
    "                \n",
    "                #Updating the critiqued items to list\n",
    "                print('Saving critiqued items at index: ', listCritiqueRestaurant[:5], '...')\n",
    "\n",
    "                ##Update current valid set , filter out critiqued items, sequence must remain the same\n",
    "                critiqueDictionary['current_user_item_predict'] = [item for item in critiqueDictionary['current_user_item_predict']\\\n",
    "                                                                   if item not in tempCritiqueList]\n",
    "            \n",
    "        #Scenario 6 negatively critique rating & positively critique rating: both goes up \n",
    "        #\"I don't want ratings this low?\" \"I don't want restuarants with rating below XXX\" \"I want restaurants with rating above XXX\"\n",
    "        #I will critique the ratings below the current rating or specific rating \n",
    "        if 'rating' in critique_feature:\n",
    "            currentRating = float(recommendResDict['recBusinessJson']['rating'])\n",
    "            \n",
    "            if critique_value.lower() == 'current_rating':\n",
    "                critique_value = currentRating\n",
    "        \n",
    "            #Critiquing the restaurants that has ratings equal and below this restaurant \n",
    "            critiqueRes = [rating/10 for rating in range(0,int(float(critique_value)*10)+1,5)]\n",
    "            critiqueDictionary['ciritiqued_Rating_list'] = updateExtendList(critiqueDictionary['ciritiqued_Rating_list'], \\\n",
    "                                                                           critiqueRes)\n",
    "            #If critiqued all price\n",
    "            if critiqueDictionary['ciritiqued_Rating_list'] == [price/10 for price in range(0,51,5)]:\n",
    "                print('exhausted list, no better restaurants, recommending the finest restaurants')\n",
    "                additionalText += '| Exhausted list, no better restaurants, recommending restaurants beyond current rating'\n",
    "\n",
    "                #reset critiqued restaurant list \n",
    "                critiqueDictionary['critique_Res_list'] = [item for item in critiqueDictionary['test_user_item_predict'] if\\\n",
    "                                    item in list(set(critiqueDictionary['critiqued_Res_AccrdName_list']+\\\n",
    "                                                     critiqueDictionary['critiqued_Res_AccrdCuisine_list']+\\\n",
    "                                                     critiqueDictionary['critiqued_Res_AccrdPrice_list']+\\\n",
    "                                                     critiqueDictionary['critiqued_Res_AccrdDistance_list']))] \n",
    "\n",
    "                #Clear out the restuarants critiquied by rating \n",
    "                critiqueDictionary['critiqued_Res_AccrdStar_list'] = []\n",
    "                critiqueDictionary['ciritiqued_Rating_list'] = [rating/10 for rating in range(0,int(currentRating*10+1),5)]\n",
    "\n",
    "            print('critiquing restaurants at rating rangeing at:',critiqueDictionary['ciritiqued_Rating_list'])\n",
    "            #additionalText += '| critiquing restaurants at rating rangeing at:'+str(critiqueDictionary['ciritiqued_Rating_list'])\n",
    "\n",
    "            #Get the list of restaurants to critique\n",
    "            listCritiqueRes = [key  for (key, value) in IS_dictionary.items() if \\\n",
    "                               value in critiqueDictionary['ciritiqued_Rating_list']]\n",
    "            \n",
    "            #CHECK EXHAUSTED - Check to see if user critique exhausts the recommendation list\n",
    "            #Take a temporary list as updated critiquing list \n",
    "            tempCritiqueList = updateExtendList(critiqueDictionary['critique_Res_list'], listCritiqueRes)\n",
    "            \n",
    "            #Take a temporary list as updated recommendation list \n",
    "            tempRecommendList = [item for item in critiqueDictionary['current_user_item_predict'] \\\n",
    "                                                               if item not in tempCritiqueList]\n",
    "            #Exhausted recommendation list\n",
    "            if exhaustFallBack(tempRecommendList):\n",
    "                additionalText += '| Exhausted recommendation list, no matching restaurant after current critique, discarding current critique'\n",
    "            else:\n",
    "                #Updating the critiqued items to list\n",
    "                print('Saving critiqued items at index: ', listCritiqueRes[:5], '...')\n",
    "\n",
    "                #Update the critiqued restaurant list\n",
    "                critiqueDictionary['critique_Res_list'] = updateExtendList(critiqueDictionary['critique_Res_list'], listCritiqueRes)\n",
    "\n",
    "                #Record those as well\n",
    "                critiqueDictionary['critiqued_Res_AccrdStar_list'] = updateExtendList(critiqueDictionary['critiqued_Res_AccrdStar_list'], \\\n",
    "                                                                                      listCritiqueRes)\n",
    "                #Update current valid set \n",
    "                critiqueDictionary['current_user_item_predict'] = [item for item in critiqueDictionary['current_user_item_predict'] \\\n",
    "                                                                   if item not in critiqueDictionary['critique_Res_list']]\n",
    "        \n",
    "        \n",
    "        #Scenario #7 Critique on Distance, goes up or down, only say positive critiques. Want closer, further, or specific value \n",
    "        if 'distance' in critique_feature:\n",
    "            \n",
    "            #Get current distance\n",
    "            currentDistance = float(recommendResDict['recBusinessJson']['distance'].strip('km'))\n",
    "            \n",
    "            #If want further distance restaurants\n",
    "            if 'positive' in critique_posNeg and 'further' in critique_value:\n",
    "                print('Critiquing distance <=', currentDistance)\n",
    "                #New requirements for restaurants to be critiqued\n",
    "                listCritiquedRestaurant = [key for (key, value) in ID_dictionary.items() if value <= currentDistance]\n",
    "\n",
    "            #Closer distance, critique value not empty \n",
    "            else:\n",
    "                if (critique_value) and not 'closer' in critique_value.lower():\n",
    "                    currentDistance = float(critique_value)\n",
    "\n",
    "                print('Critiquing distance >=', currentDistance)\n",
    "\n",
    "                #New requirements for restaurants to be critiqued\n",
    "                listCritiquedRestaurant = [key for (key, value) in ID_dictionary.items() if value >= currentDistance]\n",
    "\n",
    "\n",
    "            #Update critique restaurant list, only keep the ones that are critiqued under other features\n",
    "            critiqueDictionary['critique_Res_list'] = [item for item in critiqueDictionary['test_user_item_predict'] if\\\n",
    "                                                      (item in list(set(listCritiquedRestaurant+\\\n",
    "                                                                        critiqueDictionary['critiqued_Res_AccrdPrice_list']+\\\n",
    "                                                                        critiqueDictionary['critiqued_Res_AccrdStar_list']+\\\n",
    "                                                                        critiqueDictionary['critiqued_Res_AccrdName_list']+\\\n",
    "                                                                        critiqueDictionary['critiqued_Res_AccrdCuisine_list'])))] \n",
    "\n",
    "            #Update list of restaurants critiqued by the restuarnt distance, entire replacement\n",
    "            critiqueDictionary['critiqued_Res_AccrdDistance_list'] = listCritiquedRestaurant\n",
    "\n",
    "            #Update initial valid restuarnt list\n",
    "            critiqueDictionary['current_user_item_predict'] = [item for item in critiqueDictionary['current_user_item_predict']\\\n",
    "                                                               if item not in critiqueDictionary['critique_Res_list']]\n",
    "\n",
    "            #Handle case where critiqued everything, there's no restuarnt that satisfy all the critiques \n",
    "            if(len(critiqueDictionary['current_user_item_predict']) == 0):\n",
    "                print('Exhausted sytem')\n",
    "\n",
    "                #new_Distance= input('There\\'s no restaurant that matches your preference within this area, please input a new larger distance')\n",
    "                additionalText += 'No restaurants that matches your preference within this area, currently default back to 2.0km'\n",
    "                new_Distance = 2.0\n",
    "                \n",
    "                listCritiquedRestaurant = [key for (key, value) in ID_dictionary.items() if value > new_Distance]\n",
    "\n",
    "                #Restore original critiqued restaurants under distance feature \n",
    "                critiqueDictionary['critique_Res_list'] = [item for item in critiqueDictionary['test_user_item_predict'] if\\\n",
    "                                    (item in list(set(listCritiquedRestaurant + \\\n",
    "                                                      critiqueDictionary['critiqued_Res_AccrdPrice_list']+\\\n",
    "                                                      critiqueDictionary['critiqued_Res_AccrdStar_list']+\\\n",
    "                                                      critiqueDictionary['critiqued_Res_AccrdName_list']+\\\n",
    "                                                      critiqueDictionary['critiqued_Res_AccrdCuisine_list'])))]   \n",
    "                #New critiquing restuarants\n",
    "                critiqueDictionary['critiqued_Res_AccrdDistance_list'] = listCritiquedRestaurant\n",
    "\n",
    "                #Update initial valid restuarnt list\n",
    "                critiqueDictionary['current_user_item_predict'] = [item for item in critiqueDictionary['current_user_item_predict'] \\\n",
    "                                                                   if item not in critiqueDictionary['critique_Res_list']]\n",
    "        \n",
    "        #Full fall back \n",
    "        if(len(critiqueDictionary['current_user_item_predict']) ==0):\n",
    "            fallBackSetup(critique_Res_list=critiqueDictionary['critique_Res_list'], \\\n",
    "                              critiqued_Res_AccrdName_list=critiqueDictionary['critiqued_Res_AccrdName_list'], \\\n",
    "                              critiqueDistance=2.0)\n",
    "            additionalText += ' Ran out of recommendations at the end of the process, reset, filtered out seen restaurants'\n",
    "            \n",
    "            #If still no results\n",
    "            if len(critiqueDictionary['current_user_item_predict']) ==0:\n",
    "                fallBackSetup(critique_Res_list=[], \\\n",
    "                              critiqued_Res_AccrdName_list=[], \\\n",
    "                              critiqueDistance=2.0)\n",
    "                additionalText += ' Clearing EVERYTHING'\n",
    "\n",
    "        #Construct newly returning item\n",
    "        return_Json = constructRestaurantDict(recommendIndex, critiqueDictionary['current_user_item_predict'],\\\n",
    "                                              df,ID_dictionary,additionalText)\n",
    "\n",
    "        #Update restaurant information for the GET method\n",
    "        recommendResDict['recBusinessJson'] = return_Json.copy()\n",
    "\n",
    "        #Return newly computed object \n",
    "        return {'You sent': request_json, 'Result': return_Json}, 201\n",
    "            \n",
    "api.add_resource(Business, '/business') # Route_1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     app.run(port='5002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original critiquing logic\n",
    "need to update updateExtendList function \n",
    "need to check when calling exhaust list, if retrieving message \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Recommendation\n",
      "Enter Stop any time to exist loop\n",
      "Recommending...\n",
      "------------------------------------------------------\n",
      "Business_num_id:  4501\n",
      "Restaurant name: Lai Wah Heen \n",
      "Cuisine Type:  Dim Sum \n",
      "Price: $$$ \n",
      "Rating: 3.5 \n",
      "Distance: 1.0 km\n",
      "------------------------------------------------------\n",
      "\n",
      "????????????????\n",
      "You Like? ('yes', 'no') no\n",
      "What feature to critique: (name, cuisine, price, rating, distance)price\n",
      "Positive or negative: positive\n",
      "Critique value: (cheaper, more expensive)cheaper\n",
      "????????????????\n",
      "\n",
      "You have exhaused the price range option, showing the most cheaper option\n",
      "Critiqing price at range: ['$$', '$$$', '$$$$']\n",
      "Saving critiqued items at index:  [1384, 4271, 1030, 1084, 3458] ...\n",
      "Re-recommending...\n",
      "Recommending...\n",
      "------------------------------------------------------\n",
      "Business_num_id:  2261\n",
      "Restaurant name: New Treasure \n",
      "Cuisine Type:  Dim Sum, Asian Fusion \n",
      "Price: $ \n",
      "Rating: 3.0 \n",
      "Distance: 1.1 km\n",
      "------------------------------------------------------\n",
      "\n",
      "????????????????\n"
     ]
    }
   ],
   "source": [
    "print('Initial Recommendation')\n",
    "print('Enter Stop any time to exist loop')\n",
    "#displayRestaurantInfo(recommendIndex, test_user_item_predict)\n",
    "\n",
    "while True:\n",
    "    satisfied = 'None'\n",
    "    feature = 'None'\n",
    "    positiveOrNegative = 'None'\n",
    "    critiqueValue = 'None'\n",
    "    \n",
    "    print('Recommending...')\n",
    "    displayRestaurantInfo(recommendIndex, current_user_item_predict,df,ID_dictionary)\n",
    "    \n",
    "    #Current recommendation cuisine type \n",
    "    currentCuisineType = df[df['business_num_id'] == current_user_item_predict[recommendIndex]]\\\n",
    "                                                        .categories.unique()[0].split(', ')\n",
    "    currentPriceLabel = IP_dictionary[current_user_item_predict[recommendIndex]]\n",
    "    currentRating = IS_dictionary[current_user_item_predict[recommendIndex]]\n",
    "    currentDistance = ID_dictionary[current_user_item_predict[recommendIndex]]\n",
    "    \n",
    "    #First testing cuisine type\n",
    "    print('\\n????????????????')\n",
    "    \n",
    "    while satisfied.lower() not in ['yes', 'no', 'stop']: \n",
    "        satisfied = input(\"You Like? ('yes', 'no') \").strip().lower()\n",
    "    \n",
    "    if satisfied == 'stop' or satisfied == 'yes':\n",
    "        print('BYE :)')\n",
    "        break\n",
    "        \n",
    "    #When satisfied is NO, take in feature\n",
    "    while feature.lower() not in ['name', 'cuisine', 'price', 'distance', 'rating', 'stop']: \n",
    "        feature = input(\"What feature to critique: (name, cuisine, price, rating, distance)\")\n",
    "    \n",
    "    if feature == 'stop':\n",
    "        break\n",
    "    \n",
    "    #Take in Positive or nagative \n",
    "    if feature != 'name':\n",
    "        while positiveOrNegative.lower() not in ['positive', 'negative', 'stop']:\n",
    "            positiveOrNegative = input(\"Positive or negative: \")\n",
    "    \n",
    "    if positiveOrNegative == 'stop':\n",
    "        break\n",
    "    \n",
    "    #Only ask for critique value when not critiquing restaurant name, or not negatively critiquing price \n",
    "    if feature != 'name' and not(feature == 'price' and positiveOrNegative == 'negative')\\\n",
    "    and not(feature == 'distance' and positiveOrNegative == 'negative'):\n",
    "    #and not(feature == 'rating' and positiveOrNegative == 'negative')\\\n",
    "     \n",
    "        #The valid values to be critiuqed that can pass in \n",
    "        validCritiqueValueList = []\n",
    "        #negatively critique current cuisine type, should only enter current cruisine type\n",
    "        if 'cuisine' in feature and 'negative' in positiveOrNegative:\n",
    "            validCritiqueValueList = [cat.strip().lower() for cat in currentCuisineType] + ['stop']\n",
    "            outPutString = '(' + currentCuisineType[0] +')'\n",
    "        elif 'cuisine' in feature and 'positive' in positiveOrNegative:\n",
    "            validCritiqueValueList = [cat.strip().lower() for cat in categoryList] \n",
    "            categories = list(set(IC_dictionary.keys())) + ['stop']\n",
    "            outPutString = '(' + categories[0] +categories[1] +categories[2] +'...)'\n",
    "        #Can only enter cheapter or more expensive\n",
    "        elif 'price' in feature:\n",
    "            validCritiqueValueList = ['cheaper', 'more expensive','stop']\n",
    "            outPutString = '(cheaper, more expensive)'\n",
    "        elif 'rating' in feature:\n",
    "            validCritiqueValueList = [str(star/10) for star in range(0,51,1)] + ['stop', 'current_rating']\n",
    "            outPutString = '(0 ~ 5.0 with 0.1 increment)'\n",
    "        #positively critique distance\n",
    "        elif 'distance' in feature:\n",
    "            validCritiqueDis = [str(i/10) for i in range(0,int((maxDistance+0.5)*10),5)][1:] \n",
    "            validCritiqueValueList = ['closer', 'further'] + validCritiqueDis + ['stop']\n",
    "            outPutString = '(closer, further, or distance in range 0.5 ~' + str(maxDistance) + 'in every 0.5km)' \n",
    "        #Prompt to ask critique value\n",
    "        while critiqueValue not in validCritiqueValueList:\n",
    "            critiqueValue = input(\"Critique value: \" + outPutString).strip().lower()\n",
    "        if critiqueValue == 'stop':\n",
    "            break\n",
    "            \n",
    "    print('????????????????\\n')\n",
    "    \n",
    "    #If user starts critiquing, the current showend restaurant will be in critiqued list \n",
    "    critique_Res_list.append(current_user_item_predict[recommendIndex])\n",
    "    critique_Res_list = list(set(critique_Res_list))\n",
    "    #critique_Res_list = updateList(critique_Res_list, current_user_item_predict[recommendIndex])\n",
    "    \n",
    "    #Scenario 1 - Critique Restaurant name \n",
    "    if 'name' in feature:\n",
    "        \n",
    "        print(\"Saving critiqued item: \", current_user_item_predict[recommendIndex])\n",
    "        \n",
    "        #Save critiqued restaurant to list \n",
    "        #critique_Res_list.append(current_user_item_predict[recommendIndex])\n",
    "        #critique_Res_list = list(set(critique_Res_list))\n",
    "        #critique_Res_list = updateList(critique_Res_list, current_user_item_predict[recommendIndex])\n",
    "        \n",
    "        #update critiqued restaurant list according to name\n",
    "        #critiqued_Res_AccrdName_list.append(current_user_item_predict[recommendIndex])\n",
    "        critiqued_Res_AccrdName_list = updateList(critiqued_Res_AccrdName_list, current_user_item_predict[recommendIndex])\n",
    "        \n",
    "        current_user_item_predict = current_user_item_predict[recommendIndex+1 :]\n",
    "        #Handling all items critiqued case\n",
    "        \"\"\"BUT I'M NOT COUNTING THE FACTOR THAT THE USER HAD LIKED CATEGORIES\"\"\"\n",
    "        current_user_item_predict, message = checkIfExhaustedList(current_user_item_predict, test_user_item_predict, critique_Res_list)\n",
    "            \n",
    "    #Scenario 2 - Negatively critique restaurant features \n",
    "    if ('cuisine' in feature.lower()) and ('negative' in positiveOrNegative.lower()):\n",
    "        \n",
    "        #Find the correct category name the user want to critique in current recommended item categories\n",
    "        critiqueValue = [cuisine for cuisine in currentCuisineType if critiqueValue.strip().lower() in cuisine.lower()][0]\n",
    "        \n",
    "        critiquied_Cat_Index = IC_dictionary[critiqueValue]\n",
    "        print('Saving negatively critiqued cuisine type:', critiqueValue, ', cuisine index: ', critiquied_Cat_Index)\n",
    "        critique_Cat_list.append(critiquied_Cat_Index)\n",
    "        \n",
    "        #Handling extreme case - critique categories previously requested \n",
    "        if critiquied_Cat_Index == wanted_Category_index:\n",
    "            #Reset wanted category index\n",
    "            wanted_Category_index = None\n",
    "            print('You are critiquing a cuisine type you previously requested\\n Fall back to initial preference')\n",
    "            current_user_item_predict = [item for item in test_user_item_predict if item not in critique_Res_list]\n",
    "        \n",
    "        \n",
    "        #Find list of restaurants to filter out \n",
    "        critiquedItemsList = I_C_matrix.getcol(critiquied_Cat_Index).nonzero()[0]\n",
    "        \n",
    "        critiqued_Res_AccrdCuisine_list.append(critiquedItemsList)\n",
    "        critiqued_Res_AccrdCuisine_list =list(set(critique_Res_list))\n",
    "        \n",
    "        #Updating the critiqued items to list\n",
    "        print('Saving critiqued items at index: ', critiquedItemsList[:5], '...')\n",
    "        critique_Res_list.extend(list(critiquedItemsList))\n",
    "        critique_Res_list = list(set(critique_Res_list))\n",
    "        \n",
    "        #Filter out critiqued items, sequence must remain the same \n",
    "        #Update current valid set \n",
    "        current_user_item_predict = [item for item in current_user_item_predict if item not in critique_Res_list]\n",
    "\n",
    "        #Handle case where run out of items! - Fall Back!\n",
    "        current_user_item_predict,message = checkIfExhaustedList(current_user_item_predict, test_user_item_predict, critique_Res_list)\n",
    "        \n",
    "        \n",
    "    \n",
    "    #Scenario 3 - Positively critique restaurant cuisine type \n",
    "    if 'cuisine' in feature and 'positive' in positiveOrNegative:\n",
    "\n",
    "        #Find the correct category within all the categories list - assuming exact word typed in \n",
    "        \"\"\"Add ERROR HANDLING HERE\"\"\"\n",
    "        positiveCritiquiCategory = [cuisine for cuisine in categoryList if critiqueValue.strip().lower() in cuisine.lower()][0]\n",
    "        \n",
    "        #Retrieve cuisine type index \n",
    "        positiveCritiquiedIndex = IC_dictionary[positiveCritiquiCategory]\n",
    "        \n",
    "        #Get the preferred category index \n",
    "        wanted_Category_index = positiveCritiquiedIndex\n",
    "        \n",
    "        #Retrieve items matching item category \n",
    "        matchedResList = I_C_matrix.getcol(positiveCritiquiedIndex).nonzero()[0]\n",
    "        print('matching list:', matchedResList[:10])\n",
    "        \n",
    "        #Check if user have previously critiqued - remove it\n",
    "        if positiveCritiquiedIndex in critique_Cat_list:\n",
    "            critique_Cat_list.remove(positiveCritiquiedIndex)\n",
    "            \n",
    "            #Update critiqued restaurant list according to cuisine type \n",
    "            critiqued_Res_AccrdCuisine_list.remove(matchedResList)\n",
    "            \n",
    "            #UPDATE CRITIQUE RESTAURANT LIST \n",
    "            #In the matched restuarnt list and not critiqued under other criteria will be withdrawn from this list\n",
    "            \"\"\"TODO\"\"\"\n",
    "            critique_Res_list = [item for item in critique_Res_list if item not in matchedResList or \\\n",
    "                                item in list(set(critiqued_Res_AccrdName_list+ critiqued_Res_AccrdCuisine_list+\\\n",
    "                                                 critiqued_Res_AccrdStar_list + critiqued_Res_AccrdDistance_list))]\n",
    "        \n",
    "        #Update current valid set, make sure not in critiqued restaurant set \n",
    "        current_user_item_predict = [item for item in matchedResList if item not in critique_Res_list]\n",
    "        \n",
    "    #Scenario 4 - Negative critique restuarant price e.g. \"I don't want expensive restaurants\" OR positive \"I want cheaper\"\n",
    "    #Does not pass in anything ASSUMING ONLY GOING DOWN\n",
    "    #Scenario 5 - Positively critique restaurant price, \"I want fine dining\", wanting more expensive restaurant \n",
    "    if 'price' in feature:\n",
    "        \n",
    "        #Update critiqued price list\n",
    "        if 'positive' in positiveOrNegative and critiqueValue == 'more expensive':\n",
    "            critique_Price_list.extend([price for price in range(1,currentPriceLabel+1,1)])\n",
    "        #Negative or positive, cheaper     \n",
    "        else:     \n",
    "            critique_Price_list.extend([price for price in range(currentPriceLabel,5,1)])\n",
    "            \n",
    "        #Deduplicate\n",
    "        critique_Price_list = list(set(critique_Price_list))\n",
    "        \n",
    "        #Check if critiqued all price range, if exhausted, fall back \n",
    "        if len(critique_Price_list) == 4:\n",
    "            print('You have exhaused the price range option, showing the most', critiqueValue, 'option')\n",
    "            #Clear the previous critiqued restuarants based on price out of critiqued restuarant list \n",
    "            #POTENTIAL ISSUE HERE, MAY BE ERASING SOME RESTAURANTS CRITIQUED IN OTHER STEPS ... NEED TO RECHECK\n",
    "            critique_Res_list = [item for item in test_user_item_predict if\\\n",
    "                                item in list(set(critiqued_Res_AccrdName_list+ critiqued_Res_AccrdCuisine_list+\\\n",
    "                                                 critiqued_Res_AccrdStar_list + critiqued_Res_AccrdDistance_list))]\n",
    "            \n",
    "            #Clear out the restuarants critiquied by price \n",
    "            critiqued_Res_AccrdPrice_list = []\n",
    "            \n",
    "            #Restore default critiquing price list \n",
    "            if critiqueValue == 'more expensive':\n",
    "                critique_Price_list = [1,2,3]\n",
    "            else:\n",
    "                critique_Price_list = [2,3,4]  \n",
    "        \n",
    "        print('Critiqing price at range:', ['$'*label for label in critique_Price_list])\n",
    "        \n",
    "        #Find the list of restaurants to critique \n",
    "        listCritiqueRestaurant = [key  for (key, value) in IP_dictionary.items() if value in critique_Price_list]\n",
    "        \n",
    "        #Record the list of restaurants critiqued so far based on price \n",
    "        #critiqued_Res_AccrdPrice_list.extend(listCritiqueRestaurant)\n",
    "        #critiqued_Res_AccrdPrice_list = list(set(critiqued_Res_AccrdPrice_list))\n",
    "        \n",
    "        critiqued_Res_AccrdPrice_list = updateExtendList(critiqued_Res_AccrdPrice_list, listCritiqueRestaurant)\n",
    "        \n",
    "        #Update the critiqued restaurant list\n",
    "        #critique_Res_list.extend(listCritiqueRestaurant)\n",
    "        #critique_Res_list = list(set(critique_Res_list))\n",
    "        critique_Res_list = updateExtendList(critique_Res_list, listCritiqueRestaurant)\n",
    "        \n",
    "        \n",
    "        #Updating the critiqued items to list\n",
    "        print('Saving critiqued items at index: ', listCritiqueRestaurant[:5], '...')\n",
    "        \n",
    "        #Filter out critiqued items, sequence must remain the same \n",
    "        #Update current valid set \n",
    "        current_user_item_predict = [item for item in current_user_item_predict if item not in critique_Res_list]\n",
    "        \n",
    "        #Check if exhaused list\n",
    "        current_user_item_predict, message = checkIfExhaustedList(current_user_item_predict, test_user_item_predict, critique_Res_list)\n",
    "        \n",
    "        #Recommended\n",
    "        print('Re-recommending...')\n",
    "        \n",
    "    #Scenario 6 negatively critique rating & positively critique rating: both goes up \n",
    "    #\"I don't want ratings this low?\" \"I don't want restuarants with rating below XXX\" \"I want restaurants with rating above XXX\"\n",
    "    #I will critique the ratings below the current rating or specific rating \n",
    "    if 'rating' in feature:\n",
    "        #Critiquing the restaurants that has ratings equal and below this restaurant \n",
    "        #if 'negative' in positiveOrNegative:\n",
    "            #ciritiqued_Rating_list.extend([rating/10 for rating in range(0,int(currentRating*10+1),5)])\n",
    "        #else:\n",
    "        \n",
    "        if critique_value.lower() == 'current_rating':\n",
    "                critique_value = currentRating\n",
    "\n",
    "        ciritiqued_Rating_list.extend([rating/10 for rating in range(0,int(float(critiqueValue)*10)+1,5)])   \n",
    "        ciritiqued_Rating_list = list(set(ciritiqued_Rating_list))\n",
    "            \n",
    "        #If critiqued all price\n",
    "        if ciritiqued_Rating_list == [price/10 for price in range(0,int(5.0 *10 +1),5)]:\n",
    "            print('exhausted list, no better restaurants, recommending he finest restaurants')\n",
    "            #reset critiqued restaurant list \n",
    "            critique_Res_list = [item for item in test_user_item_predict if\\\n",
    "                                item in list(set(critiqued_Res_AccrdName_list+critiqued_Res_AccrdCuisine_list+\\\n",
    "                                                critiqued_Res_AccrdPrice_list+critiqued_Res_AccrdDistance_list))] \n",
    "\n",
    "            #Clear out the restuarants critiquied by rating \n",
    "            critiqued_Res_AccrdStar_list = []\n",
    "\n",
    "            ciritiqued_Rating_list = [rating/10 for rating in range(0,int(currentRating*10+1),5)]\n",
    "\n",
    "        print('critiquing restaurants at rating rangeing at:',ciritiqued_Rating_list)\n",
    "\n",
    "        #Get the list of restaurants to critique\n",
    "        listCritiqueRes = [key  for (key, value) in IS_dictionary.items() if value in ciritiqued_Rating_list]\n",
    "\n",
    "        #Updating the critiqued items to list\n",
    "        print('Saving critiqued items at index: ', listCritiqueRes[:5], '...')\n",
    "\n",
    "        #Update the critiqued restaurant list\n",
    "        #critique_Res_list.extend(listCritiqueRes)\n",
    "        #critique_Res_list = list(set(critique_Res_list))\n",
    "        critique_Res_list = updateExtendList(critique_Res_list, listCritiqueRes)\n",
    "        \n",
    "        #Record those as well\n",
    "        #critiqued_Res_AccrdStar_list.extend(listCritiqueRes)\n",
    "        #critiqued_Res_AccrdStar_list = list(set(critiqued_Res_AccrdStar_list))\n",
    "        critiqued_Res_AccrdStar_list = updateExtendList(critiqued_Res_AccrdStar_list, listCritiqueRes)\n",
    "\n",
    "        #Update current valid set \n",
    "        current_user_item_predict = [item for item in current_user_item_predict if item not in critique_Res_list]\n",
    "        \n",
    "        \n",
    "    #Scenario #7 Critique on Distance, goes up or down, only say positive critiques\n",
    "    #Want closer, further, or specific value \n",
    "    if 'distance' in feature:\n",
    "        #If want further distance restaurants\n",
    "        if 'positive' in positiveOrNegative and 'further' in critiqueValue:\n",
    "            print('Critiquing distance <=', currentDistance)\n",
    "\n",
    "            #New requirements for restaurants to be critiqued\n",
    "            listCritiquedRestaurant = [key for (key, value) in ID_dictionary.items() if value <= currentDistance]\n",
    "        \n",
    "        #Closer distance\n",
    "        else:\n",
    "            if (critiqueValue != 'None') and not 'closer' in critiqueValue:\n",
    "                currentDistance = int(critiqueValue)\n",
    "                \n",
    "            print('Critiquing distance >=', currentDistance)\n",
    "            \n",
    "            #New requirements for restaurants to be critiqued\n",
    "            listCritiquedRestaurant = [key for (key, value) in ID_dictionary.items() if value >= currentDistance]\n",
    "        \n",
    "\n",
    "        #Update critique restaurant list, only keep the ones that are critiqued under other features\n",
    "        critique_Res_list = [item for item in test_user_item_predict if\\\n",
    "                            (item in list(set(listCritiquedRestaurant+critiqued_Res_AccrdPrice_list+\\\n",
    "                                              critiqued_Res_AccrdStar_list+critiqued_Res_AccrdName_list+\\\n",
    "                                                critiqued_Res_AccrdCuisine_list)))] \n",
    "        \n",
    "        #Update list of restaurants critiqued by the restuarnt distance, entire replacement\n",
    "        critiqued_Res_AccrdDistance_list= listCritiquedRestaurant\n",
    "        \n",
    "        #Update initial valid restuarnt list\n",
    "        current_user_item_predict = [item for item in  current_user_item_predict if item not in critique_Res_list]\n",
    "        \n",
    "        #Handle case where critiqued everything, there's no restuarnt that satisfy all the critiques \n",
    "        if(len(current_user_item_predict) == 0):\n",
    "            print('Exhausted sytem')\n",
    "            \n",
    "            new_Distance= input('There\\'s no restaurant that matches your preference within this area, please input a new larger distance')\n",
    "\n",
    "            listCritiquedRestaurant = [key for (key, value) in ID_dictionary.items() if value > new_Distance]\n",
    "            \n",
    "            #Restore original critiqued restaurants under distance feature \n",
    "            critique_Res_list = [item for item in test_user_item_predict if\\\n",
    "                                (item in list(set(listCritiquedRestaurant+critiqued_Res_AccrdPrice_list\\\n",
    "                                                  +critiqued_Res_AccrdStar_list+critiqued_Res_AccrdName_list+\\\n",
    "                                                    critiqued_Res_AccrdCuisine_list)))] \n",
    "            \n",
    "            #New critiquing restuarants\n",
    "            critiqued_Res_AccrdDistance_list= listCritiquedRestaurant\n",
    "        \n",
    "            #Update initial valid restuarnt list\n",
    "            current_user_item_predict = [item for item in  current_user_item_predict if item not in critique_Res_list]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = listCritiquedRestaurant+critiqued_Res_AccrdPrice_list+ critiqued_Res_AccrdStar_list+critiqued_Res_AccrdName_list + critiqued_Res_AccrdCuisine_list\n",
    "a = 4139\n",
    "4139 not in critiqued_Res_AccrdDistance_list or 4139 in list(set(merge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of reviews popularity list, redundent with the output of the next method\n",
    "dff_popular = df.copy()\n",
    "dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "#Get the list of restaurants accoridng to their popularity level\n",
    "popular_list = dff_popular[\"business_num_id\"].tolist()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrainValide = rtrain + rvalid\n",
    "numUsers = rtrainValide.shape[0]\n",
    "# transfer to a matrix(list * number of users)\n",
    "matrix_popular_list_num_of_reviews = np.tile(popular_list,(numUsers,1))\n",
    "matrix_popular_list_num_of_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popularity_res = evaluate(matrix_popular_list_num_of_reviews, rtest)\n",
    "popularity_res['MAP@10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrain = rtrain + rvalid \n",
    "rtrain_implicit = rtrain_implicit + rvalid_implicit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrain_implicit_similarity_trainValid = train(rtrain_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IK_MATRIX_trainValid = X_cleaned_sparse_trainValid\n",
    "IK_similarity_trainValid = train(IK_MATRIX_trainValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPerformance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testPerformance['Implicit_UserReview'] = KNNPrediction(rtrain_implicit_similarity_trainValid, rtrain_implicit, 140, rtest_implicit, itemBased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testPerformance['Implicit_Explicit_Combined_UserReview'] = KNNPrediction(rtrain_implicit_similarity_trainValid, rtrain, 100, rtest, itemBased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testPerformance['ItemKeyphrase'] = KNNPrediction(IK_similarity_trainValid, rtrain, 110, rtest, itemBased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testPerformance['ItemCategory'] = KNNPrediction(IC_similarity, rtrain, 130, rtest, itemBased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPerformance['Popularity_reviewNumber'] = popularity_res['MAP@10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requests  Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask_restful import reqparse, abort, Api, Resource\n",
    "\n",
    "app = Flask(__name__)\n",
    "api = Api(app)\n",
    "\n",
    "TODOS = {\n",
    "    'todo1': {'task': 'build an API'},\n",
    "    'todo2': {'task': '?????'},\n",
    "    'todo3': {'task': 'profit!'},\n",
    "}\n",
    "\n",
    "\n",
    "def abort_if_todo_doesnt_exist(todo_id):\n",
    "    if todo_id not in TODOS:\n",
    "        abort(404, message=\"Todo {} doesn't exist\".format(todo_id))\n",
    "\n",
    "parser = reqparse.RequestParser()\n",
    "parser.add_argument('task')\n",
    "\n",
    "\n",
    "# Todo\n",
    "# shows a single todo item and lets you delete a todo item\n",
    "class Todo(Resource):\n",
    "    def get(self, todo_id):\n",
    "        abort_if_todo_doesnt_exist(todo_id)\n",
    "        return TODOS[todo_id]\n",
    "\n",
    "    def delete(self, todo_id):\n",
    "        abort_if_todo_doesnt_exist(todo_id)\n",
    "        del TODOS[todo_id]\n",
    "        return '', 204\n",
    "\n",
    "    def put(self, todo_id):\n",
    "        args = parser.parse_args()\n",
    "        task = {'task': args['task']}\n",
    "        TODOS[todo_id] = task\n",
    "        return task, 201\n",
    "\n",
    "\n",
    "# TodoList\n",
    "# shows a list of all todos, and lets you POST to add new tasks\n",
    "class TodoList(Resource):\n",
    "    def get(self):\n",
    "        return TODOS\n",
    "\n",
    "    def post(self):\n",
    "        args = parser.parse_args()\n",
    "        todo_id = int(max(TODOS.keys()).lstrip('todo')) + 1\n",
    "        todo_id = 'todo%i' % todo_id\n",
    "        TODOS[todo_id] = {'task': args['task']}\n",
    "        return TODOS[todo_id], 201\n",
    "\n",
    "\n",
    "## Actually setup the Api resource routing here\n",
    "\n",
    "api.add_resource(TodoList, '/todos')\n",
    "api.add_resource(Todo, '/todos/<todo_id>')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

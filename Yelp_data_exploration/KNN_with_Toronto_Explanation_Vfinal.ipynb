{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\hexiaoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hexiaoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hexiaoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hexiaoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hexiaoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Data Packages\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Counter\n",
    "from collections import Counter\n",
    "import collections\n",
    "\n",
    "#Operation\n",
    "import operator\n",
    "\n",
    "#Natural Language Processing Packages\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "## Download Resources\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import PerceptronTagger\n",
    "from nltk.data import find\n",
    "\n",
    "## Machine Learning\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-word for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Lexicon --> Add Polarity Score for Restaurant Specific Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = {\n",
    "\"excellent\":3.99,\n",
    "\"amazing\":3.981,\n",
    "\"awesome\":3.98,\n",
    "\"best\":3.98,\n",
    "\"wonderful\":3.979,\n",
    "\"authentic\":3.97,\n",
    "\"incredible\":3.97,\n",
    "\"incredibly\":3.97,\n",
    "\"popular\":3.96,\n",
    "\"well-known\":3.96,\n",
    "\"delicious\":3.95,\n",
    "\"tasty\":3.94,\n",
    "\"five-star\":3.91,\n",
    "\"fanciest\":3.89,\n",
    "\"finest\":3.89,\n",
    "\"fast\":3.88,\n",
    "\"phenomenal\":3.88,\n",
    "\"exceptional\":3.83,\n",
    "\"exceptionally\":3.83,\n",
    "\"extrodinary\":3.82,\n",
    "\"magnificent\":3.82,\n",
    "\"famous\":3.81,\n",
    "\"fantastic\":3.8,\n",
    "\"splendid\":3.7,\n",
    "\"yummy\":3.7,\n",
    "\"flavorful\":3.699,\n",
    "\"flavourful\":3.699,\n",
    "\"delightful\":3.69,\n",
    "\"decent\":3.6,\n",
    "\"unique\":3.6,\n",
    "\"flavored\":3.5,\n",
    "\"fancy\":3.5,\n",
    "\"quick\":3.1,\n",
    "\"classic\":3,\n",
    "\"fresh\":3,\n",
    "\"xoxo\":0,\n",
    "\"fine\":0.1,\n",
    "\"please\":0,\n",
    "\"yeah\":0\n",
    "}\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "#Update new words with polarity score\n",
    "sid.lexicon.update(new_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contraction Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\",\n",
    "\"ice cream\": \"ice-cream\",\n",
    "\"hot pot\": \"hot-pot\",\n",
    "\"icecream \": \"ice-cream\",\n",
    "\"hotpot\": \"hot pot\",\n",
    "\"dim sum\":\"dim-sum\",\n",
    "\"dimsum\":\"dim-sum\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dict = \\\n",
    "{\"ice cream\": \"ice-cream\",\n",
    "\"hot pot\": \"hot-pot\",\n",
    "\"icecream \": \"ice-cream\",\n",
    "\"hotpot\": \"hot pot\",\n",
    "\"dim sum\":\"dim-sum\",\n",
    "\"dimsum\":\"dim-sum\",\n",
    "\"egg tart\":\"egg-tart\",\n",
    "\"eggtart\":\"egg-tart\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use vader to evaluate sentiment of reviews, vader here!\n",
    "def evalSentences(sentences, to_df=False, columns=[]):\n",
    "    #Instantiate an instance to access SentimentIntensityAnalyzer class\n",
    "    pdlist = []\n",
    "    if to_df:\n",
    "        for sentence in tqdm(sentences):\n",
    "            ss = sid.polarity_scores(sentence)\n",
    "            pdlist.append([sentence]+[ss['compound']])\n",
    "        reviewDf = pd.DataFrame(pdlist)\n",
    "        reviewDf.columns = columns\n",
    "        return reviewDf\n",
    "    \n",
    "    else:\n",
    "        for sentence in tqdm(sentences):\n",
    "            print(sentence)\n",
    "            ss = sid.polarity_scores(sentence)\n",
    "            for k in sorted(ss):\n",
    "                print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yelp_df(path = 'data/', filename = 'Export_CleanedReview.json', sampling=False, top_user_num=6100, top_item_num=4000):\n",
    "    \"\"\"\n",
    "    Get the pandas dataframe\n",
    "    Sampling only the top users/items by density \n",
    "    Implicit representation applies\n",
    "    \"\"\"\n",
    "    with open(filename,'r') as f:\n",
    "        data = f.readlines()\n",
    "        data = list(map(json.loads, data))\n",
    "    \n",
    "    data = data[0]\n",
    "    #Get all the data from the data\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df.rename(columns={'stars': 'review_stars', 'text': 'review_text', 'cool': 'review_cool',\n",
    "                       'funny': 'review_funny', 'useful': 'review_useful'}, inplace=True)\n",
    "\n",
    "    df['business_num_id'] = df.business_id.astype('category').\\\n",
    "        cat.rename_categories(range(0, df.business_id.nunique()))\n",
    "    df['business_num_id'] = df['business_num_id'].astype('int')\n",
    "\n",
    "    df['user_num_id'] = df.user_id.astype('category').\\\n",
    "    cat.rename_categories(range(0, df.user_id.nunique()))\n",
    "    df['user_num_id'] = df['user_num_id'].astype('int')\n",
    "\n",
    "    df['timestamp'] = df['date'].apply(date_to_timestamp)\n",
    "\n",
    "    if sampling:\n",
    "        df = filter_yelp_df(df, top_user_num=top_user_num, top_item_num=top_item_num)\n",
    "        # Refresh num id\n",
    "        df['business_num_id'] = df.business_id.astype('category').\\\n",
    "        cat.rename_categories(range(0, df.business_id.nunique()))\n",
    "        df['business_num_id'] = df['business_num_id'].astype('int')\n",
    "        \n",
    "        df['user_num_id'] = df.user_id.astype('category').\\\n",
    "        cat.rename_categories(range(0, df.user_id.nunique()))\n",
    "        df['user_num_id'] = df['user_num_id'].astype('int')\n",
    "        # drop_list = ['date','review_id','review_funny','review_cool','review_useful']\n",
    "        # df = df.drop(drop_list, axis=1)\n",
    "    df = df.reset_index(drop = True)\n",
    "    return df \n",
    "\n",
    "def filter_yelp_df(df, top_user_num=6100, top_item_num=4000):\n",
    "    #Getting the reviews where starts are above 3\n",
    "    df_implicit = df[df['review_stars']>3]\n",
    "    frequent_user_id = df_implicit['user_num_id'].value_counts().head(top_user_num).index.values\n",
    "    frequent_item_id = df_implicit['business_num_id'].value_counts().head(top_item_num).index.values\n",
    "    return df.loc[(df['user_num_id'].isin(frequent_user_id)) & (df['business_num_id'].isin(frequent_item_id))]\n",
    "\n",
    "def date_to_timestamp(date):\n",
    "    dt = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "    return time.mktime(dt.timetuple())\n",
    "\n",
    "def df_to_sparse(df, row_name='userId', col_name='movieId', value_name='rating',\n",
    "                 shape=None):\n",
    "    rows = df[row_name]\n",
    "    cols = df[col_name]\n",
    "    if value_name is not None:\n",
    "        values = df[value_name]\n",
    "    else:\n",
    "        values = [1]*len(rows)\n",
    "    return csr_matrix((values, (rows, cols)), shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_business_review(business_num_id,df_Subset_Cols):\n",
    "#     # Set the business ID below\n",
    "#     #3464 Hotpot, 2159 Hand-pulled noodle, 3490 Pai Northern Thai\n",
    "#     review_text = df.loc[df['business_num_id'] == business_num_id, 'review_text'].sum()\n",
    "#     #review_text\n",
    "# #     for word in tqdm(review_text.split()):\n",
    "# #         if word.lower() in contractions:\n",
    "# #             review_text = review_text.replace(word, contractions[word.lower()])\n",
    "    \n",
    "#     for word in contractions.keys():\n",
    "#         review_text = review_text.lower().replace(word,contractions[word.lower()])\n",
    "    \n",
    "#     df_spe_item = df_Subset_Cols.loc[df_Subset_Cols['business_num_id'] == business_num_id]\n",
    "#     for i in range(len(df_spe_item)):\n",
    "#         for word in contractions.keys():\n",
    "#             row = df_spe_item.review_text.iloc[i].lower().replace(word,contractions[word.lower()])\n",
    "#             df_spe_item['review_text'].iloc[i] = row\n",
    "            \n",
    "#     return review_text, df_spe_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_business_review(business_num_id,df_Subset_Cols):\n",
    "    # Set the business ID below\n",
    "    #3464 Hotpot, 2159 Hand-pulled noodle, 3490 Pai Northern Thai\n",
    "    review_text = df.loc[df['business_num_id'] == business_num_id, 'review_text'].sum()\n",
    "    \n",
    "    for word in contractions.keys():\n",
    "        review_text = review_text.replace(word,contractions[word.lower()])\n",
    "    \n",
    "    df_spe_item = df_Subset_Cols.loc[df_Subset_Cols['business_num_id'] == business_num_id]\n",
    "\n",
    "    return review_text, df_spe_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun Phrase Extraction Support Functions\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "# generator, generate leaves one by one\n",
    "# Filter only on NP (The other two labels may not be useful)\n",
    "def leaves(tree):\n",
    "    \"\"\"Finds NP (nounphrase) leaf nodes of a chunk tree.\"\"\"\n",
    "    for subtree in tree.subtrees(filter = lambda t: t.label()=='NP' or t.label()=='JJ' or t.label()=='RB'):\n",
    "        yield subtree.leaves()\n",
    "\n",
    "# stemming, lematizing, lower case...\n",
    "def normalise(word):\n",
    "    \"\"\"Normalises words to lowercase and stems and lemmatizes it.\"\"\"\n",
    "    word = word.lower()\n",
    "    #word = stemmer.stem(word)\n",
    "    if word != 'was':\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "    return word\n",
    "        \n",
    "# stop-words and length control\n",
    "def acceptable_word(word):\n",
    "    \"\"\"Checks conditions for acceptable word: length, stopword.\"\"\"\n",
    "    special_non_stopwords = ['is','was','are','were'] # Kick out a few words from stopwords list\n",
    "    final_stop_words = list([word for word in stopwords.words('english') if word not in special_non_stopwords])\n",
    "    accepted = (bool(2 <= len(word) <= 40)\n",
    "    and word.lower() not in final_stop_words)\n",
    "    return accepted\n",
    "        \n",
    "# generator, create item once a time\n",
    "def get_terms(tree):\n",
    "    for leaf in leaves(tree):\n",
    "        # Normalize word in \n",
    "        term = [normalise(w) for w,t in leaf if acceptable_word(w) ]\n",
    "        # Phrase only\n",
    "        if len(term)>1:\n",
    "            yield term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten phrase lists to get tokens for analysis\n",
    "def flatten(npTokenList):\n",
    "    finalList =[]\n",
    "    for phrase in npTokenList:\n",
    "        token = ''\n",
    "        for word in phrase:\n",
    "            token += word + ' '\n",
    "        finalList.append(token.rstrip())\n",
    "    return finalList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2\n",
    "grammar1 = r\"\"\"\n",
    "    NBAR:\n",
    "        {<RB|RBS>?<JJ|JJR|JJS>+<NN|NNS>+}\n",
    "    NP:\n",
    "        {<NBAR>}\n",
    "        {<NBAR><IN><NBAR>}\n",
    "\"\"\"\n",
    "\n",
    "grammar2 = r\"\"\"\n",
    "    NBAR:\n",
    "        {<NN|NNS>+<VBZ|VBD><RB>?<JJ>+}\n",
    "    NP:\n",
    "        {<NBAR>}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract key phrases in the given grammar\n",
    "def get_keyphrase_list(review_text):\n",
    "    tagger = PerceptronTagger()\n",
    "    pos_tag = tagger.tag\n",
    "    taggedToks = pos_tag([word.lower() for word in tqdm(re.findall(r'[\\w]+-[\\w]+[-[\\w]+]?|[\\w]+|[.,!?;]', review_text))])\n",
    "\n",
    "    # Create phrase tree\n",
    "    chunker1 = nltk.RegexpParser(grammar1)\n",
    "    tree1= chunker1.parse(taggedToks)\n",
    "    chunker2 = nltk.RegexpParser(grammar2)\n",
    "    tree2= chunker2.parse(taggedToks)\n",
    "\n",
    "    # Traverse tree and get noun phrases\n",
    "    npTokenList1 = [word for word in get_terms(tree1)]\n",
    "    # npTokenList\n",
    "    npTokenList2 = [word for word in get_terms(tree2)]\n",
    "    # Combine np token list to one\n",
    "    npTokenList_duplicate = npTokenList1 + npTokenList2\n",
    "    npTokenList = []\n",
    "    for i in tqdm(npTokenList_duplicate):\n",
    "        if i not in npTokenList:\n",
    "            npTokenList.append(i)\n",
    "    \n",
    "    \n",
    "    Extracted_list1 = flatten(npTokenList1)\n",
    "    Extracted_list2 = flatten(npTokenList2)\n",
    "    #Extracted_list = flatten([word\n",
    "    #                           for word\n",
    "    #                           in get_terms(chunker.parse(pos_tag([word.lower()\n",
    "    #                                                               for word in re.findall(r'\\w+', review_text)])))])\n",
    "    Extracted_list = Extracted_list1 + list(set(Extracted_list2) - set(Extracted_list1))\n",
    "    return Extracted_list,npTokenList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract noun phrases from the extracted keyphrases (In order to rank the noun phrase frequency)\n",
    "def get_noun_list(npToken_List,stop_words):\n",
    "    # create a list of NN from the Keyphrase list\n",
    "    NN_List=[]\n",
    "    \n",
    "    for word in npToken_List:\n",
    "        phrase = pos_tag(word)\n",
    "        for term in phrase:\n",
    "            if term[1]=='NN':\n",
    "                NN_List.append(term[0])\n",
    "    NN_List=list(dict.fromkeys(NN_List))\n",
    "    \n",
    "    # filter out the stop words\n",
    "    NN_List= [x for x in NN_List if x not in stop_words]\n",
    "    return NN_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the noun words/phrases based on the total number of appearances in all the reviews (if the phrase existed one or more times in a review, count once…)\n",
    "def get_score_from_freq(NN_List,review_text,df_spe_item):\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    stop = set(stopwords.words('english'))\n",
    "    # Get the frequency of the noun from the whole review, store in the dict_Counter\n",
    "    dict_Counter = {}\n",
    "    c = collections.Counter([normalise(word) for word in re.findall(r'[\\w]+-[\\w]+[-[\\w]+]?|[\\w]+|[.,!?;]', review_text) if word.lower() not in stop and len(word) > 2])\n",
    "    for term in tqdm(NN_List):\n",
    "        if term in c:\n",
    "            dict_Counter[term] = dict(c)[term]\n",
    "\n",
    "    \n",
    "    # Get the binary frequency of the noun for each review. If the word in this review, then it is 1, otherwise is 0\n",
    "    # store in the review_freq_counter\n",
    "    # initialize review_freq_counter\n",
    "    review_freq_counter = {}   \n",
    "    for k in dict_Counter.keys():\n",
    "        review_freq_counter[k] = 0\n",
    "        \n",
    "    for i in tqdm(range(len(df_business.review_text.values))):\n",
    "        temp = lemmatizer.lemmatize(df_business.review_text.values[i]).lower()\n",
    "        for key in merge_dict.keys():\n",
    "            temp=temp.replace(key,merge_dict[key])\n",
    "        temp_list = re.findall(r'[\\w]+-[\\w]+[-[\\w]+]?|[\\w]+|[.,!?;]',temp)\n",
    "        for word in dict_Counter.keys():\n",
    "            if word in temp_list:\n",
    "                review_freq_counter[word] = review_freq_counter[word]+1 \n",
    "                \n",
    "    # normalized score by --> dict_Counter(total frequency) * review_freq_counter(binary review frequency)\n",
    "    normalized_score = {}\n",
    "    for k in dict_Counter.keys():\n",
    "        normalized_score[k] = 0\n",
    "\n",
    "    #construct the score by multiplying\n",
    "    for word in dict_Counter.keys():\n",
    "        normalized_score[word] = dict_Counter[word] * review_freq_counter[word]\n",
    "\n",
    "    #sort it and store it in a list\n",
    "    final_score_counter=[]\n",
    "    for key, value in tqdm(sorted(normalized_score.items(), key=lambda item: item[1], reverse = True)):\n",
    "        temp = [key,value]\n",
    "        final_score_counter.append(temp)\n",
    "    return final_score_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the key phrases that contain the top noun phrases (top 3 nouns, so three lists of key phrases will be generated and each contains\n",
    "def get_keyphrase_contain_topk(top_word_list, k,Extracted_list):\n",
    "    topk_freq_words = [x[0] for x in top_word_list[0:k]]\n",
    "    keyphrase_list = []\n",
    "    for key_word in Extracted_list:\n",
    "        for freq_word in topk_freq_words:\n",
    "            if freq_word in key_word:\n",
    "                keyphrase_list.append(key_word)\n",
    "    return list(dict.fromkeys(keyphrase_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top sentiment scored a key phrase from each of the lists\n",
    "def get_final_keyphrase(df_keyphrase, topk, top_word_list):\n",
    "    res_dict = {}\n",
    "    topk_freq_words = [x[0] for x in top_word_list[0:topk]]\n",
    "    for word in topk_freq_words:\n",
    "        for i in range(df_keyphrase.keyphrase_list.values.shape[0]):\n",
    "            #deduplicate with excisting keyphrases\n",
    "            if df_keyphrase[\"keyphrase_list\"][i] not in list(res_dict.values()):\n",
    "                if word in df_keyphrase[\"keyphrase_list\"][i].split():\n",
    "                    if word not in res_dict:\n",
    "                        res_dict[word] = df_keyphrase[\"keyphrase_list\"][i]\n",
    "                    if word in res_dict:\n",
    "                        if df_keyphrase[\"Vader\"][i] > df_keyphrase[df_keyphrase[\"keyphrase_list\"] == res_dict[word]].Vader.values[0]:\n",
    "                            res_dict[word] = df_keyphrase[\"keyphrase_list\"][i]\n",
    "    \n",
    "    for (key,val) in res_dict.items():\n",
    "        #replace words\n",
    "        val = val.replace(\"was\", \"is\").replace(\"were\",\"are\").replace(\"also\",\"\").replace(\"still\",\"\").replace(\"actual\",\"\")\n",
    "        #deduplicate\n",
    "        res_dict[key] = ' '.join(list(dict.fromkeys(val.split())))\n",
    "        \n",
    "        # reorder to a list\n",
    "#     res_list = []\n",
    "#     for i in topk_freq_words:\n",
    "#         res_list.append([i,res_dict[i]])\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Read Data\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewJsonToronto = \"..\\\\data\\\\Export_TorontoData.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_yelp_df(path ='', filename=reviewJsonToronto, sampling= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-setting for the variables\n",
    "set :\n",
    "- which business to use\n",
    "- stop_words\n",
    "- how many nouns\n",
    "- tagger and pos_tag declaration\n",
    "- Add Vader for restaurant-specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_num_id = 3782\n",
    "stop_words_defined = [\"place\",\"restaurant\",\"food\", \"amount\",\"experience\",\"side\",\"size\",\"location\",\"quality\" ,\"taste\"\\\n",
    ",\"thing\",\"order\",\"bowl\",\"night\",\"day\",\"flavour\",\"spot\",\"portion\",\"dish\",\"meal\",\"good\",\"drink\",\"time\",\"everything\",\"get\",'delivery','nice',\"customer\",\"one\"]\n",
    "tagger = PerceptronTagger()\n",
    "pos_tag = tagger.tag\n",
    "# how many nouns are we looking at\n",
    "top_k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/2281 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2281/2281 [00:00<00:00, 2287711.01it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/105 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 105/105 [00:00<00:00, 102490.56it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 58/58 [00:00<00:00, 29078.37it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 4345.04it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 58/58 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 20054.05it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seafood': 'seafood came really fast',\n",
       " 'shrimp': 'shrimp poop',\n",
       " 'sauce': 'sauce is good'}"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get whole review text and the dataframe for this item\n",
    "review_text, df_business= get_business_review(business_num_id,df)\n",
    "# get all keyphrases and npTokenList(keyphrases before flatten --> partitioned keyphrase)\n",
    "Extracted_list,npTokenList = get_keyphrase_list(review_text)\n",
    "# get a noun list\n",
    "Noun_List = get_noun_list(npTokenList,stop_words_defined)\n",
    "# get a noun and it's score(dict_Counter(total frequency) * review_freq_counter(binary review frequency)), store in list\n",
    "top_noun_with_score = get_score_from_freq(Noun_List,review_text,df_business)\n",
    "# keyphrases that contrain the top nouns\n",
    "keyphrase_list = get_keyphrase_contain_topk(top_noun_with_score,top_k ,Extracted_list)\n",
    "# get dataframe for the keyphrases with vader score\n",
    "df_keyphrase = evalSentences(keyphrase_list, to_df=True,columns = ['keyphrase_list', 'Vader'])\n",
    "# get final keyphrases(one for each noun)\n",
    "keyphrase_final = get_final_keyphrase(df_keyphrase,3,top_noun_with_score)\n",
    "keyphrase_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = [3490,888,2666,820,2159,1796,1657,1367,215,2768,3758,2264,540,2427,1526,3740,166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pai Northern Thai Kitchen',\n",
       "  {'thai': 'best authentic thai food',\n",
       "   'pad': 'pad thai is super flavourful',\n",
       "   'curry': 'delicious curry'}],\n",
       " ['Hokkaido Ramen Santouka',\n",
       "  {'broth': 'awesome super rich broth',\n",
       "   'pork': 'pork is super',\n",
       "   'one': 'famous popular one'}],\n",
       " ['Insomnia Restaurant & Lounge',\n",
       "  {'brunch': 'brunch is honestly amazing',\n",
       "   'service': 'pretty awesome customer service',\n",
       "   'insomnia': 'insomnia egg benny is quite impressive'}],\n",
       " ['MeNami',\n",
       "  {'udon': 'udon is pretty tasty',\n",
       "   'sauce': 'cream sauce udon is pretty decent',\n",
       "   'corn': 'strong sweet corn taste'}],\n",
       " ['GB Hand-pulled Noodles',\n",
       "  {'noodle': 'noodle are pretty decent',\n",
       "   'soup': 'soup is extremely delicious',\n",
       "   'beef': 'best beef noodle'}],\n",
       " ['Ryus Noodle Bar',\n",
       "  {'broth': 'delicious rich broth',\n",
       "   'noodle': 'best japanese noodle restaurant',\n",
       "   'pork': 'delicious pork'}],\n",
       " [\"C'est What\",\n",
       "  {'beer': 'good great craft beer selection',\n",
       "   'selection': 'selection is pretty good',\n",
       "   'service': 'excellent service'}],\n",
       " ['KINTON RAMEN',\n",
       "  {'pork': 'pork miso ramen is amazing',\n",
       "   'broth': 'best broth',\n",
       "   'kinton': 'kinton amazing'}],\n",
       " ['Kenzo Ramen',\n",
       "  {'kenzo': 'kenzo quite decent',\n",
       "   'service': 'service is excellent',\n",
       "   'broth': 'authentic broth'}],\n",
       " [\"India's Taste\",\n",
       "  {'buffet': 'ayce buffet is really awesome',\n",
       "   'naan': 'best naan bread',\n",
       "   'chicken': 'butter chicken is really delicious'}],\n",
       " ['Shawarma Empire',\n",
       "  {'shawarma': 'good authentic shawarma',\n",
       "   'chicken': 'chicken is delicious',\n",
       "   'beef': 'super yummy beef'}],\n",
       " ['Bapbo Korean Restaurant',\n",
       "  {'korean': 'excellent korean place',\n",
       "   'rice': 'incredible crispy rice',\n",
       "   'bibimbap': 'really terrific daily bibimbap special'}],\n",
       " [\"Frankie's\",\n",
       "  {'burger': 'best prepared veggie burger he',\n",
       "   'frankie': 'frankie original breakfast',\n",
       "   'brunch': 'classic brunch food'}],\n",
       " ['Factory Girl',\n",
       "  {'pizza': 'pizza is excellent',\n",
       "   'patio': 'decent patio',\n",
       "   'service': 'service is pretty good'}],\n",
       " [\"Jack Astor's Bar & Grill\",\n",
       "  {'jack': 'jack astor',\n",
       "   'service': 'excellent service',\n",
       "   'chicken': 'chicken strip'}],\n",
       " ['Joy Thai Restaurant',\n",
       "  {'thai': 'best thai restaurant',\n",
       "   'service': 'service is friendly',\n",
       "   'chicken': 'chicken is good'}],\n",
       " ['The Donlands Diner',\n",
       "  {'breakfast': 'standard breakfast', 'diner': 'diner coffee'}]]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrase_final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                       | 0/137467 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████| 137467/137467 [00:00<00:00, 3282447.91it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/7731 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      " 59%|████████████████████████████████████████████                               | 4539/7731 [00:00<00:00, 45049.78it/s]\n",
      "\n",
      "\n",
      " 85%|███████████████████████████████████████████████████████████████▌           | 6553/7731 [00:00<00:00, 32703.19it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7731/7731 [00:00<00:00, 27174.00it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/1319 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      " 60%|██████████████████████████████████████████████▍                              | 795/1319 [00:00<00:00, 7890.21it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1319/1319 [00:00<00:00, 7825.64it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/868 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  6%|████▊                                                                           | 52/868 [00:00<00:01, 506.20it/s]\n",
      "\n",
      "\n",
      " 14%|███████████▎                                                                   | 124/868 [00:00<00:01, 547.16it/s]\n",
      "\n",
      "\n",
      " 21%|████████████████▉                                                              | 186/868 [00:00<00:01, 561.46it/s]\n",
      "\n",
      "\n",
      " 29%|██████████████████████▌                                                        | 248/868 [00:00<00:01, 576.65it/s]\n",
      "\n",
      "\n",
      " 35%|███████████████████████████▉                                                   | 307/868 [00:00<00:00, 574.23it/s]\n",
      "\n",
      "\n",
      " 41%|████████████████████████████████▍                                              | 357/868 [00:00<00:00, 519.49it/s]\n",
      "\n",
      "\n",
      " 49%|██████████████████████████████████████▋                                        | 425/868 [00:00<00:00, 554.00it/s]\n",
      "\n",
      "\n",
      " 56%|████████████████████████████████████████████                                   | 484/868 [00:00<00:00, 563.11it/s]\n",
      "\n",
      "\n",
      " 62%|█████████████████████████████████████████████████                              | 539/868 [00:00<00:00, 549.52it/s]\n",
      "\n",
      "\n",
      " 69%|██████████████████████████████████████████████████████▏                        | 596/868 [00:01<00:00, 554.33it/s]\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████████████████████████████████▎                   | 651/868 [00:01<00:00, 542.04it/s]\n",
      "\n",
      "\n",
      " 81%|████████████████████████████████████████████████████████████████▏              | 705/868 [00:01<00:00, 537.03it/s]\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████████████████████████████████████████▎         | 761/868 [00:01<00:00, 540.99it/s]\n",
      "\n",
      "\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▎    | 816/868 [00:01<00:00, 537.72it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 868/868 [00:01<00:00, 550.84it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/1301 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1301/1301 [00:00<00:00, 1264902.53it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/598 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 598/598 [00:00<00:00, 22207.80it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/65074 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 65074/65074 [00:00<00:00, 3107348.14it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/3508 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 3508/3508 [00:00<00:00, 45095.34it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/783 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 783/783 [00:00<00:00, 13306.73it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/416 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      " 25%|███████████████████▏                                                          | 102/416 [00:00<00:00, 1002.67it/s]\n",
      "\n",
      "\n",
      " 48%|█████████████████████████████████████▉                                         | 200/416 [00:00<00:00, 990.46it/s]\n",
      "\n",
      "\n",
      " 72%|████████████████████████████████████████████████████████▉                      | 300/416 [00:00<00:00, 988.21it/s]\n",
      "\n",
      "\n",
      " 92%|████████████████████████████████████████████████████████████████████████▎      | 381/416 [00:00<00:00, 924.70it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 416/416 [00:00<00:00, 922.82it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/776 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 776/776 [00:00<00:00, 777539.39it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/189 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 189/189 [00:00<00:00, 23604.20it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/57100 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 57100/57100 [00:00<00:00, 3361848.96it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/2985 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 2985/2985 [00:00<00:00, 46046.33it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/885 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 885/885 [00:00<00:00, 14078.32it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/363 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      " 22%|█████████████████▊                                                              | 81/363 [00:00<00:00, 803.88it/s]\n",
      "\n",
      "\n",
      " 46%|████████████████████████████████████▏                                          | 166/363 [00:00<00:00, 813.13it/s]\n",
      "\n",
      "\n",
      " 68%|█████████████████████████████████████████████████████▉                         | 248/363 [00:00<00:00, 811.00it/s]\n",
      "\n",
      "\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▍    | 342/363 [00:00<00:00, 844.14it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 363/363 [00:00<00:00, 823.46it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/875 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 875/875 [00:00<00:00, 438472.64it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/175 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 175/175 [00:00<00:00, 24965.25it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/51835 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 51835/51835 [00:00<00:00, 3057314.49it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/2987 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 2987/2987 [00:00<00:00, 50770.10it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/777 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 777/777 [00:00<00:00, 16230.76it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/275 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      " 29%|███████████████████████▎                                                        | 80/275 [00:00<00:00, 793.96it/s]\n",
      "\n",
      "\n",
      " 59%|██████████████████████████████████████████████▊                                | 163/275 [00:00<00:00, 802.73it/s]\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████████████████████████████████████████▎          | 238/275 [00:00<00:00, 781.91it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 275/275 [00:00<00:00, 776.72it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/772 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 772/772 [00:00<00:00, 386996.86it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/373 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 373/373 [00:00<00:00, 23375.50it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/35342 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 35342/35342 [00:00<00:00, 2958429.97it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/2073 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 2073/2073 [00:00<00:00, 83141.70it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/491 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 491/491 [00:00<00:00, 19691.00it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/229 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      " 65%|██████████████████████████████████████████████████▍                           | 148/229 [00:00<00:00, 1468.87it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 229/229 [00:00<00:00, 1471.89it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/479 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 479/479 [00:00<00:00, 480639.14it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/352 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 352/352 [00:00<00:00, 23528.96it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/34028 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 34028/34028 [00:00<00:00, 1798956.05it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/1998 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 1998/1998 [00:00<00:00, 77053.11it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/578 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 578/578 [00:00<00:00, 17546.09it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/193 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      " 62%|████████████████████████████████████████████████                              | 119/193 [00:00<00:00, 1158.02it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 193/193 [00:00<00:00, 1099.36it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/571 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 571/571 [00:00<00:00, 572679.96it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/179 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 179/179 [00:00<00:00, 22436.14it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/26875 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 26875/26875 [00:00<00:00, 2984746.07it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/1438 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 1438/1438 [00:00<00:00, 90117.88it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/602 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 602/602 [00:00<00:00, 17246.36it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/160 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      " 76%|██████████████████████████████████████████████████████████▉                   | 121/160 [00:00<00:00, 1200.86it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 160/160 [00:00<00:00, 1113.84it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/593 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 593/593 [00:00<00:00, 594602.50it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/166 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 166/166 [00:00<00:00, 18494.29it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/24830 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 24830/24830 [00:00<00:00, 2766270.94it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/1359 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1359/1359 [00:00<00:00, 113375.35it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/413 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 413/413 [00:00<00:00, 24359.08it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/148 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 1595.65it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/406 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 406/406 [00:00<00:00, 406805.40it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/93 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 93/93 [00:00<00:00, 23144.08it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/15088 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15088/15088 [00:00<00:00, 3008636.43it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/797 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 797/797 [00:00<00:00, 159830.76it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/327 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 327/327 [00:00<00:00, 29808.25it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/112 [00:00<?, ?it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 2291.78it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/321 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/52 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 17380.17it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/14423 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14423/14423 [00:00<00:00, 2410329.37it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/887 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 887/887 [00:00<00:00, 176721.81it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/313 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 313/313 [00:00<00:00, 34870.83it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/99 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 99/99 [00:00<00:00, 2306.85it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/308 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 308/308 [00:00<00:00, 308980.06it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/90 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 18046.05it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/12298 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 12298/12298 [00:00<00:00, 2465421.59it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/604 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 604/604 [00:00<00:00, 201636.39it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/260 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 260/260 [00:00<00:00, 37241.96it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/88 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 88/88 [00:00<00:00, 2672.58it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/259 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 259/259 [00:00<00:00, 259637.84it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/65 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 65/65 [00:00<00:00, 21730.41it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/10116 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████| 10116/10116 [00:00<00:00, 2536289.03it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/558 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 558/558 [00:00<00:00, 186487.78it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/236 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 236/236 [00:00<00:00, 39264.41it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/73 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 73/73 [00:00<00:00, 2924.65it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/231 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 231/231 [00:00<00:00, 231679.63it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/77 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 77/77 [00:00<00:00, 19307.79it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/7729 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7729/7729 [00:00<00:00, 2583295.53it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/440 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 440/440 [00:00<00:00, 220594.52it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/245 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 245/245 [00:00<00:00, 34950.16it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/56 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 56/56 [00:00<00:00, 2807.50it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/244 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 244/244 [00:00<00:00, 244600.90it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/46 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 23056.64it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/7060 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7060/7060 [00:00<00:00, 2359128.92it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/420 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 420/420 [00:00<00:00, 210567.50it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/239 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 39866.32it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/45 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 2506.66it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/238 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 238/238 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/39 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 19545.69it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/4572 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4572/4572 [00:00<00:00, 2291903.66it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/187 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 187/187 [00:00<00:00, 187505.34it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/107 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 107/107 [00:00<00:00, 52917.17it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/29 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 3634.58it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/107 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 107/107 [00:00<00:00, 107340.48it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/12 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 11683.30it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                         | 0/1604 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1604/1604 [00:00<00:00, 1607565.98it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/85 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 85270.47it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/64 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 64/64 [00:00<00:00, 64142.28it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 4679.65it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/64 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 64/64 [00:00<00:00, 64096.34it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 13694.09it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/980 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 980/980 [00:00<00:00, 982883.29it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/52 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/43 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 43/43 [00:00<00:00, 43116.20it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 4513.24it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/43 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 43/43 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 6017.65it/s]"
     ]
    }
   ],
   "source": [
    "keyphrase_final_list = []\n",
    "for i in item_list:\n",
    "# get whole review text and the dataframe for this item\n",
    "    review_text, df_business= get_business_review(i,df)\n",
    "    # get all keyphrases and npTokenList(keyphrases before flatten --> partitioned keyphrase)\n",
    "    Extracted_list,npTokenList = get_keyphrase_list(review_text)\n",
    "    # get a noun list\n",
    "    Noun_List = get_noun_list(npTokenList,stop_words_defined)\n",
    "    # get a noun and it's score(dict_Counter(total frequency) * review_freq_counter(binary review frequency)), store in list\n",
    "    top_noun_with_score = get_score_from_freq(Noun_List,review_text,df_business)\n",
    "    # keyphrases that contrain the top nouns\n",
    "    keyphrase_list = get_keyphrase_contain_topk(top_noun_with_score,top_k ,Extracted_list)\n",
    "    # get dataframe for the keyphrases with vader score\n",
    "    df_keyphrase = evalSentences(keyphrase_list, to_df=True,columns = ['keyphrase_list', 'Vader'])\n",
    "    # get final keyphrases(one for each noun)\n",
    "    keyphrase_final = get_final_keyphrase(df_keyphrase,top_k,top_noun_with_score)\n",
    "    keyphrase_final_list.append([df_business[df_business[\"business_num_id\"]==i].name.iloc[0],keyphrase_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 118848/118848 [00:00<00:00, 119190.00it/s]\n"
     ]
    }
   ],
   "source": [
    "review_text, df_business= get_business_review(business_num_id,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 138104/138104 [00:00<00:00, 3215073.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7732/7732 [00:00<00:00, 30021.63it/s]\n"
     ]
    }
   ],
   "source": [
    "Extracted_list,npTokenList = get_keyphrase_list(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noun_List = get_noun_list(npTokenList,stop_words_defined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the score for the noun list. Normalize by --> dict_Counter(total frequency) * review_freq_counter(binary review frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 868/868 [01:09<00:00, 12.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1308/1308 [00:00<00:00, 1312790.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['thai', 1043562],\n",
       " ['pad', 320320],\n",
       " ['curry', 243569],\n",
       " ['pai', 155189],\n",
       " ['khao', 151585],\n",
       " ['get', 126208],\n",
       " ['time', 125460],\n",
       " ['wait', 96302],\n",
       " ['service', 92868],\n",
       " ['delicious', 88894],\n",
       " ['rice', 75816],\n",
       " ['soi', 75048],\n",
       " ['back', 71874],\n",
       " ['beef', 71269],\n",
       " ['chicken', 63722],\n",
       " ['try', 59125],\n",
       " ['coconut', 58695],\n",
       " ['green', 53600],\n",
       " ['table', 49855],\n",
       " ['sauce', 47232],\n",
       " ['spicy', 41055],\n",
       " ['bit', 40222],\n",
       " ['menu', 39725],\n",
       " ['toronto', 34848],\n",
       " ['busy', 33174],\n",
       " ['amazing', 32844],\n",
       " ['love', 31059],\n",
       " ['dinner', 27720],\n",
       " ['atmosphere', 27040],\n",
       " ['recommend', 26313],\n",
       " ['pretty', 26226],\n",
       " ['nice', 25702],\n",
       " ['tea', 24339],\n",
       " ['favourite', 20449],\n",
       " ['sweet', 19926],\n",
       " ['friend', 19270],\n",
       " ['reservation', 18988],\n",
       " ['spice', 18304],\n",
       " ['lunch', 18212],\n",
       " ['san', 18150],\n",
       " ['gra', 17400],\n",
       " ['everything', 17255],\n",
       " ['soup', 15642],\n",
       " ['noodle', 15105],\n",
       " ['road', 14994],\n",
       " ['pork', 14880],\n",
       " ['prow', 13696],\n",
       " ['shrimp', 13020],\n",
       " ['squash', 12954],\n",
       " ['right', 12947],\n",
       " ['line', 12900],\n",
       " ['super', 12625],\n",
       " ['worth', 12614],\n",
       " ['egg', 12028],\n",
       " ['perfect', 11200],\n",
       " ['eat', 10545],\n",
       " ['crispy', 10057],\n",
       " ['chef', 9657],\n",
       " ['level', 9548],\n",
       " ['salad', 9360],\n",
       " ['drink', 9106],\n",
       " ['thailand', 9072],\n",
       " ['bar', 8798],\n",
       " ['nuit', 8100],\n",
       " ['tasty', 8084],\n",
       " ['lot', 7910],\n",
       " ['price', 7744],\n",
       " ['feel', 7446],\n",
       " ['flavourful', 7298],\n",
       " ['loud', 7209],\n",
       " ['decor', 7052],\n",
       " ['yum', 6532],\n",
       " ['staff', 6150],\n",
       " ['fish', 6100],\n",
       " ['area', 5950],\n",
       " ['gaeng', 5848],\n",
       " ['hour', 5704],\n",
       " ['tender', 5680],\n",
       " ['group', 5607],\n",
       " ['something', 5589],\n",
       " ['spring', 5544],\n",
       " ['meat', 5124],\n",
       " ['ice', 5100],\n",
       " ['inside', 5025],\n",
       " ['appetizer', 4928],\n",
       " ['vibe', 4864],\n",
       " ['server', 4680],\n",
       " ['mango', 4368],\n",
       " ['tom', 4070],\n",
       " ['medium', 4060],\n",
       " ['way', 4002],\n",
       " ['fun', 3960],\n",
       " ['downtown', 3840],\n",
       " ['city', 3770],\n",
       " ['eating', 3770],\n",
       " ['papaya', 3750],\n",
       " ['grabong', 3630],\n",
       " ['water', 3432],\n",
       " ['tamarind', 3400],\n",
       " ['find', 3392],\n",
       " ['cool', 3240],\n",
       " ['seating', 3162],\n",
       " ['top', 3132],\n",
       " ['fan', 3016],\n",
       " ['review', 2888],\n",
       " ['creamy', 2688],\n",
       " ['thought', 2544],\n",
       " ['visit', 2430],\n",
       " ['point', 2296],\n",
       " ['street', 2288],\n",
       " ['choice', 2280],\n",
       " ['kind', 2254],\n",
       " ['star', 2072],\n",
       " ['quick', 2068],\n",
       " ['mild', 2021],\n",
       " ['ask', 1974],\n",
       " ['music', 1968],\n",
       " ['yummy', 1968],\n",
       " ['space', 1927],\n",
       " ['share', 1892],\n",
       " ['end', 1890],\n",
       " ['masaman', 1886],\n",
       " ['peanut', 1856],\n",
       " ['cannot', 1808],\n",
       " ['flavor', 1769],\n",
       " ['fast', 1764],\n",
       " ['couple', 1680],\n",
       " ['mind', 1665],\n",
       " ['everyone', 1640],\n",
       " ['party', 1632],\n",
       " ['work', 1628],\n",
       " ['milk', 1596],\n",
       " ['option', 1586],\n",
       " ['friday', 1558],\n",
       " ['seat', 1539],\n",
       " ['bite', 1530],\n",
       " ['ambience', 1521],\n",
       " ['start', 1521],\n",
       " ['half', 1517],\n",
       " ['home', 1517],\n",
       " ['dessert', 1504],\n",
       " ['lime', 1496],\n",
       " ['kick', 1480],\n",
       " ['garlic', 1480],\n",
       " ['spiciness', 1462],\n",
       " ['tofu', 1408],\n",
       " ['item', 1400],\n",
       " ['check', 1400],\n",
       " ['favorite', 1395],\n",
       " ['room', 1394],\n",
       " ['wan', 1368],\n",
       " ['style', 1365],\n",
       " ['part', 1365],\n",
       " ['unique', 1365],\n",
       " ['dining', 1365],\n",
       " ['advance', 1365],\n",
       " ['ground', 1344],\n",
       " ['saturday', 1296],\n",
       " ['ambiance', 1296],\n",
       " ['kiaw', 1190],\n",
       " ['walk', 1188],\n",
       " ['decent', 1155],\n",
       " ['jasmine', 1140],\n",
       " ['name', 1102],\n",
       " ['add', 1092],\n",
       " ['beer', 1080],\n",
       " ['basil', 1054],\n",
       " ['minute', 999],\n",
       " ['cute', 992],\n",
       " ['nothing', 992],\n",
       " ['reason', 986],\n",
       " ['look', 975],\n",
       " ['whole', 961],\n",
       " ['plate', 936],\n",
       " ['texture', 875],\n",
       " ['satay', 858],\n",
       " ['course', 858],\n",
       " ['weekday', 837],\n",
       " ['chili', 832],\n",
       " ['waitress', 816],\n",
       " ['return', 812],\n",
       " ['kitchen', 806],\n",
       " ['mai', 806],\n",
       " ['fritter', 784],\n",
       " ['stir', 783],\n",
       " ['awesome', 783],\n",
       " ['broth', 750],\n",
       " ['dip', 744],\n",
       " ['savoury', 728],\n",
       " ['hungry', 728],\n",
       " ['average', 675],\n",
       " ['sukho', 667],\n",
       " ['sausage', 665],\n",
       " ['starter', 665],\n",
       " ['conversation', 660],\n",
       " ['date', 660],\n",
       " ['sabai', 656],\n",
       " ['otherwise', 650],\n",
       " ['salty', 650],\n",
       " ['fact', 648],\n",
       " ['door', 644],\n",
       " ['foreigner', 638],\n",
       " ['basement', 625],\n",
       " ['attentive', 625],\n",
       " ['bill', 616],\n",
       " ['pricey', 600],\n",
       " ['hype', 598],\n",
       " ['evening', 594],\n",
       " ['chiang', 594],\n",
       " ['tip', 580],\n",
       " ['sangria', 580],\n",
       " ['guess', 576],\n",
       " ['refreshing', 575],\n",
       " ['cuisine', 572],\n",
       " ['mix', 572],\n",
       " ['balance', 572],\n",
       " ['family', 567],\n",
       " ['pla', 567],\n",
       " ['serving', 567],\n",
       " ['cold', 546],\n",
       " ['roll', 534],\n",
       " ['crowd', 532],\n",
       " ['variety', 529],\n",
       " ['rush', 529],\n",
       " ['panang', 528],\n",
       " ['crab', 525],\n",
       " ['book', 525],\n",
       " ['cocktail', 520],\n",
       " ['veggie', 520],\n",
       " ['min', 504],\n",
       " ['arrive', 504],\n",
       " ['kung', 500],\n",
       " ['note', 494],\n",
       " ['lineup', 493],\n",
       " ['week', 490],\n",
       " ['light', 486],\n",
       " ['yelp', 484],\n",
       " ['wow', 484],\n",
       " ['environment', 483],\n",
       " ['market', 483],\n",
       " ['crunchy', 483],\n",
       " ['sweetness', 483],\n",
       " ['number', 480],\n",
       " ['warm', 462],\n",
       " ['oyster', 450],\n",
       " ['town', 441],\n",
       " ['year', 440],\n",
       " ['afternoon', 440],\n",
       " ['moo', 437],\n",
       " ['tawt', 432],\n",
       " ['leaf', 429],\n",
       " ['dipping', 420],\n",
       " ['coriander', 420],\n",
       " ['presentation', 420],\n",
       " ['complaint', 420],\n",
       " ['tail', 408],\n",
       " ['glass', 406],\n",
       " ['noisy', 400],\n",
       " ['glad', 400],\n",
       " ['selection', 399],\n",
       " ['opinion', 399],\n",
       " ['mine', 399],\n",
       " ['ate', 399],\n",
       " ['weekend', 392],\n",
       " ['hit', 384],\n",
       " ['sai', 378],\n",
       " ['heat', 368],\n",
       " ['wednesday', 361],\n",
       " ['dark', 360],\n",
       " ['version', 360],\n",
       " ['king', 360],\n",
       " ['handle', 360],\n",
       " ['app', 357],\n",
       " ['massaman', 342],\n",
       " ['lol', 342],\n",
       " ['mouth', 342],\n",
       " ['platter', 340],\n",
       " ['potato', 336],\n",
       " ['boyfriend', 336],\n",
       " ['vegan', 330],\n",
       " ['dim', 324],\n",
       " ['interior', 324],\n",
       " ['waiter', 324],\n",
       " ['combination', 323],\n",
       " ['takeout', 323],\n",
       " ['lemongrass', 320],\n",
       " ['hand', 320],\n",
       " ['piece', 308],\n",
       " ['simple', 306],\n",
       " ['set', 304],\n",
       " ['tum', 304],\n",
       " ['stop', 289],\n",
       " ['crazy', 289],\n",
       " ['feeling', 288],\n",
       " ['classic', 288],\n",
       " ['chance', 285],\n",
       " ['stuff', 272],\n",
       " ['basa', 272],\n",
       " ['bomb', 270],\n",
       " ['life', 266],\n",
       " ['skewer', 264],\n",
       " ['sukhothai', 260],\n",
       " ['district', 256],\n",
       " ['bonus', 256],\n",
       " ['use', 256],\n",
       " ['peak', 256],\n",
       " ['trendy', 256],\n",
       " ['patio', 256],\n",
       " ['floor', 255],\n",
       " ['lighting', 255],\n",
       " ['birthday', 252],\n",
       " ['owner', 250],\n",
       " ['breast', 247],\n",
       " ['month', 242],\n",
       " ['summer', 240],\n",
       " ['tad', 240],\n",
       " ['type', 238],\n",
       " ['touch', 238],\n",
       " ['tangy', 238],\n",
       " ['hunglay', 238],\n",
       " ['gai', 234],\n",
       " ['entree', 230],\n",
       " ['cozy', 225],\n",
       " ['chill', 225],\n",
       " ['list', 225],\n",
       " ['greasy', 225],\n",
       " ['ginger', 224],\n",
       " ['som', 224],\n",
       " ['pick', 224],\n",
       " ['hipster', 221],\n",
       " ['offer', 220],\n",
       " ['value', 210],\n",
       " ['issue', 204],\n",
       " ['parking', 200],\n",
       " ['kao', 196],\n",
       " ['addition', 196],\n",
       " ['longer', 196],\n",
       " ['helpful', 196],\n",
       " ['pow', 195],\n",
       " ['section', 195],\n",
       " ['juicy', 195],\n",
       " ['phone', 195],\n",
       " ['customer', 189],\n",
       " ['hip', 182],\n",
       " ['online', 182],\n",
       " ['paste', 182],\n",
       " ['recommendation', 180],\n",
       " ['fillet', 180],\n",
       " ['oxtail', 180],\n",
       " ['bottom', 169],\n",
       " ['perfection', 169],\n",
       " ['thick', 169],\n",
       " ['absolute', 169],\n",
       " ['bunch', 169],\n",
       " ['tasting', 169],\n",
       " ['damn', 169],\n",
       " ['hope', 169],\n",
       " ['pay', 169],\n",
       " ['house', 168],\n",
       " ['care', 168],\n",
       " ['ksr', 168],\n",
       " ['thinking', 168],\n",
       " ['chilli', 160],\n",
       " ['drinking', 156],\n",
       " ['fair', 156],\n",
       " ['lack', 154],\n",
       " ['guy', 153],\n",
       " ['thursday', 144],\n",
       " ['mood', 144],\n",
       " ['dine', 144],\n",
       " ['delivery', 144],\n",
       " ['bamboo', 144],\n",
       " ['efficient', 144],\n",
       " ['problem', 144],\n",
       " ['sunday', 143],\n",
       " ['man', 143],\n",
       " ['please', 143],\n",
       " ['thamada', 143],\n",
       " ['picture', 140],\n",
       " ['fry', 132],\n",
       " ['noise', 132],\n",
       " ['bland', 132],\n",
       " ['miang', 132],\n",
       " ['turn', 130],\n",
       " ['corner', 130],\n",
       " ['morning', 121],\n",
       " ['attention', 121],\n",
       " ['ping', 121],\n",
       " ['guest', 120],\n",
       " ['trip', 120],\n",
       " ['host', 120],\n",
       " ['north', 120],\n",
       " ['cost', 117],\n",
       " ['hint', 117],\n",
       " ['oil', 110],\n",
       " ['mention', 110],\n",
       " ['understand', 110],\n",
       " ['change', 110],\n",
       " ['standard', 108],\n",
       " ['plan', 108],\n",
       " ['bartender', 104],\n",
       " ['chewy', 100],\n",
       " ['notch', 100],\n",
       " ['alcohol', 100],\n",
       " ['continue', 100],\n",
       " ['upbeat', 100],\n",
       " ['luck', 100],\n",
       " ['surprise', 99],\n",
       " ['fit', 99],\n",
       " ['joint', 96],\n",
       " ['ratio', 90],\n",
       " ['opening', 90],\n",
       " ['decoration', 90],\n",
       " ['crunch', 90],\n",
       " ['winter', 90],\n",
       " ['consistency', 90],\n",
       " ['hostess', 90],\n",
       " ['vibrant', 90],\n",
       " ['fire', 90],\n",
       " ['theatre', 90],\n",
       " ['brisket', 90],\n",
       " ['expectation', 88],\n",
       " ['resto', 88],\n",
       " ['shell', 88],\n",
       " ['rating', 84],\n",
       " ['lit', 81],\n",
       " ['glory', 81],\n",
       " ['signature', 81],\n",
       " ['multiple', 81],\n",
       " ['homemade', 81],\n",
       " ['idea', 81],\n",
       " ['take-out', 81],\n",
       " ['authenticity', 81],\n",
       " ['haha', 81],\n",
       " ['core', 81],\n",
       " ['betel', 81],\n",
       " ['anyway', 80],\n",
       " ['ton', 78],\n",
       " ['mushroom', 78],\n",
       " ['bean', 77],\n",
       " ['laap', 77],\n",
       " ['wise', 72],\n",
       " ['juice', 72],\n",
       " ['sugar', 72],\n",
       " ['job', 72],\n",
       " ['story', 72],\n",
       " ['base', 72],\n",
       " ['farang', 72],\n",
       " ['liquor', 72],\n",
       " ['container', 72],\n",
       " ['beforehand', 72],\n",
       " ['stand', 72],\n",
       " ['cream', 70],\n",
       " ['sign', 70],\n",
       " ['wine', 70],\n",
       " ['depth', 70],\n",
       " ['vegetable', 68],\n",
       " ['beat', 66],\n",
       " ['system', 64],\n",
       " ['playing', 64],\n",
       " ['form', 64],\n",
       " ['tho', 64],\n",
       " ['sweeter', 64],\n",
       " ['comfort', 64],\n",
       " ['underground', 64],\n",
       " ['sister', 64],\n",
       " ['goodness', 64],\n",
       " ['beware', 64],\n",
       " ['cause', 64],\n",
       " ['move', 63],\n",
       " ['establishment', 63],\n",
       " ['setting', 63],\n",
       " ['fall', 63],\n",
       " ['partner', 63],\n",
       " ['cucumber', 60],\n",
       " ['cabbage', 56],\n",
       " ['sip', 56],\n",
       " ['lychee', 56],\n",
       " ['company', 56],\n",
       " ['prik', 56],\n",
       " ['reading', 56],\n",
       " ['drumstick', 56],\n",
       " ['preference', 56],\n",
       " ['cuz', 56],\n",
       " ['pineapple', 56],\n",
       " ['boy', 56],\n",
       " ['compliment', 54],\n",
       " ['suko', 54],\n",
       " ['office', 54],\n",
       " ['wall', 52],\n",
       " ['mak', 50],\n",
       " ['pot', 49],\n",
       " ['mediocre', 49],\n",
       " ['holy', 49],\n",
       " ['funky', 49],\n",
       " ['tuesday', 49],\n",
       " ['buttercup', 49],\n",
       " ['omg', 49],\n",
       " ['appeal', 49],\n",
       " ['hearty', 49],\n",
       " ['request', 49],\n",
       " ['weather', 49],\n",
       " ['runny', 49],\n",
       " ['pleasant', 49],\n",
       " ['batter', 49],\n",
       " ['entrance', 49],\n",
       " ['décor', 49],\n",
       " ['richness', 49],\n",
       " ['drank', 49],\n",
       " ['background', 49],\n",
       " ['protein', 48],\n",
       " ['non', 48],\n",
       " ['deal', 48],\n",
       " ['coat', 48],\n",
       " ['effort', 48],\n",
       " ['tomato', 45],\n",
       " ['range', 42],\n",
       " ['blend', 42],\n",
       " ['delight', 42],\n",
       " ['fav', 42],\n",
       " ['staple', 42],\n",
       " ['wood', 42],\n",
       " ['case', 42],\n",
       " ['wing', 41],\n",
       " ['event', 40],\n",
       " ['pepper', 40],\n",
       " ['meet', 40],\n",
       " ['onion', 38],\n",
       " ['convenient', 36],\n",
       " ['combo', 36],\n",
       " ['flame', 36],\n",
       " ['bet', 36],\n",
       " ['trust', 36],\n",
       " ['express', 36],\n",
       " ['disappointment', 36],\n",
       " ['brick', 36],\n",
       " ['neat', 36],\n",
       " ['money', 36],\n",
       " ['gotta', 36],\n",
       " ['business', 36],\n",
       " ['relaxing', 36],\n",
       " ['tolerance', 36],\n",
       " ['shot', 36],\n",
       " ['charge', 36],\n",
       " ['soooo', 36],\n",
       " ['recall', 36],\n",
       " ['palate', 36],\n",
       " ['team', 36],\n",
       " ['wooden', 36],\n",
       " ['gang', 36],\n",
       " ['factor', 35],\n",
       " ['movie', 35],\n",
       " ['random', 30],\n",
       " ['volume', 30],\n",
       " ['ingredient', 30],\n",
       " ['explosion', 30],\n",
       " ['stomach', 30],\n",
       " ['imo', 30],\n",
       " ['hook', 30],\n",
       " ['winner', 30],\n",
       " ['cup', 30],\n",
       " ['tiff', 30],\n",
       " ['break', 30],\n",
       " ['caesar', 30],\n",
       " ['rock', 30],\n",
       " ['energy', 30],\n",
       " ['phet', 30],\n",
       " ['buzzer', 30],\n",
       " ['mark', 30],\n",
       " ['chang', 30],\n",
       " ['gravy', 28],\n",
       " ['bag', 28],\n",
       " ['fruit', 28],\n",
       " ['offering', 28],\n",
       " ['savory', 25],\n",
       " ['west', 25],\n",
       " ['deliciousness', 25],\n",
       " ['tiger', 25],\n",
       " ['asia', 25],\n",
       " ['legit', 25],\n",
       " ['nua', 25],\n",
       " ['stage', 25],\n",
       " ['orange', 25],\n",
       " ['baby', 25],\n",
       " ['graw', 25],\n",
       " ['plastic', 25],\n",
       " ['moment', 25],\n",
       " ['traffic', 25],\n",
       " ['rate', 25],\n",
       " ['beside', 25],\n",
       " ['must-try', 25],\n",
       " ['fai', 25],\n",
       " ['penang', 25],\n",
       " ['hotter', 25],\n",
       " ['island', 25],\n",
       " ['tax', 25],\n",
       " ['ppl', 25],\n",
       " ['line-up', 25],\n",
       " ['monday', 25],\n",
       " ['colourful', 25],\n",
       " ['spiciest', 25],\n",
       " ['communal', 25],\n",
       " ['key', 25],\n",
       " ['louder', 25],\n",
       " ['excuse', 25],\n",
       " ['spent', 25],\n",
       " ['layout', 25],\n",
       " ['example', 24],\n",
       " ['mistake', 24],\n",
       " ['refill', 24],\n",
       " ['occasion', 21],\n",
       " ['shake', 21],\n",
       " ['butternut', 20],\n",
       " ['chew', 20],\n",
       " ['colour', 20],\n",
       " ['relish', 20],\n",
       " ['blowing', 20],\n",
       " ['match', 20],\n",
       " ['pricing', 20],\n",
       " ['hubby', 20],\n",
       " ['alternative', 20],\n",
       " ['wave', 20],\n",
       " ['quantity', 20],\n",
       " ['soul', 20],\n",
       " ['comment', 20],\n",
       " ['temperature', 20],\n",
       " ['complex', 20],\n",
       " ['suit', 18],\n",
       " ['twist', 18],\n",
       " ['snack', 18],\n",
       " ['bench', 18],\n",
       " ['sooo', 16],\n",
       " ['venture', 16],\n",
       " ['khoa', 16],\n",
       " ['crap', 16],\n",
       " ['plah', 16],\n",
       " ['advice', 16],\n",
       " ['neighborhood', 16],\n",
       " ['mixture', 16],\n",
       " ['tai', 16],\n",
       " ['consider', 16],\n",
       " ['hidden', 16],\n",
       " ['fare', 16],\n",
       " ['comforting', 16],\n",
       " ['mess', 16],\n",
       " ['stay', 16],\n",
       " ['mor', 16],\n",
       " ['fatty', 16],\n",
       " ['counter', 16],\n",
       " ['caution', 16],\n",
       " ['superb', 16],\n",
       " ['challenge', 16],\n",
       " ['station', 16],\n",
       " ['standing', 16],\n",
       " ['building', 16],\n",
       " ['underwhelming', 16],\n",
       " ['mini', 16],\n",
       " ['majority', 16],\n",
       " ['vacation', 16],\n",
       " ['moving', 16],\n",
       " ['waitlist', 16],\n",
       " ['mushy', 16],\n",
       " ['culture', 16],\n",
       " ['design', 16],\n",
       " ['complexity', 16],\n",
       " ['intimate', 16],\n",
       " ['control', 16],\n",
       " ['cell', 16],\n",
       " ['citrus', 16],\n",
       " ['companion', 16],\n",
       " ['pop', 16],\n",
       " ['didnt', 16],\n",
       " ['chaotic', 16],\n",
       " ['skin', 16],\n",
       " ['situation', 16],\n",
       " ['mom', 16],\n",
       " ['jam', 16],\n",
       " ['scale', 16],\n",
       " ['insane', 16],\n",
       " ['royal', 15],\n",
       " ['chunk', 15],\n",
       " ['hett', 15],\n",
       " ['chair', 15],\n",
       " ['box', 15],\n",
       " ['post', 15],\n",
       " ['topping', 15],\n",
       " ['round', 15],\n",
       " ['dollar', 15],\n",
       " ['wrap', 14],\n",
       " ['diner', 12],\n",
       " ['professional', 12],\n",
       " ['yea', 12],\n",
       " ['york', 12],\n",
       " ['paper', 12],\n",
       " ['flavouring', 12],\n",
       " ['decision', 12],\n",
       " ['game', 12],\n",
       " ['comfy', 12],\n",
       " ['chive', 12],\n",
       " ['scene', 12],\n",
       " ['detail', 12],\n",
       " ['hole', 12],\n",
       " ['store', 12],\n",
       " ['weeknight', 12],\n",
       " ['complement', 12],\n",
       " ['pig', 12],\n",
       " ['stew', 12],\n",
       " ['bob', 12],\n",
       " ['travel', 12],\n",
       " ['shoot', 11],\n",
       " ['beverage', 10],\n",
       " ['patron', 10],\n",
       " ['lover', 10],\n",
       " ['buck', 10],\n",
       " ['raptor', 10],\n",
       " ['bottle', 10],\n",
       " ['memory', 10],\n",
       " ['arrangement', 10],\n",
       " ['booth', 10],\n",
       " ['shoe', 10],\n",
       " ['bucket', 10],\n",
       " ['art', 9],\n",
       " ['availability', 9],\n",
       " ['knick', 9],\n",
       " ['pleasure', 9],\n",
       " ['setup', 9],\n",
       " ['pricy', 9],\n",
       " ['prao', 9],\n",
       " ['definite', 9],\n",
       " ['standout', 9],\n",
       " ['celebration', 9],\n",
       " ['school', 9],\n",
       " ['capacity', 9],\n",
       " ['sale', 9],\n",
       " ['tang', 9],\n",
       " ['air', 9],\n",
       " ['quieter', 9],\n",
       " ['slice', 9],\n",
       " ['foodie', 9],\n",
       " ['southeast', 9],\n",
       " ['jug', 9],\n",
       " ['playlist', 9],\n",
       " ['metal', 9],\n",
       " ['dive', 9],\n",
       " ['speed', 9],\n",
       " ['substitute', 9],\n",
       " ['adelaide', 9],\n",
       " ['heaven', 9],\n",
       " ['yolk', 9],\n",
       " ['terrific', 9],\n",
       " ['drawback', 9],\n",
       " ['thirsty', 9],\n",
       " ['nobody', 9],\n",
       " ['aroma', 9],\n",
       " ['retro', 9],\n",
       " ['consideration', 9],\n",
       " ['cafe', 9],\n",
       " ['period', 9],\n",
       " ['machine', 9],\n",
       " ['relative', 9],\n",
       " ['bud', 9],\n",
       " ['support', 9],\n",
       " ['restos', 9],\n",
       " ['kitschy', 9],\n",
       " ['lazy', 9],\n",
       " ['cushion', 9],\n",
       " ['burn', 9],\n",
       " ['improvement', 9],\n",
       " ['voice', 9],\n",
       " ['guava', 9],\n",
       " ['altho', 9],\n",
       " ['marley', 9],\n",
       " ['spoon', 9],\n",
       " ['downfall', 9],\n",
       " ['fiance', 9],\n",
       " ['inexpensive', 9],\n",
       " ['milky', 9],\n",
       " ['gem', 8],\n",
       " ['win', 8],\n",
       " ['eater', 8],\n",
       " ['larb', 8],\n",
       " ['dinning', 8],\n",
       " ['suggestion', 8],\n",
       " ['gathering', 8],\n",
       " ['attempt', 6],\n",
       " ['pas', 6],\n",
       " ['component', 6],\n",
       " ['alot', 6],\n",
       " ['drinker', 6],\n",
       " ['country', 6],\n",
       " ['wedge', 6],\n",
       " ['hangout', 6],\n",
       " ['sum', 6],\n",
       " ['furniture', 6],\n",
       " ['staircase', 6],\n",
       " ['straw', 6],\n",
       " ['clump', 6],\n",
       " ['son', 6],\n",
       " ['album', 6],\n",
       " ['stool', 6],\n",
       " ['score', 6],\n",
       " ['grabang', 6],\n",
       " ['distinctive', 6],\n",
       " ['vodka', 6],\n",
       " ['mat', 5],\n",
       " ['bathroom', 5],\n",
       " ['competent', 4],\n",
       " ['november', 4],\n",
       " ['news', 4],\n",
       " ['lunchtime', 4],\n",
       " ['lounge', 4],\n",
       " ['pricer', 4],\n",
       " ['alert', 4],\n",
       " ['bass', 4],\n",
       " ['fancy', 4],\n",
       " ['sao', 4],\n",
       " ['intolerance', 4],\n",
       " ['ipa', 4],\n",
       " ['adventure', 4],\n",
       " ['yelling', 4],\n",
       " ['soupy', 4],\n",
       " ['piping', 4],\n",
       " ['existent', 4],\n",
       " ['relax', 4],\n",
       " ['dimension', 4],\n",
       " ['essence', 4],\n",
       " ['roomier', 4],\n",
       " ['garage', 4],\n",
       " ['basis', 4],\n",
       " ['expansion', 4],\n",
       " ['page', 4],\n",
       " ['opposite', 4],\n",
       " ['profile', 4],\n",
       " ['wok', 4],\n",
       " ['mustard', 4],\n",
       " ['good-looking', 4],\n",
       " ['pink', 4],\n",
       " ['height', 4],\n",
       " ['shout', 4],\n",
       " ['pace', 4],\n",
       " ['inconvenient', 4],\n",
       " ['flow', 4],\n",
       " ['park', 4],\n",
       " ['impression', 4],\n",
       " ['land', 4],\n",
       " ['diverse', 4],\n",
       " ['marketplace', 4],\n",
       " ['coconuty', 4],\n",
       " ['sleepy', 4],\n",
       " ['password', 4],\n",
       " ['sense', 4],\n",
       " ['suicide', 4],\n",
       " ['hop', 4],\n",
       " ['theme', 4],\n",
       " ['mainstream', 4],\n",
       " ['nook', 4],\n",
       " ['kid', 4],\n",
       " ['husk', 4],\n",
       " ['culinary', 4],\n",
       " ['plik', 4],\n",
       " ['village', 4],\n",
       " ['busiest', 4],\n",
       " ['neighbor', 4],\n",
       " ['imagination', 4],\n",
       " ['dare', 4],\n",
       " ['nicer', 4],\n",
       " ['reco', 4],\n",
       " ['jazz', 4],\n",
       " ['extreme', 4],\n",
       " ['ketchupy', 4],\n",
       " ['proportion', 4],\n",
       " ['neighbourhood', 4],\n",
       " ['bias', 4],\n",
       " ['watering', 4],\n",
       " ['turnover', 4],\n",
       " ['emphasis', 4],\n",
       " ['ideal', 4],\n",
       " ['length', 4],\n",
       " ['tbh', 4],\n",
       " ['recipe', 4],\n",
       " ['highway', 4],\n",
       " ['pile', 4],\n",
       " ['degree', 4],\n",
       " ['must-order', 4],\n",
       " ['display', 4],\n",
       " ['tower', 4],\n",
       " ['america', 4],\n",
       " ['border', 4],\n",
       " ['tall', 4],\n",
       " ['ranging', 4],\n",
       " ['testament', 4],\n",
       " ['countless', 4],\n",
       " ['scream', 4],\n",
       " ['twenty', 4],\n",
       " ['syrup', 4],\n",
       " ['pool', 4],\n",
       " ['cherry', 4],\n",
       " ['crush', 4],\n",
       " ['phai', 4],\n",
       " ['spinach', 4],\n",
       " ['seafood', 4],\n",
       " ['cayman', 3],\n",
       " ['filet', 3],\n",
       " ['element', 3],\n",
       " ['omelette', 3],\n",
       " ['leg', 3],\n",
       " ['layer', 3],\n",
       " ['accent', 3],\n",
       " ['napkin', 3],\n",
       " ['trinity', 3],\n",
       " ['color', 3],\n",
       " ['bae', 3],\n",
       " ['orchid', 2],\n",
       " ['womp', 2],\n",
       " ['window', 2],\n",
       " ['palette', 2],\n",
       " ['pa', 2],\n",
       " ['dig', 2],\n",
       " ['dubai', 2],\n",
       " ['ring', 2],\n",
       " ['advantage', 2],\n",
       " ['undertone', 2],\n",
       " ['floater', 2],\n",
       " ['critic', 2],\n",
       " ['pha', 2],\n",
       " ['vinegar', 2],\n",
       " ['suspect', 2],\n",
       " ['july', 2],\n",
       " ['edge', 2],\n",
       " ['kho', 2],\n",
       " ['pudding', 2],\n",
       " ['attitude', 2],\n",
       " ['contrast', 2],\n",
       " ['bkk', 2],\n",
       " ['custard', 2],\n",
       " ['disco', 2],\n",
       " ['scallion', 2],\n",
       " ['corriander', 2],\n",
       " ['inch', 2],\n",
       " ['chart', 2],\n",
       " ['concept', 2],\n",
       " ['destination', 2],\n",
       " ['waitor', 2],\n",
       " ['ramp', 1],\n",
       " ['elevator', 1],\n",
       " ['takeaway', 1],\n",
       " ['bubbletea', 1],\n",
       " ['curacao', 1],\n",
       " ['exterior', 1],\n",
       " ['disconnect', 1],\n",
       " ['process', 1],\n",
       " ['grass', 1],\n",
       " ['dundas', 1],\n",
       " ['sarn', 1],\n",
       " ['grail', 1],\n",
       " ['vacant', 1],\n",
       " ['nite', 1],\n",
       " ['sea', 1],\n",
       " ['crusty', 1],\n",
       " ['flight', 1],\n",
       " ['cleanser', 1],\n",
       " ['transit', 1],\n",
       " ['tatami', 1],\n",
       " ['check-out', 1],\n",
       " ['daythe', 1],\n",
       " ['efficientthe', 1],\n",
       " ['billsthey', 1],\n",
       " ['muchbeer', 1],\n",
       " ['lapsmy', 1],\n",
       " ['estimate', 1],\n",
       " ['lager', 1],\n",
       " ['trend', 1],\n",
       " ['parliament', 1],\n",
       " ['steet', 1],\n",
       " ['layering', 1],\n",
       " ['bar-seating', 1],\n",
       " ['duo', 1],\n",
       " ['galentine', 1],\n",
       " ['trim', 1],\n",
       " ['itthe', 1],\n",
       " ['batch', 1],\n",
       " ['icce', 1],\n",
       " ['diego', 1],\n",
       " ['ohhhh', 1],\n",
       " ['convo', 1],\n",
       " ['sui', 1],\n",
       " ['thereof', 1],\n",
       " ['rip', 1],\n",
       " ['textury', 1],\n",
       " ['experiment', 1],\n",
       " ['salada', 1],\n",
       " ['servicea', 1],\n",
       " ['decorfun', 1],\n",
       " ['warehouse', 1],\n",
       " ['cheat', 1],\n",
       " ['effy', 1],\n",
       " ['diner5', 1],\n",
       " ['regretful', 1],\n",
       " ['stint', 1],\n",
       " ['rom-com', 1],\n",
       " ...]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_word_list = get_score_from_freq(Noun_List,review_text,df_business)\n",
    "top_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['usual thai restaurant',\n",
       " 'chicken pad thai',\n",
       " 'favourite thai restaurant',\n",
       " 'traditional thai',\n",
       " 'best tasting pad thai',\n",
       " 'green curry',\n",
       " 'average thai restaurant',\n",
       " 'thai takeaway place',\n",
       " 'competent thai restaurant',\n",
       " 'curry-based broth',\n",
       " 'already delicious coconut-based curry',\n",
       " 'pad thai',\n",
       " 'red curry',\n",
       " 'main course panang curry',\n",
       " 'chopped thai chilli',\n",
       " 'thai restaurant',\n",
       " 'best thai food',\n",
       " 'thai craving',\n",
       " 'pad gra pow',\n",
       " 'green curry chicken shrimp',\n",
       " 'favourite thai place',\n",
       " 'authentic thai food',\n",
       " 'average thai food',\n",
       " 'classic pad',\n",
       " 'northern thai sweet',\n",
       " 'northern thailand',\n",
       " 'best thai restaurant',\n",
       " 'best pad thai',\n",
       " 'pad thai cannot',\n",
       " 'good thai place',\n",
       " 'thai place',\n",
       " 'typical thai dish',\n",
       " 'favourite pad thai',\n",
       " 'yellow curry sauce',\n",
       " 'good thai food',\n",
       " 'thai spot',\n",
       " 'thai style',\n",
       " 'authentic thai',\n",
       " 'especially thai cuisine',\n",
       " 'new favorite thai place',\n",
       " 'thai dish',\n",
       " 'great phad thai',\n",
       " 'massaman beef curry',\n",
       " 'classic thai-style chicken flavor',\n",
       " 'thai-styled fried egg',\n",
       " 'classic pad thai',\n",
       " 'authentic thai restaurant right',\n",
       " 'pai northern thai kitchen',\n",
       " 'delicious thai cuisine',\n",
       " 'thai chilies',\n",
       " 'favourite thai spot',\n",
       " 'northern thai sausage pork sausage',\n",
       " 'thai relish',\n",
       " 'great thai foodwow',\n",
       " 'green curry dish',\n",
       " 'fancy thai',\n",
       " 'popular thai ice tea',\n",
       " 'thai tea',\n",
       " 'thai cuisine',\n",
       " 'thai coriander',\n",
       " 'real thai food',\n",
       " 'next thai food adventure',\n",
       " 'thai ice tea',\n",
       " 'decent thai food',\n",
       " 'best thai food place',\n",
       " 'thai beer',\n",
       " 'solid thai restaurant',\n",
       " 'braised beef curry',\n",
       " 'thai food',\n",
       " 'really good thai food',\n",
       " 'golden curry',\n",
       " 'typical thai restaurant',\n",
       " 'northern thai style',\n",
       " 'tasty thai spice',\n",
       " 'go-to thai place',\n",
       " 'best pad gra',\n",
       " 'mak mak thai spicy',\n",
       " 'authentic thai experience',\n",
       " 'curry coconut soup',\n",
       " 'really solid thai food',\n",
       " 'excellent thai cuisine',\n",
       " 'great curry flavor',\n",
       " 'best thai place',\n",
       " 'great thai restaurant',\n",
       " 'authentic northern thai food',\n",
       " 'tasty thai food',\n",
       " 'northern thai dish',\n",
       " 'best thai curry',\n",
       " 'ho-hum neighborhood thai place',\n",
       " 'always pad thai',\n",
       " 'fish curry',\n",
       " 'select thai restaurant',\n",
       " 'phenomenally fragrant green curry',\n",
       " 'anymore thai place',\n",
       " 'hot beef pad',\n",
       " 'vegetable pad thai',\n",
       " 'thai experience',\n",
       " 'creamy coconut curry sauce',\n",
       " 'regular thai place',\n",
       " 'sukho thai',\n",
       " 'northern thai homemade pork',\n",
       " 'spiciest level thai spicy',\n",
       " 'delicious curry',\n",
       " 'good curry',\n",
       " 'awesome thai food',\n",
       " 'thai basil',\n",
       " 'finest thai food',\n",
       " 'great thai food',\n",
       " 'pad tai',\n",
       " 'pad gra prow',\n",
       " 'excellent thai food',\n",
       " 'decent pad thai',\n",
       " 'northern thai sausage platter appetizer',\n",
       " 'delicious delicious curry',\n",
       " 'thai express',\n",
       " 'traditional style thai',\n",
       " 'best green curry',\n",
       " 'new favourite thai restaurant',\n",
       " 'delicious thai food',\n",
       " 'northern thai sausage',\n",
       " 'fancy-ish authetic thai establishment',\n",
       " 'best thai',\n",
       " 'great overall thai restaurant',\n",
       " 'thai option',\n",
       " 'best thai food downtown',\n",
       " 'creamy golden curry',\n",
       " 'busy energetic thai place',\n",
       " 'fav thai place',\n",
       " 'sukhothai location',\n",
       " 'authentic casual thai vibe',\n",
       " 'green coconut curry',\n",
       " 'curry lovin soup fan',\n",
       " 'northern thai kitchen fun place',\n",
       " 'so-called thai placespai',\n",
       " 'popular thai restaurant',\n",
       " 'flavorful curry',\n",
       " 'good thai street food',\n",
       " 'many thai restaurant',\n",
       " 'flavourful pad thai',\n",
       " 'basically green curry',\n",
       " 'different thai restaurant',\n",
       " 'fish pad gra prow',\n",
       " 'unique thai environment',\n",
       " 'favourite thai dish',\n",
       " 'green curry sauce',\n",
       " 'curry dish',\n",
       " 'similar place sukhothai',\n",
       " 'pai northern thai',\n",
       " 'thai street food stall',\n",
       " 'watered-down curry',\n",
       " 'little green curry',\n",
       " 'milky sweet thai',\n",
       " 'good go-to thai restaurant',\n",
       " 'jamaican-thai feel',\n",
       " 'northern thai cuisine',\n",
       " 'rich coconut curry broth',\n",
       " 'authentic thai restaurant',\n",
       " 'beautiful thailand',\n",
       " 'thai land',\n",
       " 'ordered thai spicy',\n",
       " 'authdntic thai heat',\n",
       " 'really good thai',\n",
       " 'vegan dish pad pha hett',\n",
       " 'good thai restaurant',\n",
       " 'better thai restaurant',\n",
       " 'certainly cheaper thai restaurant',\n",
       " 'nice little thailand feel',\n",
       " 'delicious shrimp pad thai',\n",
       " 'green curry chicken',\n",
       " 'famous pad thai',\n",
       " 'spiked thai tea',\n",
       " 'northern thai kitchen',\n",
       " 'combine traditional thai decor',\n",
       " 'ubereats dinner pad thai',\n",
       " 'best thai joint downtown',\n",
       " 'favorite thai restaurant',\n",
       " 'traditional thai dish',\n",
       " 'amazing northern thai dish',\n",
       " 'thai laap paste',\n",
       " 'preselected curry',\n",
       " 'thai omelette',\n",
       " 'favorite thai dessert',\n",
       " 'presumably thai military men',\n",
       " 'much curry',\n",
       " 'incredible pad thai',\n",
       " 'traditional northern thai kitchen',\n",
       " 'delicious thai meal',\n",
       " 'shrimp-gaeng masaman-pad thai-thai ice',\n",
       " 'tea-thai ice tea ice',\n",
       " 'thai ice tea ice cream',\n",
       " 'best thai resto',\n",
       " 'thai chili',\n",
       " 'nuir pad thai',\n",
       " 'regularly eat thai food',\n",
       " 'red penang curry',\n",
       " 'nice thailand feel',\n",
       " 'thai street food market',\n",
       " 'consistently delicious thai place',\n",
       " 'thai papaya salad',\n",
       " 'fav thai dish',\n",
       " 'new favourite thai resto',\n",
       " 'delicious northern thai food',\n",
       " 'san road pad thai',\n",
       " 'first sukho thai',\n",
       " 'latest delicious thai restaurant',\n",
       " 'ox tail curry',\n",
       " 'original sukhothai',\n",
       " 'sukhothai pad thai',\n",
       " 'green chicken curry',\n",
       " 'strong thai flavour',\n",
       " 'ox tail ginger curry',\n",
       " 'golden curry sauce',\n",
       " 'great thai spot',\n",
       " 'new thai restaurant',\n",
       " 'green curry spiciness',\n",
       " 'really good thai restaurant',\n",
       " 'really good pad thai',\n",
       " 'fantastic northern thai restaurant',\n",
       " 'inferior ketchup-based pad thai',\n",
       " 'gaeng masaman tamarind curry',\n",
       " 'sour ginger curry',\n",
       " 'aromatic thai herb',\n",
       " 'fav thai food',\n",
       " 'proper thai restaurant',\n",
       " 'thai spicy',\n",
       " 'genuine thai flavour',\n",
       " 'saturated thai cuisine scene',\n",
       " 'far pad gra prow',\n",
       " 'fish green curry',\n",
       " 'super tender beef massaman curry',\n",
       " 'many good thai food',\n",
       " 'authentic thai pad thai',\n",
       " 'delicious pad thai',\n",
       " 'pad thai dish',\n",
       " 'real authentic thai food',\n",
       " 'good pad thai',\n",
       " 'basic asian tasting curry',\n",
       " 'simple thai food',\n",
       " 'much thai food',\n",
       " 'red curry paste batter',\n",
       " 'northern thai sausage pork',\n",
       " 'delectable coconut milk curry',\n",
       " 'real good curry',\n",
       " 'authentic thai restauraunt',\n",
       " 'masaman curry',\n",
       " 'chickenkhao pad',\n",
       " 'take-out thai place',\n",
       " 'thai phase',\n",
       " 'regular thai food',\n",
       " 'latest thai restaurant',\n",
       " 'good northern thai',\n",
       " 'great thai place',\n",
       " 'thai foodpai',\n",
       " 'usual thai expectation',\n",
       " 'normal thai restaurant',\n",
       " 'pad gra',\n",
       " 'truly authentic thai place',\n",
       " 'thick curry',\n",
       " 'vegetarian pad thai',\n",
       " 'green curry luxuriant',\n",
       " 'authentic thai food pai',\n",
       " 'favorite thai dish',\n",
       " 'pretty subpar thai option',\n",
       " 'red thai curry',\n",
       " 'really good thai place',\n",
       " 'curry fiend',\n",
       " 'authentic northern thai restaurant',\n",
       " 'pai northern thai kitchen transfer',\n",
       " 'thai hot sauce',\n",
       " 'yellow curry',\n",
       " 'sub-standard pad thai',\n",
       " 'thai family',\n",
       " 'northern thai',\n",
       " 'top thai food place',\n",
       " 'golden thai restaurant',\n",
       " 'peanut-based curry',\n",
       " 'best curry',\n",
       " 'authentic thai selection',\n",
       " 'sister restaurant sukho thai',\n",
       " 'yellow curry khao soi',\n",
       " 'north thai plate',\n",
       " 'authentic thailand style spicy',\n",
       " 'real pad thai',\n",
       " 'curry take-away',\n",
       " 'spicymy new favourite thai restaurant',\n",
       " 'upcoming thailand vacation',\n",
       " 'northern thai section',\n",
       " 'pad thai noodle',\n",
       " 'green curry thai spicy',\n",
       " 'authentic thai place',\n",
       " 'northern thai food',\n",
       " 'tasty curry sauce',\n",
       " 'solid pad thai',\n",
       " 'outstanding thai',\n",
       " 'green curry rice',\n",
       " 'panang curry curry',\n",
       " 'thai aromatics',\n",
       " 'mine thai spice',\n",
       " 'trendy thai restaurant',\n",
       " 'vegan pad thai',\n",
       " 'hipster thai resto',\n",
       " 'simplest pad',\n",
       " 'soi curry',\n",
       " 'thai milk tea',\n",
       " 'thai shack',\n",
       " 'thai choice',\n",
       " 'chef nuit pad thai',\n",
       " 'amazing pad thai',\n",
       " 'thai market',\n",
       " 'green curry vegan',\n",
       " 'heir thai ice',\n",
       " 'hands-down best thai food',\n",
       " 'typically pad thai',\n",
       " 'favorite thai spot',\n",
       " 'thai style chicken wing',\n",
       " 'gaeng masaman curry',\n",
       " 'iconic toronto thai restaurant',\n",
       " 'delicious green curry',\n",
       " 'great curry',\n",
       " 'suko thai',\n",
       " 'top thai restaurant',\n",
       " 'infamous thai',\n",
       " 'favourite thai placescozy basement ambiance',\n",
       " 'thai bucket',\n",
       " 'ugly khao pad thamada',\n",
       " 'scrumptious thai meal',\n",
       " 'thai resturants',\n",
       " 'deep curry flavour',\n",
       " 'good-looking thai dish',\n",
       " 'green red curry',\n",
       " 'classic thai comfort food',\n",
       " 'perfect thai curry',\n",
       " 'subtle street-style pad thai sauce',\n",
       " 'thai spice',\n",
       " 'good thai',\n",
       " 'thai accent',\n",
       " 'thai excellence',\n",
       " 'real thai food taste',\n",
       " 'main chicken curry dish',\n",
       " 'horrid pad thai',\n",
       " 'solid thai food',\n",
       " 'red curry dish',\n",
       " 'simply phenomenal backpacker-style northern thai food',\n",
       " 'additional green curry',\n",
       " 'authentic thai street food',\n",
       " 'bkk thai',\n",
       " 'extra curry',\n",
       " 'many pad',\n",
       " 'expensive thai food place',\n",
       " 'wrong curry dish',\n",
       " 'thai ingredient',\n",
       " 'favourite thai option',\n",
       " 'faaaavourite thai restos',\n",
       " 'following chef nuit pad thai',\n",
       " 'classic thai',\n",
       " 'fake pad thai',\n",
       " 'sweet sour curry',\n",
       " 'sour curry',\n",
       " 'red curry chicken',\n",
       " 'northern thai sausage platter',\n",
       " 'better thai',\n",
       " 'thai spicy level',\n",
       " 'excellent thai',\n",
       " 'interesting nice thai accent',\n",
       " 'high quality thai food',\n",
       " 'lively thai restaurant',\n",
       " 'oyster saucepad thai',\n",
       " 'seriously delicious pad thai',\n",
       " 'many pad thai place',\n",
       " 'thai picture',\n",
       " 'best pad thai place',\n",
       " 'americanized pad thai joint',\n",
       " 'sweet coconut curry',\n",
       " 'awesome thai food coconut water',\n",
       " 'canadian thai',\n",
       " 'thai custard',\n",
       " 'better thai experience',\n",
       " 'first thai restaurant',\n",
       " 'new curry',\n",
       " 'isan thai place downtown',\n",
       " 'pad thamada beef',\n",
       " 'pad thai chicken',\n",
       " 'mild chicken pad thai',\n",
       " 'thai milkshake',\n",
       " 'distinctive thai restaurant',\n",
       " 'southern thailand',\n",
       " 'special pad gra prow',\n",
       " 'thai resto',\n",
       " 'thai street restaurant vibe',\n",
       " 'green coconut curry fish',\n",
       " 'thai wing',\n",
       " 'red sauce pad thai',\n",
       " 'red creamy coconut curry',\n",
       " 'excellent thai food spot',\n",
       " 'open northern thai experience',\n",
       " 'thai scene',\n",
       " 'authentic thai food experience',\n",
       " 'yummy thai restaurant',\n",
       " 'many great thai place',\n",
       " 'pretty much thai food',\n",
       " 'busy northern thai haunt truly',\n",
       " 'north thailand',\n",
       " 'gaeng hunglay ox tail curry',\n",
       " 'green thai curry',\n",
       " 'extra curry sauce',\n",
       " 'golden curry dish',\n",
       " 'delicious northern thai cuisine',\n",
       " 'chef nuit chicken pad thai platter',\n",
       " 'upper-end thai restaurant',\n",
       " 'exactly scream thai',\n",
       " 'current favorite thai restaurant',\n",
       " 'proper thai place',\n",
       " 'popular thai place',\n",
       " 'amazing thai food',\n",
       " 'pop-thai place',\n",
       " 'generic thai spot',\n",
       " 'regular thai tea',\n",
       " 'frequent thai tea',\n",
       " 'authentic thai eats',\n",
       " 'ua northern thai sausage',\n",
       " 'better shrimp pad thai',\n",
       " 'khao san road sukho thai',\n",
       " 'best authentic thai food',\n",
       " 'great authentic thai food',\n",
       " 'paimy favourite thai restaurant',\n",
       " 'best thai food restaurant',\n",
       " 'great authentic thai',\n",
       " 'open thai market feel',\n",
       " 'sweet thai chili sauce',\n",
       " 'super flavourful curry',\n",
       " 'awesome thai meal',\n",
       " 'favourite curry',\n",
       " 'go-to thai restaurant',\n",
       " 'northen thai kitchen',\n",
       " 'yummy pad thai',\n",
       " 'thai style curry',\n",
       " 'special thai dessert',\n",
       " 'popular northern thai place',\n",
       " 'sour ox tail ginger curry',\n",
       " 'authentic pad thai',\n",
       " 'pad thai mild',\n",
       " 'proper thai basil',\n",
       " 'definitely true thai',\n",
       " 'pad thai dishclean',\n",
       " 'best thai meal',\n",
       " 'green curry panang curry',\n",
       " 'favourite go-to thai restaurant',\n",
       " 'thai spiciness',\n",
       " 'tried-chef nuit pad thai',\n",
       " 'gravy curry',\n",
       " 'favorite thai restaurant downtown',\n",
       " 'thai people',\n",
       " 'thai venture',\n",
       " 'regular spicy curry',\n",
       " 'itgreen curry chicken',\n",
       " 'top notch thai restaurant',\n",
       " 'real authentic thai foodthis',\n",
       " 'favorite thai place',\n",
       " 'thai sausage',\n",
       " 'new thai',\n",
       " 'flavour green curry',\n",
       " 'thai soundtrack',\n",
       " 'beautiful golden curry',\n",
       " 'classic thai dish',\n",
       " 'northern style thai food',\n",
       " 'pad gra prow ground pork',\n",
       " 'salted crab pad thai gang',\n",
       " 'green currythe wing',\n",
       " 'pad thai perfect',\n",
       " 'curry sauce is rich',\n",
       " 'thai kitchen opened couple',\n",
       " 'thai is excellent',\n",
       " 'pad thai was delicious',\n",
       " 'pad thai is amazing',\n",
       " 'curry shrimp',\n",
       " 'chef nuit pad thai was good',\n",
       " 'oad thai was really good',\n",
       " 'pad thai is great',\n",
       " 'curry is incredibly deep',\n",
       " 'curry is awesome',\n",
       " 'curry was absolutely amazing',\n",
       " 'thai food is quite delicious',\n",
       " 'thai tea was delicious',\n",
       " 'place serf pad thai',\n",
       " 'beef curry was also great',\n",
       " 'curry sauce was creamy',\n",
       " 'curry is flavourful',\n",
       " 'curry was herby',\n",
       " 'thai heat was spicy',\n",
       " 'pai thai was good overall',\n",
       " 'coconut curry was rich',\n",
       " 'curry was phenomenal',\n",
       " 'thai tea is good',\n",
       " 'pad gra pow basil was fragrant',\n",
       " 'pad thai was reasonably good',\n",
       " 'pad gra prow offered many familiar',\n",
       " 'thai was pretty darn good',\n",
       " 'curry was good',\n",
       " 'pad gra prow was tasty',\n",
       " 'felt sukhothai',\n",
       " 'green-curry is really nice',\n",
       " 'curry is dense',\n",
       " 'pad thai was prob',\n",
       " 'pad thai was good',\n",
       " 'curry was nice',\n",
       " 'curry was delicious',\n",
       " 'milky roasted thai',\n",
       " 'pad gra prow is deceptively simple',\n",
       " 'pad thai was super flavourful',\n",
       " 'craved thai',\n",
       " 'pad thai is overly',\n",
       " 'curry taste delicious',\n",
       " 'curry were flavourful',\n",
       " 'thai iced tea nice',\n",
       " 'thai was decent',\n",
       " 'pad thai was flavorful',\n",
       " 'pad thai is pretty good',\n",
       " 'pad thai was ho-hum',\n",
       " 'pad thai was simple',\n",
       " 'pad thai was rich',\n",
       " 'pad thai was spectacular',\n",
       " 'curry was sweet',\n",
       " 'pad thai tofu veggie is good',\n",
       " 'curry is sooo flavourful',\n",
       " 'pad thai is generously-portioned',\n",
       " 'thai restaurant is pad',\n",
       " 'curry is mind',\n",
       " 'curry is outstanding',\n",
       " 'thai spawned koh san',\n",
       " 'chef nuit pad thai is really good',\n",
       " 'curry chicken was creamy',\n",
       " 'curry is fragrant',\n",
       " 'home made thai hot',\n",
       " 'thai food is always pad',\n",
       " 'curry flavor was good',\n",
       " 'dish was pad',\n",
       " 'curry is cute',\n",
       " 'khao pad thamada was good',\n",
       " 'pad gra prow was good',\n",
       " 'pad thai was quite delicious',\n",
       " 'curry was fine',\n",
       " 'pad thai was perfect',\n",
       " 'pad thai is delicious',\n",
       " 'curry was flavourful',\n",
       " 'thai tea is super good',\n",
       " 'curry is delicious',\n",
       " 'panang curry good',\n",
       " 'bit thai is normally super inexpensive',\n",
       " 'curry broth was rich',\n",
       " 'pad thai was authentic',\n",
       " 'pad thai is excellent',\n",
       " 'thai food is worth',\n",
       " 'curry was creamy',\n",
       " 'pad gra prow was absolutely delicious',\n",
       " 'chef nuit pad thai was pretty good',\n",
       " 'pad thai was also great',\n",
       " 'coconut milk curry is delicious',\n",
       " 'curry was authentic',\n",
       " 'thai iced tea',\n",
       " 'water pad thai was nice',\n",
       " 'curry rice is delicious',\n",
       " 'curry was medium',\n",
       " 'curry was overly',\n",
       " 'beefthe pad thai was similar',\n",
       " 'pad thai is pretty',\n",
       " 'curry was full',\n",
       " 'pad thai was creamy',\n",
       " 'pad thai good',\n",
       " 'pad gra prao is delicious',\n",
       " 'curry was rich',\n",
       " 'oxtail curry is pretty sweet',\n",
       " 'curry soup was nice',\n",
       " 'chef nuit pad thai was tasty',\n",
       " 'curry is rich',\n",
       " 'pad thai distinctive',\n",
       " 'phai thai is also amazing',\n",
       " 'nuit pad thai is good',\n",
       " 'pad thai equal',\n",
       " 'curry flavour was unique',\n",
       " 'pad thai was light',\n",
       " 'pad gra prow was really good',\n",
       " 'curry was tasty',\n",
       " 'pad ga prow was flawless',\n",
       " 'thailand great',\n",
       " 'curry come mild',\n",
       " 'pad gra prow were excellent',\n",
       " 'curry sauce was perfectly crispy',\n",
       " 'pad thai was exceptional',\n",
       " 'pad thai is also spectacular',\n",
       " 'thai bucket is fun',\n",
       " 'curry was really good',\n",
       " 'curry is quite filling',\n",
       " 'lol thai iced tea',\n",
       " 'thai was good',\n",
       " 'curry is quite adequate',\n",
       " 'curry is nice',\n",
       " 'curry was perfect']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrase_list = get_keyphrase_contain_topk(top_word_list,top_k ,Extracted_list)\n",
    "keyphrase_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Vader score for the keyphrase list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 597/597 [00:00<00:00, 22144.98it/s]\n"
     ]
    }
   ],
   "source": [
    "df_keyphrase = evalSentences(keyphrase_list, to_df=True,columns = ['keyphrase_list', 'Vader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyphrase_list</th>\n",
       "      <th>Vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>best authentic thai food</td>\n",
       "      <td>0.8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>delicious delicious curry</td>\n",
       "      <td>0.8979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>great authentic thai food</td>\n",
       "      <td>0.8770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>great authentic thai</td>\n",
       "      <td>0.8770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>pad thai was super flavourful</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>super flavourful curry</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>truly authentic thai place</td>\n",
       "      <td>0.8347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>thai tea is super good</td>\n",
       "      <td>0.7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>authentic casual thai vibe</td>\n",
       "      <td>0.7763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>classic thai comfort food</td>\n",
       "      <td>0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>curry was absolutely amazing</td>\n",
       "      <td>0.7410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>pad thai was quite delicious</td>\n",
       "      <td>0.7386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>thai food is quite delicious</td>\n",
       "      <td>0.7386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>pad gra prow was absolutely delicious</td>\n",
       "      <td>0.7386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>oxtail curry is pretty sweet</td>\n",
       "      <td>0.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>thai was pretty darn good</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>chef nuit pad thai was pretty good</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>pad thai is pretty good</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>excellent thai food spot</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>excellent thai cuisine</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>pad thai is excellent</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>thai is excellent</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>excellent thai</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>excellent thai food</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>pad gra prow were excellent</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>amazing northern thai dish</td>\n",
       "      <td>0.7168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>phai thai is also amazing</td>\n",
       "      <td>0.7168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>amazing thai food</td>\n",
       "      <td>0.7168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>amazing pad thai</td>\n",
       "      <td>0.7168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>pad thai is amazing</td>\n",
       "      <td>0.7168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>sister restaurant sukho thai</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>peanut-based curry</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>golden thai restaurant</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>northern thai</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>thai family</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>sub-standard pad thai</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>yellow curry</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>thai hot sauce</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>pai northern thai kitchen transfer</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>curry fiend</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>red thai curry</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>green curry luxuriant</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>thick curry</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>usual thai expectation</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>chickenkhao pad</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>take-out thai place</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>thai phase</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>regular thai food</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>latest thai restaurant</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>thai foodpai</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>normal thai restaurant</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>pad gra</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>trendy thai restaurant</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>thai street food stall</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>exactly scream thai</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>inferior ketchup-based pad thai</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>wrong curry dish</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>fake pad thai</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>ugly khao pad thamada</td>\n",
       "      <td>-0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>horrid pad thai</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            keyphrase_list   Vader\n",
       "422               best authentic thai food  0.8990\n",
       "113              delicious delicious curry  0.8979\n",
       "423              great authentic thai food  0.8770\n",
       "426                   great authentic thai  0.8770\n",
       "508          pad thai was super flavourful  0.8624\n",
       "429                 super flavourful curry  0.8624\n",
       "256             truly authentic thai place  0.8347\n",
       "544                 thai tea is super good  0.7783\n",
       "129             authentic casual thai vibe  0.7763\n",
       "330              classic thai comfort food  0.7579\n",
       "480           curry was absolutely amazing  0.7410\n",
       "539           pad thai was quite delicious  0.7386\n",
       "481           thai food is quite delicious  0.7386\n",
       "553  pad gra prow was absolutely delicious  0.7386\n",
       "570           oxtail curry is pretty sweet  0.7351\n",
       "496              thai was pretty darn good  0.7269\n",
       "554     chef nuit pad thai was pretty good  0.7269\n",
       "516                pad thai is pretty good  0.7269\n",
       "393               excellent thai food spot  0.7176\n",
       "80                  excellent thai cuisine  0.7176\n",
       "550                  pad thai is excellent  0.7176\n",
       "471                      thai is excellent  0.7176\n",
       "362                         excellent thai  0.7176\n",
       "110                    excellent thai food  0.7176\n",
       "585            pad gra prow were excellent  0.7176\n",
       "177             amazing northern thai dish  0.7168\n",
       "575              phai thai is also amazing  0.7168\n",
       "413                      amazing thai food  0.7168\n",
       "307                       amazing pad thai  0.7168\n",
       "473                    pad thai is amazing  0.7168\n",
       "..                                     ...     ...\n",
       "278           sister restaurant sukho thai  0.0000\n",
       "275                     peanut-based curry  0.0000\n",
       "274                 golden thai restaurant  0.0000\n",
       "272                          northern thai  0.0000\n",
       "271                            thai family  0.0000\n",
       "270                  sub-standard pad thai  0.0000\n",
       "269                           yellow curry  0.0000\n",
       "268                         thai hot sauce  0.0000\n",
       "267     pai northern thai kitchen transfer  0.0000\n",
       "265                            curry fiend  0.0000\n",
       "263                         red thai curry  0.0000\n",
       "259                  green curry luxuriant  0.0000\n",
       "257                            thick curry  0.0000\n",
       "253                 usual thai expectation  0.0000\n",
       "245                        chickenkhao pad  0.0000\n",
       "246                    take-out thai place  0.0000\n",
       "247                             thai phase  0.0000\n",
       "248                      regular thai food  0.0000\n",
       "249                 latest thai restaurant  0.0000\n",
       "252                           thai foodpai  0.0000\n",
       "254                 normal thai restaurant  0.0000\n",
       "255                                pad gra  0.0000\n",
       "298                 trendy thai restaurant  0.0000\n",
       "148                 thai street food stall -0.2023\n",
       "409                    exactly scream thai -0.4019\n",
       "218        inferior ketchup-based pad thai -0.4019\n",
       "349                       wrong curry dish -0.4767\n",
       "355                          fake pad thai -0.4767\n",
       "324                  ugly khao pad thamada -0.5106\n",
       "339                        horrid pad thai -0.5423\n",
       "\n",
       "[597 rows x 2 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keyphrase.sort_values(\"Vader\", ascending = False, inplace = True)\n",
    "df_keyphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thai': 'best authentic thai food',\n",
       " 'pad': 'pad thai was super flavourful',\n",
       " 'curry': 'delicious curry'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = get_final_keyphrase(df_keyphrase,top_k,top_word_list)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

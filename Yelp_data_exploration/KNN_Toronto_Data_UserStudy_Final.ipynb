{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This files combines the basic structures and logic of the implementation of user study, sequence is not correct, the final version will be in another file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\programdata\\anaconda3\\lib\\site-packages (1.20.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in c:\\programdata\\anaconda3\\lib\\site-packages (from geopy) (1.50)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "import statistics as stats\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "import scipy.sparse as sparse\n",
    "import yaml\n",
    "from tkinter import *\n",
    "import tkinter\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy import distance\n",
    "from geopy import Point\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewJson = \"..\\\\data\\\\Export_CleanedReview.json\"\n",
    "#reviewJsonWithClosedRes = \"..\\\\data\\\\Export_CleanedReviewWithClosedRes.json\"\n",
    "#reviewJsonToronto = \"..\\\\data\\\\Export_TorontoData.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess using Term Frequency - CounterVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def train(matrix_train):\n",
    "    similarity = cosine_similarity(X=matrix_train, Y=None, dense_output=True)\n",
    "    return similarity\n",
    "\n",
    "def get_I_K(df, X, row_name = 'business_num_id', binary = True, shape = (121994,6000)):\n",
    "    \"\"\"\n",
    "    get the item-keyphrase matrix\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    #For each review history\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        #Get the array of frequencies for document/review i \n",
    "        arr = X[i].toarray() \n",
    "        nonzero_element = arr.nonzero()[1]  # Get nonzero element in each line, keyphrase that appears index \n",
    "        length_of_nonzero = len(nonzero_element) #number of important keyphrase that appears\n",
    "        \n",
    "        # df[row_name][i] is the item idex\n",
    "        #Get a list row index that indicates the document/review\n",
    "        rows.extend(np.array([df[row_name][i]]*length_of_nonzero)) ## Item index\n",
    "        #print(rows)\n",
    "        \n",
    "        #Get a list of column index indicating the key phrase that appears in i document/review\n",
    "        cols.extend(nonzero_element) ## Keyword Index\n",
    "        if binary:\n",
    "            #Create a bunch of 1s\n",
    "            vals.extend(np.array([1]*length_of_nonzero))\n",
    "        else:\n",
    "            #If not binary \n",
    "            vals.extend(arr[arr.nonzero()])    \n",
    "    return csr_matrix((vals, (rows, cols)), shape=shape)\n",
    "\n",
    "\n",
    "#Get a UI matrix if it's not item_similarity based or else IU\n",
    "def predict(matrix_train, k, similarity, item_similarity_en = False):\n",
    "    prediction_scores = []\n",
    "    \n",
    "    #inverse to IU matrix\n",
    "    if item_similarity_en:\n",
    "        matrix_train = matrix_train.transpose()\n",
    "        \n",
    "    #for each user or item, depends UI or IU \n",
    "    for user_index in tqdm(range(matrix_train.shape[0])):\n",
    "        # Get user u's prediction scores for all items\n",
    "        #Get prediction/similarity score for each user 1*num or user or num of items\n",
    "        vector_u = similarity[user_index]\n",
    "\n",
    "        # Get closest K neighbors excluding user u self\n",
    "        #Decending accoding to similarity score, select top k\n",
    "        similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "        \n",
    "        # Get neighbors similarity weights and ratings\n",
    "        similar_users_weights = similarity[user_index][similar_users]\n",
    "        \n",
    "        #similar_users_weights_sum = np.sum(similar_users_weights)\n",
    "        #print(similar_users_weights.shape)\n",
    "        #shape: num of res * k\n",
    "        similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "              \n",
    "        prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "        #print(prediction_scores_u)\n",
    "        \n",
    "        \n",
    "        prediction_scores.append(np.sum(prediction_scores_u, axis=0))\n",
    "        \n",
    "    res = np.array(prediction_scores)\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        res = res.transpose()\n",
    "    return res\n",
    "\n",
    "\n",
    "#Preidction score is UI or IU?\n",
    "def prediction(prediction_score, topK, matrix_Train):\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    #for each user\n",
    "    for user_index in tqdm(range(matrix_Train.shape[0])):\n",
    "        \n",
    "        #take the prediction scores for user 1 * num res\n",
    "        vector_u = prediction_score[user_index]\n",
    "        \n",
    "        #The restuarant the user rated\n",
    "        vector_train = matrix_Train[user_index]\n",
    "        \n",
    "        if len(vector_train.nonzero()[0]) > 0:\n",
    "            vector_predict = sub_routine(vector_u, vector_train, topK=topK)\n",
    "        else:\n",
    "            vector_predict = np.zeros(topK, dtype=np.float32)\n",
    "\n",
    "        prediction.append(vector_predict)\n",
    "\n",
    "    return np.vstack(prediction)\n",
    "\n",
    "#topK: the number of restuarants we are suggesting \n",
    "#if vector_train has number, then the user has visited\n",
    "def sub_routine(vector_u, vector_train, topK=500):\n",
    "\n",
    "    #index where non-zero\n",
    "    train_index = vector_train.nonzero()[1]\n",
    "    \n",
    "    vector_u = vector_u\n",
    "    \n",
    "    #get topk + num rated res prediction score descending, top index \n",
    "    candidate_index = np.argpartition(-vector_u, topK+len(train_index))[:topK+len(train_index)]\n",
    "    \n",
    "    #sort top prediction score index in range topK+len(train_index) into vector_u`\n",
    "    vector_u = candidate_index[vector_u[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "    #deleted the rated res from the topk+train_index prediction score vector for user u \n",
    "    #Delete the user rated res index from the topk+numRated index\n",
    "    vector_u = np.delete(vector_u, np.isin(vector_u, train_index).nonzero()[0])\n",
    "\n",
    "    #so we only include the top K prediction score here\n",
    "    return vector_u[:topK]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the user number that we are trying to recommend for\n",
    "#Enter the # of businesses that we want to recommend for them \n",
    "#Pass in the UI_Prediction matrix for users \n",
    "#userIndex parameter not used \n",
    "def constructResDictionary(userIndex, busIndexRange, UI_prediction):\n",
    "    #Construct the dictionary for the recommended restaurants to display \n",
    "    dictionaryToConstruct = {}\n",
    "    \n",
    "    #Loop through the number of businesses \n",
    "    for busIndex in range(busIndexRange):\n",
    "        #Get the business information for the recommended business \n",
    "        businessSeries = df[df[\"business_num_id\"] == UI_prediction[busIndex]].iloc[0]\n",
    "        #Get the business name \n",
    "        busName = businessSeries['name']\n",
    "        \n",
    "        #get the list of strings to generate the address information \n",
    "        address_generator = (str(w) for w in yaml.safe_load(businessSeries.location)['display_address'])\n",
    "        busLocation = ', '.join(address_generator)\n",
    "        bus_Price = businessSeries.price\n",
    "        busStars = businessSeries.business_stars\n",
    "        busReviewCount = businessSeries.review_count_y \n",
    "        #category_generator = (str(s) for s in [cateDict['title'] for cateDict in yaml.safe_load(businessSeries.categories)])\n",
    "        #busCategories = [cateDict['title'] for cateDict in yaml.safe_load(businessSeries.categories)]\n",
    "        #busCategories = ', '.join(category_generator)\n",
    "        busCategories = businessSeries.categories\n",
    "        #Now add the restaurant to the dictionary\n",
    "        dictionaryToConstruct[busName] = {'Address': busLocation,\\\n",
    "                                'Price': bus_Price,\\\n",
    "                                 'Star': busStars, \\\n",
    "                                 'Review Count': busReviewCount, \\\n",
    "                                 'Category': busCategories}\n",
    "    return dictionaryToConstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_three_popularity_matrix(df_original,rtrain):\n",
    "    # get the list of popular items by ranking the number of reviews\n",
    "    numUsers = rtrain.shape[0]\n",
    "    numItems = rtrain.shape[1]\n",
    "    \n",
    "    dff_popular = df_original.copy()\n",
    "    dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "    popular_list_num_of_reviews = dff_popular[\"business_num_id\"].tolist()\n",
    "    \n",
    "    # get the list of popular items by ranking average rating score\n",
    "    dff_popular_rating = df_original.copy()\n",
    "    dff_popular_rating = dff_popular_rating.sort_values(by=[\"business_stars\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "    popular_list_avg_stars = dff_popular_rating[\"business_num_id\"].tolist()\n",
    "    \n",
    "    lst_temp = []\n",
    "    for item in tqdm(range(numItems)):\n",
    "        numOfUsersRated = len(rtrain.toarray()[:, item].nonzero()[0])\n",
    "        if numOfUsersRated <= 50:\n",
    "            lst_temp.append(item)\n",
    "    popular_list_avg_stars = [x for x in popular_list_avg_stars if x not in lst_temp]\n",
    "    \n",
    "    # get the popularity items by using the percentage liked method(number of liked items / total items)\n",
    "    predictionMatrix = np.zeros((numUsers , numItems))\n",
    "\n",
    "    # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "    vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "    rtrain_array = rtrain.toarray()\n",
    "    # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "    itemPopularity = np.zeros((numItems))\n",
    "    for item in range(numItems):\n",
    "        numOfUsersRated = len(rtrain_array[:, item].nonzero()[0])\n",
    "        numOfUsersLiked = len(vf(rtrain_array[:, item]).nonzero()[0])\n",
    "#         if numOfUsersRated == 0:\n",
    "        # set a threshold to filter out restaurants with very few reviews\n",
    "        if numOfUsersRated <= 30:\n",
    "            itemPopularity[item] = 0\n",
    "        else:\n",
    "            itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "    popular_list_liked_ratio = itemPopularity.argsort()\n",
    "    \n",
    "    return np.asarray(popular_list_num_of_reviews),np.asarray(popular_list_avg_stars),popular_list_liked_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either a list or an array\n",
    "def geographical_dist(prediction_matrix,intersection,user_id, bus_indexRange):\n",
    "    lst = []\n",
    "    length = 0\n",
    "    #if the prediction matrix is a list of items for an user \n",
    "    print(type(prediction_matrix))\n",
    "    if isinstance(prediction_matrix, list):\n",
    "        length = len(prediction_matrix)\n",
    "    #loop through the prediction matrix for the user, if passed in a prediction matrix \n",
    "    else:\n",
    "        length = prediction_matrix[user_id].shape[0]\n",
    "        #length = prediction_matrix.shape[0]\n",
    "    for j in range(length):\n",
    "        if isinstance(prediction_matrix, list):\n",
    "            coordinateDict = yaml.safe_load(df_location[df_location[\"business_num_id\"] == prediction_matrix[j]].iloc[0].coordinates)\n",
    "        else:    \n",
    "            coordinateDict = yaml.safe_load(df_location[df_location[\"business_num_id\"] == prediction_matrix[user_id][j]].iloc[0].coordinates)\n",
    "        test_point = Point(coordinateDict['latitude'],coordinateDict['longitude'])\n",
    "        \n",
    "        #Get the distance with the test point\n",
    "        result = distance.distance(intersection,test_point).kilometers\n",
    "        if result<=0.6:\n",
    "            #append the jth item if the condition matches\n",
    "            if isinstance(prediction_matrix, list):\n",
    "                lst.append(prediction_matrix[j])\n",
    "            else:\n",
    "                lst.append(prediction_matrix[user_id][j])\n",
    "        lst = lst[0:bus_indexRange]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiListbox_Initialize(Frame):\n",
    "    \n",
    "    def __init__(self, master, lists,list1Res,list2Res,list3Res):\n",
    "        Frame.__init__(self, master)\n",
    "        self.lists = []\n",
    "        #self.entries = []\n",
    "        #self.fields = 'Like', 'Dislike'\n",
    "        self.dropDownTextBox = 'Rank1','Score1', 'Rank2','Score2','Rank3','Score3'\n",
    "        #Var for checkbox\n",
    "        #self.var = IntVar()\n",
    "        self.var = []\n",
    "        self.listNames = []\n",
    "        self.responseDict = {}\n",
    "        #self.options = [\"Jan\", \"Feb\", \"Mar\"] #etc\n",
    "        #No 0s or else you won't choose it as liked \n",
    "        self.scores = [5, 4, 3, 2, 1]\n",
    "        #stores the list of restaurants for list 1-3\n",
    "        self.list1Name = list1Res\n",
    "        self.list2Name = list2Res\n",
    "        self.list3Name = list3Res\n",
    "        #To get response from dropdowns \n",
    "        self.rankVar = []\n",
    "        self.scoreVar = []\n",
    "        \n",
    "        #list count 0,1,2\n",
    "        listCount = 0 \n",
    "        #Loop through the lists, l is the list label and widthW is the width \n",
    "        for l,widthW in lists:\n",
    "            \n",
    "            frame = Frame(self); \n",
    "            frame.pack(side=LEFT, expand=YES, fill=BOTH)\n",
    "            \n",
    "            Label(frame, text=l, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "            \n",
    "            #store the list names \n",
    "            self.listNames.append(l)\n",
    "            \n",
    "            lb = Listbox(frame, width=widthW, borderwidth=0, selectborderwidth=0,\n",
    "                 relief=FLAT, exportselection=FALSE)\n",
    "            lb.pack(expand=YES, fill=BOTH)\n",
    "            #lb.pack(fill=X,expand=1)\n",
    "            #lb.pack\n",
    "            self.lists.append(lb)\n",
    "            \n",
    "            #lb.bind('<B1-Motion>', lambda e, s=self: s._select(e.y))\n",
    "            #lb.bind('<Button-1>', lambda e, s=self: s._select(e.y))\n",
    "            \n",
    "            #lb.bind('<Leave>', lambda e: 'break')\n",
    "            \n",
    "            #lb.bind('<B2-Motion>', lambda e, s=self: s._b2motion(e.x, e.y))\n",
    "            #lb.bind('<Button-2>', lambda e, s=self: s._button2(e.x, e.y))\n",
    "             \n",
    "            for fieldText in self.dropDownTextBox:\n",
    "\n",
    "                if('Rank' in fieldText):\n",
    "                    lab = Label(frame, text=fieldText, borderwidth=0, relief=RAISED)\n",
    "                    lab.pack(side=TOP,fill=BOTH)\n",
    "            \n",
    "                    #Get the current list number \n",
    "                    if listCount+1 == 1:\n",
    "                        currentOptions = self.list1Name\n",
    "                    elif listCount+1 == 2:\n",
    "                        currentOptions = self.list2Name\n",
    "                    elif listCount+1 == 3:\n",
    "                        currentOptions = self.list3Name\n",
    "                        \n",
    "                    variable = StringVar(master)\n",
    "                    variable.set(currentOptions[0]) # default value\n",
    "\n",
    "                    #row = Frame(self)\n",
    "                    #lab = Label(frame, width=15, text=fieldText, anchor='center')\n",
    "                    drowDwn = OptionMenu(frame, variable, *currentOptions)\n",
    "                    \n",
    "                    #Append the variable set from dropdown \n",
    "                    self.rankVar.append(variable)\n",
    "                    \n",
    "                    #lab.pack(side=LEFT,fill=X)\n",
    " \n",
    "                    drowDwn.pack(side=TOP)\n",
    "\n",
    "\n",
    "                elif('Score' in fieldText ):\n",
    "                    variable = StringVar(master)\n",
    "                    variable.set(self.scores[0]) # default value\n",
    "\n",
    "                    #row = Frame(self)\n",
    "                    lab = Label(frame, width=15, text=fieldText, anchor='center')\n",
    "                    drowDwn = OptionMenu(frame, variable, *self.scores)\n",
    "                    \n",
    "                    #Append te varaible set from dropdown \n",
    "                    self.scoreVar.append(variable)\n",
    "\n",
    "                    #lab.pack(side=RIGHT, fill=X)\n",
    "                    drowDwn.pack(side=TOP)\n",
    "            \n",
    "            listCount += 1\n",
    "            \n",
    "        #Set the submit button  \n",
    "        b1 = Button(master, text='Submit', command=self.fetch)\n",
    "        b1.pack(side=BOTTOM, padx=5, pady=5)\n",
    "\n",
    "        #pakcing the frame\n",
    "        #frame = Frame(self); frame.pack(side=LEFT, fill=Y)\n",
    "        \n",
    "        #packing the label\n",
    "        #Label(frame, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "\n",
    "    def _select(self, y):\n",
    "        row = self.lists[0].nearest(y)\n",
    "        self.selection_clear(0, END)\n",
    "        self.selection_set(row)\n",
    "        return 'break'\n",
    "\n",
    "    def _button2(self, x, y):\n",
    "        for l in self.lists: l.scan_mark(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _b2motion(self, x, y):\n",
    "        for l in self.lists: l.scan_dragto(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _scroll(self, *args):\n",
    "        for l in self.lists:\n",
    "            apply(l.yview, args)\n",
    "\n",
    "    def curselection(self):\n",
    "        return self.lists[0].curselection()\n",
    "\n",
    "    def delete(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.delete(first, last)\n",
    "\n",
    "#     def get(self, first, last=None):\n",
    "#         result = []\n",
    "#         for l in self.lists:\n",
    "#             result.append(l.get(first,last))\n",
    "#         if last: return apply(map, [None] + result)\n",
    "#         return result\n",
    "\n",
    "    def index(self, index):\n",
    "        self.lists[0].index(index)\n",
    "\n",
    "    def insert(self, index, *elements):\n",
    "        #Loop through the elements \n",
    "        for element in elements:\n",
    "            i = 0\n",
    "            for l in self.lists:\n",
    "                l.insert(index, element[i])\n",
    "                i = i + 1\n",
    "\n",
    "    def size(self):\n",
    "        return self.lists[0].size()\n",
    "\n",
    "    def see(self, index):\n",
    "        for l in self.lists:\n",
    "            l.see(index)\n",
    "\n",
    "    def selection_anchor(self, index):\n",
    "        for l in self.lists:\n",
    "            l.selection_anchor(index)\n",
    "\n",
    "    def selection_clear(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_clear(first, last)\n",
    "\n",
    "    def selection_includes(self, index):\n",
    "        return self.lists[0].selection_includes(index)\n",
    "\n",
    "    def selection_set(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_set(first, last)\n",
    "            \n",
    "    def fetch(self):\n",
    "        localDict = {}\n",
    "        localRankList = list(map((lambda var: var.get()), self.rankVar))\n",
    "        localScoreList = list(map((lambda var: var.get()), self.scoreVar))\n",
    "        \n",
    "        #lop through each selected restaurant and score, construct the dictionary \n",
    "        for count in range(len(localRankList)):\n",
    "            localDict[localRankList[count]] = int(localScoreList[count])\n",
    "            \n",
    "        print('Your selected restaurants:', localRankList)\n",
    "        print('Your scores given to the restaurants', localScoreList)\n",
    "        print('Your final choice is :', localDict)\n",
    "         \n",
    "        self.responseDict = localDict.copy()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiListbox_entries(Frame):\n",
    "    \n",
    "    def __init__(self, master, lists):\n",
    "        Frame.__init__(self, master)\n",
    "        self.lists = []\n",
    "        self.entries = []\n",
    "        self.fields = 'Like', 'Dislike'\n",
    "        #Var for checkbox\n",
    "        #self.var = IntVar()\n",
    "        self.var = []\n",
    "        self.listNames = []\n",
    "        self.responseDict = {}\n",
    "        \n",
    "        #Loop through the lists, l is the list label and widthW is the width \n",
    "        for l,widthW in lists:\n",
    "            \n",
    "            frame = Frame(self); frame.pack(side=LEFT, expand=YES, fill=BOTH)\n",
    "            \n",
    "            Label(frame, text=l, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "            \n",
    "            #store the list names \n",
    "            self.listNames.append(l)\n",
    "            \n",
    "            lb = Listbox(frame, width=widthW, borderwidth=0, selectborderwidth=0,\n",
    "                 relief=FLAT, exportselection=FALSE)\n",
    "            lb.pack(expand=YES, fill=BOTH)\n",
    "            \n",
    "            self.lists.append(lb)\n",
    "            \n",
    "            lb.bind('<B1-Motion>', lambda e, s=self: s._select(e.y))\n",
    "            lb.bind('<Button-1>', lambda e, s=self: s._select(e.y))\n",
    "            \n",
    "            lb.bind('<Leave>', lambda e: 'break')\n",
    "            \n",
    "            lb.bind('<B2-Motion>', lambda e, s=self: s._b2motion(e.x, e.y))\n",
    "            lb.bind('<Button-2>', lambda e, s=self: s._button2(e.x, e.y))\n",
    "             \n",
    "             #loop through the fields to \n",
    "            for field in self.fields:\n",
    "                #row = Frame(self)\n",
    "                lab = Label(frame, width=15, text=field, anchor='w')\n",
    "                ent = Entry(frame)\n",
    "                #row.pack(side=BOTTOM, fill=Y, padx=5, pady=5) #=BOTTOM\n",
    "                lab.pack()\n",
    "                #ent.pack(side=RIGHT, expand=YES, fill=Y)\n",
    "                ent.pack(side=TOP, fill=X)\n",
    "                self.entries.append((field, ent))\n",
    "            \n",
    "            #localVar = IntVar()\n",
    "            \n",
    "            #self.var.append(localVar)\n",
    "            \n",
    "            #Checkbox \n",
    "            #c = Checkbutton(frame, text=\"Liked\", variable=localVar, command=self.cb(count))\n",
    "            #c = Checkbutton(frame, text=\"Liked\", variable=localVar)\n",
    "            #c.pack()\n",
    "            \n",
    "            lab = Label(frame, width=15, text='List rating', anchor='w')\n",
    "            ent = Entry(frame)\n",
    "            #row.pack(side=BOTTOM, fill=Y, padx=5, pady=5) #=BOTTOM\n",
    "            lab.pack()\n",
    "            #ent.pack(side=RIGHT, expand=YES, fill=Y)\n",
    "            ent.pack(side=TOP, fill=X)\n",
    "            self.var.append((field, ent))\n",
    "                \n",
    "        #Set the submit button \n",
    "        #master.bind('<Button-1>', (lambda event, e=self.entries: fetch(e)))   \n",
    "        #b1 = Button(master, text='Submit', command=(lambda e=self.entries: self.fetch(e)))\n",
    "        b1 = Button(master, text='Submit', command=self.fetchDict)\n",
    "        b1.pack(side=BOTTOM, padx=5, pady=5)\n",
    "        #b2 = Button(root, text='Quit', command=root.quit)\n",
    "        #b2.pack(side=LEFT, padx=5, pady=5)\n",
    "            \n",
    "        #pakcing the frame\n",
    "        frame = Frame(self); frame.pack(side=LEFT, fill=Y)\n",
    "        \n",
    "        #packing the label\n",
    "        Label(frame, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "        #Setting a scrollbar \n",
    "#         sb = Scrollbar(frame, orient=VERTICAL, command=self._scroll)\n",
    "#         sb.pack(expand=YES, fill=Y)\n",
    "#         self.lists[0]['yscrollcommand']=sb.set\n",
    "\n",
    "    def _select(self, y):\n",
    "        row = self.lists[0].nearest(y)\n",
    "        self.selection_clear(0, END)\n",
    "        self.selection_set(row)\n",
    "        return 'break'\n",
    "    \n",
    "    #For checkbox \n",
    "    def cb(self, index):\n",
    "        print (\"variable is\", self.var[index].get())\n",
    "\n",
    "    def _button2(self, x, y):\n",
    "        for l in self.lists: l.scan_mark(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _b2motion(self, x, y):\n",
    "        for l in self.lists: l.scan_dragto(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _scroll(self, *args):\n",
    "        for l in self.lists:\n",
    "            apply(l.yview, args)\n",
    "\n",
    "    def curselection(self):\n",
    "        return self.lists[0].curselection()\n",
    "\n",
    "    def delete(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.delete(first, last)\n",
    "\n",
    "#     def get(self, first, last=None):\n",
    "#         result = []\n",
    "#         for l in self.lists:\n",
    "#             result.append(l.get(first,last))\n",
    "#         if last: return apply(map, [None] + result)\n",
    "#         return result\n",
    "\n",
    "    def index(self, index):\n",
    "        self.lists[0].index(index)\n",
    "\n",
    "    def insert(self, index, *elements):\n",
    "        #Loop through the elements \n",
    "        for element in elements:\n",
    "            i = 0\n",
    "            for l in self.lists:\n",
    "                l.insert(index, element[i])\n",
    "                i = i + 1\n",
    "\n",
    "    def size(self):\n",
    "        return self.lists[0].size()\n",
    "\n",
    "    def see(self, index):\n",
    "        for l in self.lists:\n",
    "            l.see(index)\n",
    "\n",
    "    def selection_anchor(self, index):\n",
    "        for l in self.lists:\n",
    "            l.selection_anchor(index)\n",
    "\n",
    "    def selection_clear(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_clear(first, last)\n",
    "\n",
    "    def selection_includes(self, index):\n",
    "        return self.lists[0].selection_includes(index)\n",
    "\n",
    "    def selection_set(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_set(first, last)\n",
    "            \n",
    "    def fetch(self,entries):\n",
    "        count = 1\n",
    "        \n",
    "        for entry in entries:\n",
    "            if count <= 2:\n",
    "                listCount = 1\n",
    "            elif count <= 4:\n",
    "                listCount = 2\n",
    "            elif count <= 6:\n",
    "                listCount = 3\n",
    "            elif count <= 8:\n",
    "                listCount = 4\n",
    "            elif count <= 10:\n",
    "                listCount = 5             \n",
    "            #print on odd number counts\n",
    "            if count %2 != 0:\n",
    "                print('list:', listCount)\n",
    "            #index 0 is the field \n",
    "            #index 1 is the entry data \n",
    "            field = entry[0]\n",
    "            text  = entry[1].get()\n",
    "            print('%s: \"%s\"' % (field, text))\n",
    "            \n",
    "            count =count + 1\n",
    "            \n",
    "        print(list(map((lambda var: var.get()), self.var)))\n",
    "   \n",
    "    #This function returns a dictionary of the results\n",
    "    def fetchDict(self):\n",
    "        responseDict = {}\n",
    "        count = 1\n",
    "        \n",
    "        #likeResult = list(map((lambda var: var.get()), self.var))\n",
    "        \n",
    "        for entry in self.entries:\n",
    "            tempDict = {}\n",
    "            \n",
    "            field = entry[0]\n",
    "            text  = entry[1].get()\n",
    "            # like:\"text content\"\n",
    "            tempDict[field] = text\n",
    "            \n",
    "            if count <= 2:\n",
    "                listCount = 1\n",
    "            elif count <= 4:\n",
    "                listCount = 2\n",
    "            elif count <= 6:\n",
    "                listCount = 3\n",
    "            elif count <= 8:\n",
    "                listCount = 4\n",
    "            elif count <= 10:\n",
    "                listCount = 5      \n",
    "                \n",
    "            #update the dictionary with corresponding listname :  \n",
    "            try:\n",
    "                responseDict[self.listNames[listCount-1]].update(tempDict) \n",
    "            except:\n",
    "                responseDict[self.listNames[listCount-1]] = tempDict \n",
    "            \n",
    "            if count %2 != 0:\n",
    "                #print on odd number counts\n",
    "                print('list:', listCount)\n",
    "                #Get the hit indicator and update the dictionary \n",
    "                ListRating = self.var[listCount-1][1].get()\n",
    "                tempRateDict = {'listRating': ListRating}\n",
    "                responseDict[self.listNames[listCount-1]].update(tempRateDict)\n",
    "            \n",
    "            #Print the current the field and entry text\n",
    "            print('%s: \"%s\", list rating: %s' % (field, text,ListRating))\n",
    "           \n",
    "            count =count + 1\n",
    "        \n",
    "        #print the hit list\n",
    "        #print(list(map((lambda var: var.get()), self.var)))\n",
    "        \n",
    "        self.responseDict = responseDict.copy()\n",
    "        \n",
    "        \n",
    "    #Make the entry form \n",
    "    def makeform(root, fields):\n",
    "        #For each field, like \n",
    "        for field in slef.fields:\n",
    "            row = Frame(master)\n",
    "            lab = Label(row, width=15, text=field, anchor='w')\n",
    "            ent = Entry(row)\n",
    "            row.pack(side=TOP, fill=X, padx=5, pady=5)\n",
    "            lab.pack(side=LEFT)\n",
    "            ent.pack(side=RIGHT, expand=YES, fill=X)\n",
    "            self.entries.append((field, ent))\n",
    "            \n",
    "        self.entries =  entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get original dataframe out of the review datastet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\\\data\\\\userStudy\\\\dfWhole.csv') \n",
    "rtrain = load_npz('..\\\\data\\\\userStudy\\\\Rtrain.npz').tocsr()\n",
    "rtrain_implicit = load_npz('..\\\\data\\\\userStudy\\\\Rtrain_implicit.npz').tocsr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store similarity matrices\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\UU_explicit.npy\",UU_similarity_explicit)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\UU_implicit.npy\",UU_similarity_implicit)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\II_usingIU.npy\",II_similarity_usingUI)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\II_usingIK.npy\", II_similarity_usingIK)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\II_usingIC.npy\",II_similarity_usingIC)\n",
    "\n",
    "UU_similarity_implicit = np.load('..\\\\data\\\\userStudy\\\\UU_implicit.npy')\n",
    "II_similarity_usingIK = np.load('..\\\\data\\\\userStudy\\\\II_usingIK.npy')\n",
    "II_similarity_usingIC = np.load('..\\\\data\\\\userStudy\\\\II_usingIC.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial User Input Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Popularity Metrics\n",
    "#### get the popular items in three ways\n",
    "1. avg stars\n",
    "2. number of reviews\n",
    "3. percentage liked\n",
    "\n",
    "The small analysis and the map are in the Analyse_3_ways_of_popularities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of reviews popularity list, redundent with the output of the next method\n",
    "dff_popular = df.copy()\n",
    "dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "#Get the list of restaurants accoridng to their popularity level\n",
    "popular_list = dff_popular[\"business_num_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3998/3998 [03:52<00:00, 17.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# get number of users and number of items\n",
    "numUsers = rtrain.shape[0]\n",
    "numItems = rtrain.shape[1]\n",
    "\n",
    "# get the 1d array of avg. stars, number of reviews and percentage liked ratio for the three popular metric\n",
    "popular_list_num_of_reviews,popular_list_avg_stars,popular_list_liked_ratio = get_three_popularity_matrix(df,rtrain)\n",
    "\n",
    "# transfer to a matrix(list * number of users)\n",
    "matrix_popular_list_num_of_reviews = np.tile(popular_list_num_of_reviews,(numUsers+1,1))\n",
    "#for propos, when taking in user data\n",
    "matrix_popular_list_avg_stars = np.tile(popular_list_avg_stars,(numUsers+1,1))\n",
    "#for recommendation\n",
    "matrix_popular_list_liked_ratio = np.tile(popular_list_liked_ratio,(numUsers+1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend 3 lists for three locations by using \"popular_list_liked_ratio\" method\n",
    "\n",
    "Note that the input of the geographical_dist method can only be list or n-d array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# get a copy of df\n",
    "df_location = df.copy()\n",
    "\n",
    "# three locations for user input\n",
    "yonge_and_finch = Point(\"43.779824, -79.415665\")\n",
    "bloor_and_bathurst = Point(\"43.665194,-79.411208\")\n",
    "queen_and_spadina = Point(\"43.648772,-79.396259\")\n",
    "\n",
    "# three locations for user recommendation\n",
    "bloor_and_yonge = Point(\"43.670409,-79.386814\")\n",
    "dundas_and_yonge = Point(\"43.6561,-79.3802\")\n",
    "spadina_and_dundas = Point(\"43.653004,-79.398082\")\n",
    "\n",
    "# list of percentage liked ratio (transfer the format in order to feed in to the geographical_dist method)\n",
    "list_popular_liked_ratio = popular_list_liked_ratio.tolist()\n",
    "\n",
    "# popularity list for input does not need to input the user_id\n",
    "# put user_id as 0 here but it does not matter\n",
    "# bus_indexRange = 15, gives a list of 15 restaurants per location\n",
    "bus_indexRange = 15\n",
    "yonge_and_finch_list = geographical_dist(list_popular_liked_ratio,yonge_and_finch,0, bus_indexRange)\n",
    "bloor_and_bathurst_list = geographical_dist(list_popular_liked_ratio,bloor_and_bathurst,0, bus_indexRange)\n",
    "queen_and_spadina_list = geographical_dist(list_popular_liked_ratio,queen_and_spadina,0, bus_indexRange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of restaurants for user demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# df_location_yonge_and_finch=df_location[df_location[\"business_num_id\"].isin(yonge_and_finch_list)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\", \"price\", \"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})\n",
    "# df_location_yonge_and_finch.head(2)\n",
    "# df_location_bloor_and_bathurst_list=df_location[df_location[\"business_num_id\"].isin(bloor_and_bathurst_list)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\",\"price\",\"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})\n",
    "# df_location_bloor_and_bathurst_list.head(2)\n",
    "# df_location_queen_and_spadina_list=df_location[df_location[\"business_num_id\"].isin(queen_and_spadina_list)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\",\"price\",\"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})\n",
    "# df_location_queen_and_spadina_list.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the dictionary to be used for UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the dictionary to be used for UI \n",
    "#0 is hard coded, not used for now \n",
    "dict1_yongeFinch = constructResDictionary(0, bus_indexRange, yonge_and_finch_list)\n",
    "dict2_bloorBathurst = constructResDictionary(0, bus_indexRange, bloor_and_bathurst_list)\n",
    "dict3_queenSpadina = constructResDictionary(0, bus_indexRange, queen_and_spadina_list)\n",
    "\n",
    "\n",
    "#These construct the restaurant name : business id dictionary for initial user setting\n",
    "RestaurantBusId = {}\n",
    "\n",
    "# yonge_and_finch_list\n",
    "# bloor_and_bathurst_list\n",
    "# queen_and_spadina_list\n",
    "restYF = list(dict1_yongeFinch.keys())\n",
    "restBB = list(dict2_bloorBathurst.keys())\n",
    "restQS = list(dict3_queenSpadina.keys())\n",
    "\n",
    "#loop through all items\n",
    "for count in range(len(yonge_and_finch_list)):\n",
    "    RestaurantBusId[restYF[count]] = yonge_and_finch_list[count]\n",
    "    RestaurantBusId[restBB[count]] = bloor_and_bathurst_list[count]\n",
    "    RestaurantBusId[restQS[count]] = queen_and_spadina_list[count]\n",
    "\n",
    "#RestaurantBusId\n",
    "\n",
    "#Validation \n",
    "#Get the business information for the recommended business \n",
    "# businessSeries = df[df[\"business_num_id\"] == 1904].iloc[0]\n",
    "# #Get the business name \n",
    "# businessSeries['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial user setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected restaurants: ['OneZo Tapioca', 'Pastel Creperies & Dessert House', 'Cafe Vite', 'MaMa Chef Korean Restaurant', \"The Burger's Priest\", \"Yogurty's Froyo\", 'Barre3 Toronto - King Street West', 'UNIUN', 'The Fifth & Terrace']\n",
      "Your scores given to the restaurants ['5', '4', '3', '5', '4', '3', '5', '4', '4']\n",
      "Your final choice is : {'OneZo Tapioca': 5, 'Pastel Creperies & Dessert House': 4, 'Cafe Vite': 3, 'MaMa Chef Korean Restaurant': 5, \"The Burger's Priest\": 4, \"Yogurty's Froyo\": 3, 'Barre3 Toronto - King Street West': 5, 'UNIUN': 4, 'The Fifth & Terrace': 4}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Initiate a frame or master? \n",
    "    tk = Tk()\n",
    "    Label(tk, text='List of restaurants from 3 locations - choose 3 each').pack()\n",
    "    #Label(tk, text='List of restaurants from 3 locations - choose 3 each').grid()\n",
    "    \n",
    "    #Creating the multi-listbox object, pass in a tuple of tuple (lists), this will be the list objects\n",
    "    initialSetuUp = MultiListbox_Initialize(tk, (('Yonge & Finch Intersection', 20), ('Bloor & Bathurst Intersection', 20), \\\n",
    "                            ('Queen & Spadina Intersection', 20)),list(dict1_yongeFinch.keys()),list(dict2_bloorBathurst.keys()),\\\n",
    "                                 list(dict3_queenSpadina.keys()))\n",
    "\n",
    "    #loop through the length of recommend list, # = 5 \n",
    "    for index in range(len(dict1_yongeFinch)):\n",
    "        #First restaurant information to display \n",
    "        #Following the restaurants' name \n",
    "        restList1 = list(dict1_yongeFinch.keys())[index]\n",
    "        restList2 = list(dict2_bloorBathurst.keys())[index]\n",
    "        restList3 = list(dict3_queenSpadina.keys())[index]\n",
    "        \n",
    "        initialSetuUp.insert(END, (' ', ' ', ' '))\n",
    "        \n",
    "        #Inserting the restaurant names\n",
    "        initialSetuUp.insert(END, ('%d: %s' % (index + 1, restList1),'%d: %s' % (index + 1, restList2),\n",
    "                         '%d: %s' % (index + 1, restList3)))\n",
    "        \n",
    "        #Looping through each attribute keys - resinfo\n",
    "        for resinfo in dict1_yongeFinch.get(restList1).keys():\n",
    "            restList1Info = resinfo + ':' + str(dict1_yongeFinch.get(restList1).get(resinfo,''))\n",
    "            restList2Info = resinfo + ':' + str(dict2_bloorBathurst.get(restList2).get(resinfo,''))\n",
    "            restList3Info = resinfo + ':' + str(dict3_queenSpadina.get(restList3).get(resinfo,''))\n",
    "            \n",
    "            initialSetuUp.insert(END, (restList1Info, restList2Info, restList3Info))\n",
    "        \n",
    "        initialSetuUp.insert(END, ('----------------', '----------------', '----------------'))\n",
    "    \n",
    "    initialSetuUp.pack(expand=YES,fill=BOTH)\n",
    "    #initialSetuUp.grid(expand=YES,fill=BOTH)\n",
    "\n",
    "    tk.mainloop()\n",
    "    \n",
    "    #Get user response\n",
    "    UserInitialResponse = initialSetuUp.responseDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0] [2292 2071 1145 2338 2128 1617 2094 2312 2640] [5 4 3 5 4 3 5 4 4]\n"
     ]
    }
   ],
   "source": [
    "#Process user inputs\n",
    "assert len(UserInitialResponse) ==9,\"User response has duplicates!\"\n",
    "\n",
    "import statistics \n",
    "#Get row lis\n",
    "rowList = [0] * len(UserInitialResponse)\n",
    "#Get col list\n",
    "colList = []\n",
    "#Get data list\n",
    "dataList = []\n",
    "\n",
    "for resName, rating in UserInitialResponse.items():\n",
    "    #Append the bus_num_id as column values\n",
    "    #RestaurantBusId mapps restuarnt names to business ids\n",
    "    colList.append(RestaurantBusId[resName])\n",
    "    dataList.append(rating)\n",
    "\n",
    "userAvg = statistics.mean(dataList) \n",
    "dataWuserAvgList = np.array(dataList) - np.array([userAvg] * len(UserInitialResponse))+ 0.001\n",
    "rows = np.array(rowList)\n",
    "cols = np.array(colList)\n",
    "data = np.array(dataList)\n",
    "dataWuser = np.array(dataWuserAvgList) \n",
    "print(rows, cols,data)\n",
    "\n",
    "#Get explicit data\n",
    "userSetUpMatrix = csr_matrix((data, (rows, cols)), shape=(1, rtrain.shape[1]))\n",
    "#Get with user rating\n",
    "userSetUpMatrix_WuserAvg = csr_matrix((dataWuser, (rows, cols)), shape=(1, rtrain.shape[1]))\n",
    "\n",
    "#Generate Implicit user rating vector\n",
    "implicitUserSetUpMtx = csr_matrix((data, (rows, cols)), shape=(1, rtrain.shape[1]))\n",
    "implicitUserSetUpMtx[(userSetUpMatrix > 3).nonzero()] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !Stacking new user data with original data, ONLY RUN ONCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6101x3998 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 180041 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This would overwrite rtrain,rtrain_implicit, and rtrain_WuserAvg\n",
    "csr_vappend(rtrain,userSetUpMatrix)\n",
    "csr_vappend(rtrain_implicit, implicitUserSetUpMtx)\n",
    "#csr_vappend(rtrain_userAvg, userSetUpMatrix_WuserAvg)\n",
    "\n",
    "#User_index = #This should be the user index rtrain.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity score for new user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update rtrain similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6100 * 6100\n",
    "#should import \n",
    "initial_rtrain_similarity = np.load('..\\\\data\\\\userStudy\\\\UU_explicit.npy')\n",
    "\n",
    "#Compute the similarity vector for the new user 1*6101\n",
    "newSimilarityVector_explicit = cosine_similarity(X=userSetUpMatrix, Y=rtrain, dense_output=True)\n",
    "\n",
    "#new user similarity row\n",
    "# 1 * 6100\n",
    "newSimilarity_row = newSimilarityVector_explicit[0][:-1]\n",
    "newSimilarity_row = np.expand_dims(newSimilarity_row, axis=0)\n",
    "\n",
    "#new user similarity column\n",
    "# 6101 * 1\n",
    "newSimilarity_col = newSimilarityVector_explicit.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack the bottom row\n",
    "new_rtrain_similarity = np.vstack((initial_rtrain_similarity, newSimilarity_row))\n",
    "\n",
    "#stack the last column\n",
    "#new trains similarity: 6101 * 6100, new similarity_col: 6101 * 1\n",
    "new_rtrain_similarity = np.hstack((new_rtrain_similarity, newSimilarity_col))\n",
    "\n",
    "#validation\n",
    "#(new_rtrain_similarity[-1,:] == newSimilarity_row).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update rtrain_implicit similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial rtrain implicit similarity: 6100 * 6100\n",
    "#should import \n",
    "initial_rtrainImplicit_similarity = np.load('..\\\\data\\\\userStudy\\\\UU_implicit.npy')\n",
    "\n",
    "#Compute the similarity vector for the new user 1*6101\n",
    "newSimilarityVector_implicit = cosine_similarity(X=implicitUserSetUpMtx, Y=rtrain_implicit, dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new user similarity row\n",
    "# 1 * 6100\n",
    "newSimilarity_implicit_row = newSimilarityVector_implicit[0][:-1]\n",
    "newSimilarity_implicit_row = np.expand_dims(newSimilarity_implicit_row, axis=0)\n",
    "\n",
    "#new user similarity column\n",
    "# 6101 * 1\n",
    "newSimilarity_implicit_col = newSimilarityVector_implicit.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack the bottom row\n",
    "new_rtrainImplicit_similarity = np.vstack((initial_rtrainImplicit_similarity, newSimilarity_implicit_row))\n",
    "\n",
    "#stack the last column\n",
    "#new trains similarity: 6101 * 6100, new similarity_col: 6101 * 1\n",
    "new_rtrainImplicit_similarity = np.hstack((new_rtrainImplicit_similarity, newSimilarity_implicit_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-rating KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implicit User-rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:17<00:00, 357.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:01<00:00, 4024.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#UU similarity, using cosine similarity\n",
    "#similarity_2 = train(rtrain_implicit)\n",
    "UI_predictionScore_Implicit = predict(rtrain_implicit, 100, new_rtrainImplicit_similarity, item_similarity_en= False)\n",
    "UI_predict_Implicit = prediction(UI_predictionScore_Implicit, 50, rtrain_implicit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implicit similarity, Explicit user-rating combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:17<00:00, 356.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:01<00:00, 4003.80it/s]\n"
     ]
    }
   ],
   "source": [
    "#similarity_3 = train(rtrain_implicit)\n",
    "#get a user-item matrix  UI prediction\n",
    "#Predict using UI matrix with ratings in it \n",
    "UI_predictionScore_IECombined = predict(rtrain, 100, new_rtrainImplicit_similarity, item_similarity_en= False)\n",
    "UI_predict_IECombined = prediction(UI_predictionScore_IECombined, 50, rtrain)\n",
    "# user_item_res1 = evaluate(UI_predict_IECombined, rvalid)\n",
    "# user_item_res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Item_based TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3998/3998 [00:04<00:00, 963.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:01<00:00, 3642.31it/s]\n"
     ]
    }
   ],
   "source": [
    "II_similarity_IK = np.load('..\\\\data\\\\userStudy\\\\II_usingIK.npy')\n",
    "item_based_prediction_score4 = predict(rtrain, 10, II_similarity_IK, item_similarity_en= True)\n",
    "#for each restuarant top50 users \n",
    "Item_predict_tfidf = prediction(item_based_prediction_score4, 50, rtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Item_based IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3998/3998 [00:03<00:00, 1106.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:01<00:00, 3727.87it/s]\n"
     ]
    }
   ],
   "source": [
    "item_based_prediction_IC = predict(rtrain, 10, II_similarity_usingIC, item_similarity_en= True)\n",
    "#for each restuarant top50 users \n",
    "Item_predict_IC = prediction(item_based_prediction_IC, 50, rtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Section: Produce the list of restaurants close to the set location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Remember to manually change this userIndex!!!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# three locations for user recommendation\n",
    "intersection = [bloor_and_yonge,dundas_and_yonge,spadina_and_dundas]\n",
    "# get 3 items for each location\n",
    "businessIndexRange = 3\n",
    "# 5 metrics and store them in a list\n",
    "metric = [UI_predict_Implicit, matrix_popular_list_avg_stars, UI_predict_IECombined, Item_predict_IC, Item_predict_tfidf]\n",
    "\n",
    "# manually enter this number!!!!!!\n",
    "userIndex = rtrain.shape[0]\n",
    "\n",
    "#Need this number to perform the user test, so don't repeat, don't mess up\n",
    "userTestNumber = random.randint(1,1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** userIndex: 6101 userTestNumber on file: 368 **********************\n"
     ]
    }
   ],
   "source": [
    "print('********************** userIndex:',userIndex, 'userTestNumber on file:', userTestNumber,'**********************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the recommendations for each metric using loops, store in the res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3490 3654  756 ... 2574 2550   10]\n",
      " [2666  756 3332 ... 2150 2209 2228]\n",
      " [1851  103 2136 ... 2582  718 2716]\n",
      " ...\n",
      " [3490 1851 2136 ... 3391 1150 3553]\n",
      " [ 405  469 1715 ... 2867 1824 2132]\n",
      " [3490 3684 2399 ...   36 1938 1729]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " ...\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[3490 3654  756 ... 2574 2550   10]\n",
      " [2666  756 3332 ... 2150 2209 2228]\n",
      " [1851  103 2136 ... 2582  718 2716]\n",
      " ...\n",
      " [3490 1851 2136 ... 3391 1150 3553]\n",
      " [ 405  469 1715 ... 2867 1824 2132]\n",
      " [3490 3684 2399 ...   36 1938 1729]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1543   80 2711 ...  154 1005 1590]\n",
      " [3563 3496  618 ...  303 1824 2952]\n",
      " [ 904 2635 2153 ... 3458 1976 1727]\n",
      " ...\n",
      " [1600 2153  680 ...  251 3947 2180]\n",
      " [ 888  115 2717 ... 1197 1674  837]\n",
      " [2580 3822 2259 ... 1572  765 2106]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 867 3631 2729 ... 1962 1884  321]\n",
      " [3746 1656 2423 ... 1531  491  678]\n",
      " [2180  680  692 ... 1970 1238 2740]\n",
      " ...\n",
      " [2635 1874  822 ... 2466 1650 1797]\n",
      " [1615 3756 3416 ... 1459 1157 1238]\n",
      " [2461 3235 2369 ... 3661 1556  278]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[3490 3654  756 ... 2574 2550   10]\n",
      " [2666  756 3332 ... 2150 2209 2228]\n",
      " [1851  103 2136 ... 2582  718 2716]\n",
      " ...\n",
      " [3490 1851 2136 ... 3391 1150 3553]\n",
      " [ 405  469 1715 ... 2867 1824 2132]\n",
      " [3490 3684 2399 ...   36 1938 1729]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " ...\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[3490 3654  756 ... 2574 2550   10]\n",
      " [2666  756 3332 ... 2150 2209 2228]\n",
      " [1851  103 2136 ... 2582  718 2716]\n",
      " ...\n",
      " [3490 1851 2136 ... 3391 1150 3553]\n",
      " [ 405  469 1715 ... 2867 1824 2132]\n",
      " [3490 3684 2399 ...   36 1938 1729]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1543   80 2711 ...  154 1005 1590]\n",
      " [3563 3496  618 ...  303 1824 2952]\n",
      " [ 904 2635 2153 ... 3458 1976 1727]\n",
      " ...\n",
      " [1600 2153  680 ...  251 3947 2180]\n",
      " [ 888  115 2717 ... 1197 1674  837]\n",
      " [2580 3822 2259 ... 1572  765 2106]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 867 3631 2729 ... 1962 1884  321]\n",
      " [3746 1656 2423 ... 1531  491  678]\n",
      " [2180  680  692 ... 1970 1238 2740]\n",
      " ...\n",
      " [2635 1874  822 ... 2466 1650 1797]\n",
      " [1615 3756 3416 ... 1459 1157 1238]\n",
      " [2461 3235 2369 ... 3661 1556  278]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[3490 3654  756 ... 2574 2550   10]\n",
      " [2666  756 3332 ... 2150 2209 2228]\n",
      " [1851  103 2136 ... 2582  718 2716]\n",
      " ...\n",
      " [3490 1851 2136 ... 3391 1150 3553]\n",
      " [ 405  469 1715 ... 2867 1824 2132]\n",
      " [3490 3684 2399 ...   36 1938 1729]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " ...\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]\n",
      " [1115 2895 2786 ...  399 3395 3577]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[3490 3654  756 ... 2574 2550   10]\n",
      " [2666  756 3332 ... 2150 2209 2228]\n",
      " [1851  103 2136 ... 2582  718 2716]\n",
      " ...\n",
      " [3490 1851 2136 ... 3391 1150 3553]\n",
      " [ 405  469 1715 ... 2867 1824 2132]\n",
      " [3490 3684 2399 ...   36 1938 1729]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1543   80 2711 ...  154 1005 1590]\n",
      " [3563 3496  618 ...  303 1824 2952]\n",
      " [ 904 2635 2153 ... 3458 1976 1727]\n",
      " ...\n",
      " [1600 2153  680 ...  251 3947 2180]\n",
      " [ 888  115 2717 ... 1197 1674  837]\n",
      " [2580 3822 2259 ... 1572  765 2106]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 867 3631 2729 ... 1962 1884  321]\n",
      " [3746 1656 2423 ... 1531  491  678]\n",
      " [2180  680  692 ... 1970 1238 2740]\n",
      " ...\n",
      " [2635 1874  822 ... 2466 1650 1797]\n",
      " [1615 3756 3416 ... 1459 1157 1238]\n",
      " [2461 3235 2369 ... 3661 1556  278]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# get 3 top recommendations for each locations\n",
    "# store three locations in one list for each metric\n",
    "\n",
    "#loop through the 5 recommendation algorithms, initialize the res list \n",
    "res = [[] for i in range(len(metric))]\n",
    "#Loop through the intersections \n",
    "for i in range(len(intersection)):\n",
    "    #loop through each metric \n",
    "    for j in range(len(metric)):\n",
    "        temp = geographical_dist(metric[j],intersection[i],userIndex-1,businessIndexRange)\n",
    "        res[j] += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1257, 3020, 960, 1802, 1490, 2938, 1823],\n",
       " [2743, 1006, 1420, 3379, 3070, 3553, 3546, 2938, 549],\n",
       " [1257, 3020, 960, 1802, 1490, 2938, 1823],\n",
       " [276, 3405, 3822, 2264, 3497, 2882, 1122, 3595],\n",
       " [881, 702, 2461, 3305, 1897]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 recommendations for each metric\n",
    "# the sequence is -> [UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf]\n",
    "# get three recommendations for each location, so the len for each row is 3*3\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look back the the origal prediction matrix and rearrange the recommendations list, choose the top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = []\n",
    "#loop through the elements in the res list (5 recommend lists)\n",
    "for element in range(len(res)):\n",
    "    dic = {}\n",
    "    #loop through each element in the recomemndation list (order:element)\n",
    "    for i in range(len(res[element])):\n",
    "        #if the recommendation is a list \n",
    "        if isinstance(metric[element], list):\n",
    "            dic[metric[element].index(res[element][i])] = res[element][i]\n",
    "        #if the recommendation is a matrix \n",
    "        else:\n",
    "            dic[metric[element][userIndex-1].tolist().index(res[element][i])] = res[element][i]\n",
    "    temp = []\n",
    "    for j in sorted(dic.keys()):\n",
    "        temp.append(int(dic[j]))\n",
    "    res_final.append(temp[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1490, 3020, 2938],\n",
       " [3546, 2938, 2743],\n",
       " [1490, 3020, 2938],\n",
       " [3822, 2264, 2882],\n",
       " [2461, 3305, 1897]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final recommendations for each metric\n",
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match restaurant information according to business_num_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current sequence: UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = [UI_predict_Implicit, matrix_popular_list_avg_stars, UI_predict_IECombined, Item_predict_IC, Item_predict_tfidf]\n",
    "#Trying to recommend for user 0 for now \n",
    "dict1_ImplicitRecommend = {}\n",
    "dict2_PopularityRecommend = {}\n",
    "dict3_EICombineRecommend = {}\n",
    "dict4_IIbasedICRecommend = {}\n",
    "dict5_IIbasedTFIDFRecommend = {}\n",
    "#User predict [user index] [item index]\n",
    "#Add a for loop for the top recommended items\n",
    "\n",
    "dict1_ImplicitRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[0])\n",
    "dict2_PopularityRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[1])\n",
    "dict3_EICombineRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[2])\n",
    "dict4_IIbasedICRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[3])\n",
    "dict5_IIbasedTFIDFRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence for now: UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list: 1\n",
      "Like: \"afg\", list rating: 1\n",
      "Dislike: \"aerfg\", list rating: 1\n",
      "list: 2\n",
      "Like: \"adfg\", list rating: 5\n",
      "Dislike: \"afdga\", list rating: 5\n",
      "list: 3\n",
      "Like: \"afdg\", list rating: 3\n",
      "Dislike: \"ag\", list rating: 3\n",
      "list: 4\n",
      "Like: \"afg\", list rating: 4\n",
      "Dislike: \"adfga\", list rating: 4\n",
      "list: 5\n",
      "Like: \"afdg\", list rating: 2\n",
      "Dislike: \"afdg\", list rating: 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Initiate a frame or master? \n",
    "    tk = Tk()\n",
    "    Label(tk, text='List of recommended restaurants').pack()\n",
    "    \n",
    "    #Creating the multi-listbox object, pass in a tuple of tuple (lists), this will be the list objects\n",
    "    mlb = MultiListbox_entries(tk, (('Implicit User-Rating', 20), ('Popularity List', 20), \\\n",
    "                            ('Explicit Implicit Combined', 20), ('Explicit Item-Rating', 20), ('TF-IDF Score of Item', 20)))\n",
    "\n",
    "    #loop through the length of recommend list, # = 5 \n",
    "    for index in range(len(dict1_ImplicitRecommend)):\n",
    "        #First restaurant information to display \n",
    "        #Following the restaurants' name \n",
    "        restList1 = list(dict1_ImplicitRecommend.keys())[index]\n",
    "        restList2 = list(dict2_PopularityRecommend.keys())[index]\n",
    "        restList3 = list(dict3_EICombineRecommend.keys())[index]\n",
    "        restList4 = list(dict4_IIbasedICRecommend.keys())[index]\n",
    "        restList5 = list(dict5_IIbasedTFIDFRecommend.keys())[index]\n",
    "        \n",
    "        mlb.insert(END, (' ', ' ', ' ', ' ', ' '))\n",
    "        \n",
    "        #Inserting the restaurant names\n",
    "        mlb.insert(END, ('%d: %s' % (index + 1, restList1),'%d: %s' % (index + 1, restList2),\n",
    "                         '%d: %s' % (index + 1, restList3),'%d: %s' % (index + 1, restList4),\n",
    "                         '%d: %s' % (index + 1, restList5)))\n",
    "        \n",
    "        #Looping through each attribute keys - resinfo\n",
    "        for resinfo in dict1_ImplicitRecommend.get(restList1).keys():\n",
    "            restList1Info = resinfo + ':' + str(dict1_ImplicitRecommend.get(restList1).get(resinfo,''))\n",
    "            restList2Info = resinfo + ':' + str(dict2_PopularityRecommend.get(restList2).get(resinfo,''))\n",
    "            restList3Info = resinfo + ':' + str(dict3_EICombineRecommend.get(restList3).get(resinfo,''))\n",
    "            restList4Info = resinfo + ':' + str(dict4_IIbasedICRecommend.get(restList4).get(resinfo,''))\n",
    "            restList5Info = resinfo + ':' + str(dict5_IIbasedTFIDFRecommend.get(restList5).get(resinfo,''))\n",
    "            \n",
    "            mlb.insert(END, (restList1Info, restList2Info, restList3Info, restList4Info, restList5Info))\n",
    "        \n",
    "        mlb.insert(END, ('----------------', '----------------', '----------------', '----------------', '----------------'))\n",
    "    \n",
    "    mlb.pack(expand=YES,fill=BOTH)\n",
    "\n",
    "    tk.mainloop()\n",
    "    \n",
    "    #Get user response\n",
    "    response = mlb.responseDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Implicit User-Rating': {'Like': 'afg',\n",
       "  'listRating': '1',\n",
       "  'Dislike': 'aerfg'},\n",
       " 'Popularity List': {'Like': 'adfg', 'listRating': '5', 'Dislike': 'afdga'},\n",
       " 'Explicit Implicit Combined': {'Like': 'afdg',\n",
       "  'listRating': '3',\n",
       "  'Dislike': 'ag'},\n",
       " 'Explicit Item-Rating': {'Like': 'afg',\n",
       "  'listRating': '4',\n",
       "  'Dislike': 'adfga'},\n",
       " 'TF-IDF Score of Item': {'Like': 'afdg',\n",
       "  'listRating': '2',\n",
       "  'Dislike': 'afdg'}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['userinitialResponse'] = UserInitialResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Implicit User-Rating': {'Like': 'afg',\n",
       "  'listRating': '1',\n",
       "  'Dislike': 'aerfg'},\n",
       " 'Popularity List': {'Like': 'adfg', 'listRating': '5', 'Dislike': 'afdga'},\n",
       " 'Explicit Implicit Combined': {'Like': 'afdg',\n",
       "  'listRating': '3',\n",
       "  'Dislike': 'ag'},\n",
       " 'Explicit Item-Rating': {'Like': 'afg',\n",
       "  'listRating': '4',\n",
       "  'Dislike': 'adfga'},\n",
       " 'TF-IDF Score of Item': {'Like': 'afdg',\n",
       "  'listRating': '2',\n",
       "  'Dislike': 'afdg'},\n",
       " 'userinitialResponse': {'OneZo Tapioca': 5,\n",
       "  'Pastel Creperies & Dessert House': 4,\n",
       "  'Cafe Vite': 3,\n",
       "  'MaMa Chef Korean Restaurant': 5,\n",
       "  \"The Burger's Priest\": 4,\n",
       "  \"Yogurty's Froyo\": 3,\n",
       "  'Barre3 Toronto - King Street West': 5,\n",
       "  'UNIUN': 4,\n",
       "  'The Fifth & Terrace': 4}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the user response into local file\n",
    "csv_fileName = \"UserTestResult{:d}.json\".format(userTestNumber)\n",
    "with open('userStudyResults//'+csv_fileName, 'w') as fp:\n",
    "    json.dump(response, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I get the user response information here, so please make sure the sequence for list names are correct when initializing our mlb object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load the result file with json \n",
    "# with open(csv_fileName, 'r') as fp:\n",
    "#     test = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1145, 1617, 2071, 2094, 2128, 2292, 2312, 2338, 2640])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the 0th user review data \n",
    "rows, cols = rtrain[rtrain.shape[0]-1].nonzero()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_num_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>2071</td>\n",
       "      <td>Pastel Creperies &amp; Dessert House</td>\n",
       "      <td>Creperies, Desserts, Coffee &amp; Tea</td>\n",
       "      <td>4.0</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12157</th>\n",
       "      <td>2128</td>\n",
       "      <td>The Burger's Priest</td>\n",
       "      <td>Burgers</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14821</th>\n",
       "      <td>1617</td>\n",
       "      <td>Yogurty's Froyo</td>\n",
       "      <td>Ice Cream &amp; Frozen Yogurt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78441</th>\n",
       "      <td>2312</td>\n",
       "      <td>UNIUN</td>\n",
       "      <td>Dance Clubs, Lounges</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87116</th>\n",
       "      <td>2338</td>\n",
       "      <td>MaMa Chef Korean Restaurant</td>\n",
       "      <td>Korean</td>\n",
       "      <td>4.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150444</th>\n",
       "      <td>2094</td>\n",
       "      <td>Barre3 Toronto - King Street West</td>\n",
       "      <td>Pilates, Yoga, Barre Classes</td>\n",
       "      <td>4.5</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159423</th>\n",
       "      <td>1145</td>\n",
       "      <td>Cafe Vite</td>\n",
       "      <td>Cafes, Ice Cream &amp; Frozen Yogurt, Vietnamese</td>\n",
       "      <td>4.5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170050</th>\n",
       "      <td>2640</td>\n",
       "      <td>The Fifth &amp; Terrace</td>\n",
       "      <td>French, Venues &amp; Event Spaces, Italian</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183386</th>\n",
       "      <td>2292</td>\n",
       "      <td>OneZo Tapioca</td>\n",
       "      <td>Bubble Tea</td>\n",
       "      <td>3.5</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        business_num_id                               name  \\\n",
       "1840    2071             Pastel Creperies & Dessert House    \n",
       "12157   2128             The Burger's Priest                 \n",
       "14821   1617             Yogurty's Froyo                     \n",
       "78441   2312             UNIUN                               \n",
       "87116   2338             MaMa Chef Korean Restaurant         \n",
       "150444  2094             Barre3 Toronto - King Street West   \n",
       "159423  1145             Cafe Vite                           \n",
       "170050  2640             The Fifth & Terrace                 \n",
       "183386  2292             OneZo Tapioca                       \n",
       "\n",
       "                                          categories  business_stars  \\\n",
       "1840    Creperies, Desserts, Coffee & Tea             4.0              \n",
       "12157   Burgers                                       3.0              \n",
       "14821   Ice Cream & Frozen Yogurt                     4.0              \n",
       "78441   Dance Clubs, Lounges                          3.0              \n",
       "87116   Korean                                        4.0              \n",
       "150444  Pilates, Yoga, Barre Classes                  4.5              \n",
       "159423  Cafes, Ice Cream & Frozen Yogurt, Vietnamese  4.5              \n",
       "170050  French, Venues & Event Spaces, Italian        4.0              \n",
       "183386  Bubble Tea                                    3.5              \n",
       "\n",
       "        review_count  \n",
       "1840    316           \n",
       "12157   31            \n",
       "14821   35            \n",
       "78441   77            \n",
       "87116   46            \n",
       "150444  34            \n",
       "159423  31            \n",
       "170050  55            \n",
       "183386  38            "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the corresponding business information using the business num id \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df[df[\"business_num_id\"].isin(cols)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\",\"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

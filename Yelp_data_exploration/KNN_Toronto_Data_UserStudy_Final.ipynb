{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This files combines the basic structures and logic of the implementation of user study, sequence is not correct, the final version will be in another file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You cannot drop any data anymore in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\programdata\\anaconda3\\lib\\site-packages (1.20.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in c:\\programdata\\anaconda3\\lib\\site-packages (from geopy) (1.50)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "import statistics as stats\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "import scipy.sparse as sparse\n",
    "import yaml\n",
    "from tkinter import *\n",
    "import tkinter\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy import distance\n",
    "from geopy import Point\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewJson = \"..\\\\data\\\\Export_CleanedReview.json\"\n",
    "#reviewJsonWithClosedRes = \"..\\\\data\\\\Export_CleanedReviewWithClosedRes.json\"\n",
    "#reviewJsonToronto = \"..\\\\data\\\\Export_TorontoData.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess using Term Frequency - CounterVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def train(matrix_train):\n",
    "    similarity = cosine_similarity(X=matrix_train, Y=None, dense_output=True)\n",
    "    return similarity\n",
    "\n",
    "def get_I_K(df, X, row_name = 'business_num_id', binary = True, shape = (121994,6000)):\n",
    "    \"\"\"\n",
    "    get the item-keyphrase matrix\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    #For each review history\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        #Get the array of frequencies for document/review i \n",
    "        arr = X[i].toarray() \n",
    "        nonzero_element = arr.nonzero()[1]  # Get nonzero element in each line, keyphrase that appears index \n",
    "        length_of_nonzero = len(nonzero_element) #number of important keyphrase that appears\n",
    "        \n",
    "        # df[row_name][i] is the item idex\n",
    "        #Get a list row index that indicates the document/review\n",
    "        rows.extend(np.array([df[row_name][i]]*length_of_nonzero)) ## Item index\n",
    "        #print(rows)\n",
    "        \n",
    "        #Get a list of column index indicating the key phrase that appears in i document/review\n",
    "        cols.extend(nonzero_element) ## Keyword Index\n",
    "        if binary:\n",
    "            #Create a bunch of 1s\n",
    "            vals.extend(np.array([1]*length_of_nonzero))\n",
    "        else:\n",
    "            #If not binary \n",
    "            vals.extend(arr[arr.nonzero()])    \n",
    "    return csr_matrix((vals, (rows, cols)), shape=shape)\n",
    "\n",
    "\n",
    "#Get a UI matrix if it's not item_similarity based or else IU\n",
    "def predict(matrix_train, k, similarity, item_similarity_en = False):\n",
    "    prediction_scores = []\n",
    "    \n",
    "    #inverse to IU matrix\n",
    "    if item_similarity_en:\n",
    "        matrix_train = matrix_train.transpose()\n",
    "        \n",
    "    #for each user or item, depends UI or IU \n",
    "    for user_index in tqdm(range(matrix_train.shape[0])):\n",
    "        # Get user u's prediction scores for all items\n",
    "        #Get prediction/similarity score for each user 1*num or user or num of items\n",
    "        vector_u = similarity[user_index]\n",
    "\n",
    "        # Get closest K neighbors excluding user u self\n",
    "        #Decending accoding to similarity score, select top k\n",
    "        similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "        \n",
    "        # Get neighbors similarity weights and ratings\n",
    "        similar_users_weights = similarity[user_index][similar_users]\n",
    "        \n",
    "        #similar_users_weights_sum = np.sum(similar_users_weights)\n",
    "        #print(similar_users_weights.shape)\n",
    "        #shape: num of res * k\n",
    "        similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "              \n",
    "        prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "        #print(prediction_scores_u)\n",
    "        \n",
    "        \n",
    "        prediction_scores.append(np.sum(prediction_scores_u, axis=0))\n",
    "        \n",
    "    res = np.array(prediction_scores)\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        res = res.transpose()\n",
    "    return res\n",
    "\n",
    "\n",
    "#Preidction score is UI or IU?\n",
    "def prediction(prediction_score, topK, matrix_Train):\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    #for each user\n",
    "    for user_index in tqdm(range(matrix_Train.shape[0])):\n",
    "        \n",
    "        #take the prediction scores for user 1 * num res\n",
    "        vector_u = prediction_score[user_index]\n",
    "        \n",
    "        #The restuarant the user rated\n",
    "        vector_train = matrix_Train[user_index]\n",
    "        \n",
    "        if len(vector_train.nonzero()[0]) > 0:\n",
    "            vector_predict = sub_routine(vector_u, vector_train, topK=topK)\n",
    "        else:\n",
    "            vector_predict = np.zeros(topK, dtype=np.float32)\n",
    "\n",
    "        prediction.append(vector_predict)\n",
    "\n",
    "    return np.vstack(prediction)\n",
    "\n",
    "#topK: the number of restuarants we are suggesting \n",
    "#if vector_train has number, then the user has visited\n",
    "def sub_routine(vector_u, vector_train, topK=500):\n",
    "\n",
    "    #index where non-zero\n",
    "    train_index = vector_train.nonzero()[1]\n",
    "    \n",
    "    vector_u = vector_u\n",
    "    \n",
    "    #get topk + num rated res prediction score descending, top index \n",
    "    candidate_index = np.argpartition(-vector_u, topK+len(train_index))[:topK+len(train_index)]\n",
    "    \n",
    "    #sort top prediction score index in range topK+len(train_index) into vector_u`\n",
    "    vector_u = candidate_index[vector_u[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "    #deleted the rated res from the topk+train_index prediction score vector for user u \n",
    "    #Delete the user rated res index from the topk+numRated index\n",
    "    vector_u = np.delete(vector_u, np.isin(vector_u, train_index).nonzero()[0])\n",
    "\n",
    "    #so we only include the top K prediction score here\n",
    "    return vector_u[:topK]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the user number that we are trying to recommend for\n",
    "#Enter the # of businesses that we want to recommend for them \n",
    "#Pass in the UI_Prediction matrix for users \n",
    "#userIndex parameter not used \n",
    "def constructResDictionary(userIndex, busIndexRange, UI_prediction):\n",
    "    #Construct the dictionary for the recommended restaurants to display \n",
    "    dictionaryToConstruct = {}\n",
    "    \n",
    "    #Loop through the number of businesses \n",
    "    for busIndex in range(busIndexRange):\n",
    "        #Get the business information for the recommended business \n",
    "        businessSeries = df[df[\"business_num_id\"] == UI_prediction[busIndex]].iloc[0]\n",
    "        #Get the business name \n",
    "        busName = businessSeries['name']\n",
    "        \n",
    "        #get the list of strings to generate the address information \n",
    "        address_generator = (str(w) for w in yaml.safe_load(businessSeries.location)['display_address'])\n",
    "        busLocation = ', '.join(address_generator)\n",
    "        bus_Price = businessSeries.price\n",
    "        busStars = businessSeries.business_stars\n",
    "        busReviewCount = businessSeries.review_count_y \n",
    "        #category_generator = (str(s) for s in [cateDict['title'] for cateDict in yaml.safe_load(businessSeries.categories)])\n",
    "        #busCategories = [cateDict['title'] for cateDict in yaml.safe_load(businessSeries.categories)]\n",
    "        #busCategories = ', '.join(category_generator)\n",
    "        busCategories = businessSeries.categories\n",
    "        #Now add the restaurant to the dictionary\n",
    "        dictionaryToConstruct[busName] = {'Address': busLocation,\\\n",
    "                                'Price': bus_Price,\\\n",
    "                                 'Star': busStars, \\\n",
    "                                 'Review Count': busReviewCount, \\\n",
    "                                 'Category': busCategories}\n",
    "    return dictionaryToConstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_vappend(a,b):\n",
    "    \"\"\" Takes in 2 csr_matrices and appends the second one to the bottom of the first one. \n",
    "    Much faster than scipy.sparse.vstack but assumes the type to be csr and overwrites\n",
    "    the first matrix instead of copying it. The data, indices, and indptr still get copied.\"\"\"\n",
    "\n",
    "    a.data = np.hstack((a.data,b.data))\n",
    "    a.indices = np.hstack((a.indices,b.indices))\n",
    "    a.indptr = np.hstack((a.indptr,(b.indptr + a.nnz)[1:]))\n",
    "    a._shape = (a.shape[0]+b.shape[0],b.shape[1])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_three_popularity_matrix(df_original,rtrain):\n",
    "    # get the list of popular items by ranking the number of reviews\n",
    "    numUsers = rtrain.shape[0]\n",
    "    numItems = rtrain.shape[1]\n",
    "    \n",
    "    dff_popular = df_original.copy()\n",
    "    dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "    popular_list_num_of_reviews = dff_popular[\"business_num_id\"].tolist()\n",
    "    \n",
    "    # get the list of popular items by ranking average rating score\n",
    "    dff_popular_rating = df_original.copy()\n",
    "    dff_popular_rating = dff_popular_rating.sort_values(by=[\"business_stars\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "    popular_list_avg_stars = dff_popular_rating[\"business_num_id\"].tolist()\n",
    "    \n",
    "    lst_temp = []\n",
    "    for item in tqdm(range(numItems)):\n",
    "        numOfUsersRated = len(rtrain.toarray()[:, item].nonzero()[0])\n",
    "        if numOfUsersRated <= 50:\n",
    "            lst_temp.append(item)\n",
    "    popular_list_avg_stars = [x for x in popular_list_avg_stars if x not in lst_temp]\n",
    "    \n",
    "    # get the popularity items by using the percentage liked method(number of liked items / total items)\n",
    "    predictionMatrix = np.zeros((numUsers , numItems))\n",
    "\n",
    "    # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "    vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "    rtrain_array = rtrain.toarray()\n",
    "    # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "    itemPopularity = np.zeros((numItems))\n",
    "    for item in range(numItems):\n",
    "        numOfUsersRated = len(rtrain_array[:, item].nonzero()[0])\n",
    "        numOfUsersLiked = len(vf(rtrain_array[:, item]).nonzero()[0])\n",
    "#         if numOfUsersRated == 0:\n",
    "        # set a threshold to filter out restaurants with very few reviews\n",
    "        if numOfUsersRated <= 100:\n",
    "            itemPopularity[item] = 0\n",
    "        else:\n",
    "            itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "    popular_list_liked_ratio = itemPopularity.argsort()\n",
    "    \n",
    "    return np.asarray(popular_list_num_of_reviews),np.asarray(popular_list_avg_stars),popular_list_liked_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either a list or an array\n",
    "def geographical_dist(prediction_matrix,intersection,user_id, bus_indexRange):\n",
    "    lst = []\n",
    "    length = 0\n",
    "    #if the prediction matrix is a list of items for an user \n",
    "    print(type(prediction_matrix))\n",
    "    if isinstance(prediction_matrix, list):\n",
    "        length = len(prediction_matrix)\n",
    "    #loop through the prediction matrix for the user, if passed in a prediction matrix \n",
    "    else:\n",
    "        length = prediction_matrix[user_id].shape[0]\n",
    "        #length = prediction_matrix.shape[0]\n",
    "    for j in range(length):\n",
    "        if isinstance(prediction_matrix, list):\n",
    "            coordinateDict = yaml.safe_load(df_location[df_location[\"business_num_id\"] == prediction_matrix[j]].iloc[0].coordinates)\n",
    "        else:    \n",
    "            coordinateDict = yaml.safe_load(df_location[df_location[\"business_num_id\"] == prediction_matrix[user_id][j]].iloc[0].coordinates)\n",
    "        test_point = Point(coordinateDict['latitude'],coordinateDict['longitude'])\n",
    "        \n",
    "        #Get the distance with the test point\n",
    "        result = distance.distance(intersection,test_point).kilometers\n",
    "        if result<=0.6:\n",
    "            #append the jth item if the condition matches\n",
    "            if isinstance(prediction_matrix, list):\n",
    "                lst.append(prediction_matrix[j])\n",
    "            else:\n",
    "                lst.append(prediction_matrix[user_id][j])\n",
    "        lst = lst[0:bus_indexRange]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiListbox_Initialize(Frame):\n",
    "    \n",
    "    def __init__(self, master, lists,list1Res,list2Res,list3Res):\n",
    "        Frame.__init__(self, master)\n",
    "        self.lists = []\n",
    "        #self.entries = []\n",
    "        #self.fields = 'Like', 'Dislike'\n",
    "        self.dropDownTextBox = 'Rank1','Score1', 'Rank2','Score2','Rank3','Score3'\n",
    "        #Var for checkbox\n",
    "        #self.var = IntVar()\n",
    "        self.var = []\n",
    "        self.listNames = []\n",
    "        self.responseDict = {}\n",
    "        #self.options = [\"Jan\", \"Feb\", \"Mar\"] #etc\n",
    "        #No 0s or else you won't choose it as liked \n",
    "        self.scores = [5, 4, 3, 2, 1]\n",
    "        #stores the list of restaurants for list 1-3\n",
    "        self.list1Name = list1Res\n",
    "        self.list2Name = list2Res\n",
    "        self.list3Name = list3Res\n",
    "        #To get response from dropdowns \n",
    "        self.rankVar = []\n",
    "        self.scoreVar = []\n",
    "        \n",
    "        #list count 0,1,2\n",
    "        listCount = 0 \n",
    "        #Loop through the lists, l is the list label and widthW is the width \n",
    "        for l,widthW in lists:\n",
    "            \n",
    "            frame = Frame(self); \n",
    "            frame.pack(side=LEFT, expand=YES, fill=BOTH)\n",
    "            \n",
    "            Label(frame, text=l, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "            \n",
    "            #store the list names \n",
    "            self.listNames.append(l)\n",
    "            \n",
    "            lb = Listbox(frame, width=widthW, borderwidth=0, selectborderwidth=0,\n",
    "                 relief=FLAT, exportselection=FALSE)\n",
    "            lb.pack(expand=YES, fill=BOTH)\n",
    "            #lb.pack(fill=X,expand=1)\n",
    "            #lb.pack\n",
    "            self.lists.append(lb)\n",
    "            \n",
    "            #lb.bind('<B1-Motion>', lambda e, s=self: s._select(e.y))\n",
    "            #lb.bind('<Button-1>', lambda e, s=self: s._select(e.y))\n",
    "            \n",
    "            #lb.bind('<Leave>', lambda e: 'break')\n",
    "            \n",
    "            #lb.bind('<B2-Motion>', lambda e, s=self: s._b2motion(e.x, e.y))\n",
    "            #lb.bind('<Button-2>', lambda e, s=self: s._button2(e.x, e.y))\n",
    "             \n",
    "            for fieldText in self.dropDownTextBox:\n",
    "\n",
    "                if('Rank' in fieldText):\n",
    "                    lab = Label(frame, text=fieldText, borderwidth=0, relief=RAISED)\n",
    "                    lab.pack(side=TOP,fill=BOTH)\n",
    "            \n",
    "                    #Get the current list number \n",
    "                    if listCount+1 == 1:\n",
    "                        currentOptions = self.list1Name\n",
    "                    elif listCount+1 == 2:\n",
    "                        currentOptions = self.list2Name\n",
    "                    elif listCount+1 == 3:\n",
    "                        currentOptions = self.list3Name\n",
    "                        \n",
    "                    variable = StringVar(master)\n",
    "                    variable.set(currentOptions[0]) # default value\n",
    "\n",
    "                    #row = Frame(self)\n",
    "                    #lab = Label(frame, width=15, text=fieldText, anchor='center')\n",
    "                    drowDwn = OptionMenu(frame, variable, *currentOptions)\n",
    "                    \n",
    "                    #Append the variable set from dropdown \n",
    "                    self.rankVar.append(variable)\n",
    "                    \n",
    "                    #lab.pack(side=LEFT,fill=X)\n",
    " \n",
    "                    drowDwn.pack(side=TOP)\n",
    "\n",
    "\n",
    "                elif('Score' in fieldText ):\n",
    "                    variable = StringVar(master)\n",
    "                    variable.set(self.scores[0]) # default value\n",
    "\n",
    "                    #row = Frame(self)\n",
    "                    lab = Label(frame, width=15, text=fieldText, anchor='center')\n",
    "                    drowDwn = OptionMenu(frame, variable, *self.scores)\n",
    "                    \n",
    "                    #Append te varaible set from dropdown \n",
    "                    self.scoreVar.append(variable)\n",
    "\n",
    "                    #lab.pack(side=RIGHT, fill=X)\n",
    "                    drowDwn.pack(side=TOP)\n",
    "            \n",
    "            listCount += 1\n",
    "            \n",
    "        #Set the submit button  \n",
    "        b1 = Button(master, text='Submit', command=self.fetch)\n",
    "        b1.pack(side=BOTTOM, padx=5, pady=5)\n",
    "\n",
    "        #pakcing the frame\n",
    "        #frame = Frame(self); frame.pack(side=LEFT, fill=Y)\n",
    "        \n",
    "        #packing the label\n",
    "        #Label(frame, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "\n",
    "    def _select(self, y):\n",
    "        row = self.lists[0].nearest(y)\n",
    "        self.selection_clear(0, END)\n",
    "        self.selection_set(row)\n",
    "        return 'break'\n",
    "\n",
    "    def _button2(self, x, y):\n",
    "        for l in self.lists: l.scan_mark(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _b2motion(self, x, y):\n",
    "        for l in self.lists: l.scan_dragto(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _scroll(self, *args):\n",
    "        for l in self.lists:\n",
    "            apply(l.yview, args)\n",
    "\n",
    "    def curselection(self):\n",
    "        return self.lists[0].curselection()\n",
    "\n",
    "    def delete(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.delete(first, last)\n",
    "\n",
    "#     def get(self, first, last=None):\n",
    "#         result = []\n",
    "#         for l in self.lists:\n",
    "#             result.append(l.get(first,last))\n",
    "#         if last: return apply(map, [None] + result)\n",
    "#         return result\n",
    "\n",
    "    def index(self, index):\n",
    "        self.lists[0].index(index)\n",
    "\n",
    "    def insert(self, index, *elements):\n",
    "        #Loop through the elements \n",
    "        for element in elements:\n",
    "            i = 0\n",
    "            for l in self.lists:\n",
    "                l.insert(index, element[i])\n",
    "                i = i + 1\n",
    "\n",
    "    def size(self):\n",
    "        return self.lists[0].size()\n",
    "\n",
    "    def see(self, index):\n",
    "        for l in self.lists:\n",
    "            l.see(index)\n",
    "\n",
    "    def selection_anchor(self, index):\n",
    "        for l in self.lists:\n",
    "            l.selection_anchor(index)\n",
    "\n",
    "    def selection_clear(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_clear(first, last)\n",
    "\n",
    "    def selection_includes(self, index):\n",
    "        return self.lists[0].selection_includes(index)\n",
    "\n",
    "    def selection_set(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_set(first, last)\n",
    "            \n",
    "    def fetch(self):\n",
    "        localDict = {}\n",
    "        localRankList = list(map((lambda var: var.get()), self.rankVar))\n",
    "        localScoreList = list(map((lambda var: var.get()), self.scoreVar))\n",
    "        \n",
    "        #lop through each selected restaurant and score, construct the dictionary \n",
    "        for count in range(len(localRankList)):\n",
    "            localDict[localRankList[count]] = int(localScoreList[count])\n",
    "            \n",
    "        print('Your selected restaurants:', localRankList)\n",
    "        print('Your scores given to the restaurants', localScoreList)\n",
    "        print('Your final choice is :', localDict)\n",
    "         \n",
    "        self.responseDict = localDict.copy()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiListbox_entries(Frame):\n",
    "    \n",
    "    def __init__(self, master, lists):\n",
    "        Frame.__init__(self, master)\n",
    "        self.lists = []\n",
    "        self.entries = []\n",
    "        self.fields = 'Like', 'Dislike'\n",
    "        #Var for checkbox\n",
    "        #self.var = IntVar()\n",
    "        self.var = []\n",
    "        self.listNames = []\n",
    "        self.responseDict = {}\n",
    "        \n",
    "        #Loop through the lists, l is the list label and widthW is the width \n",
    "        for l,widthW in lists:\n",
    "            \n",
    "            frame = Frame(self); frame.pack(side=LEFT, expand=YES, fill=BOTH)\n",
    "            \n",
    "            #Label(frame, text=l, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "            Label(frame, text='list', borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "            \n",
    "            #store the list names \n",
    "            self.listNames.append(l)\n",
    "            \n",
    "            lb = Listbox(frame, width=widthW, borderwidth=0, selectborderwidth=0,\n",
    "                 relief=FLAT, exportselection=FALSE)\n",
    "            lb.pack(expand=YES, fill=BOTH)\n",
    "            \n",
    "            self.lists.append(lb)\n",
    "            \n",
    "            lb.bind('<B1-Motion>', lambda e, s=self: s._select(e.y))\n",
    "            lb.bind('<Button-1>', lambda e, s=self: s._select(e.y))\n",
    "            \n",
    "            lb.bind('<Leave>', lambda e: 'break')\n",
    "            \n",
    "            lb.bind('<B2-Motion>', lambda e, s=self: s._b2motion(e.x, e.y))\n",
    "            lb.bind('<Button-2>', lambda e, s=self: s._button2(e.x, e.y))\n",
    "             \n",
    "             #loop through the fields to \n",
    "            for field in self.fields:\n",
    "                #row = Frame(self)\n",
    "                lab = Label(frame, width=15, text=field, anchor='w')\n",
    "                ent = Entry(frame)\n",
    "                #row.pack(side=BOTTOM, fill=Y, padx=5, pady=5) #=BOTTOM\n",
    "                lab.pack()\n",
    "                #ent.pack(side=RIGHT, expand=YES, fill=Y)\n",
    "                ent.pack(side=TOP, fill=X)\n",
    "                self.entries.append((field, ent))\n",
    "            \n",
    "            #localVar = IntVar()\n",
    "            \n",
    "            #self.var.append(localVar)\n",
    "            \n",
    "            #Checkbox \n",
    "            #c = Checkbutton(frame, text=\"Liked\", variable=localVar, command=self.cb(count))\n",
    "            #c = Checkbutton(frame, text=\"Liked\", variable=localVar)\n",
    "            #c.pack()\n",
    "            \n",
    "            lab = Label(frame, width=15, text='List rank', anchor='w')\n",
    "            ent = Entry(frame)\n",
    "            #row.pack(side=BOTTOM, fill=Y, padx=5, pady=5) #=BOTTOM\n",
    "            lab.pack()\n",
    "            #ent.pack(side=RIGHT, expand=YES, fill=Y)\n",
    "            ent.pack(side=TOP, fill=X)\n",
    "            self.var.append((field, ent))\n",
    "                \n",
    "        #Set the submit button \n",
    "        #master.bind('<Button-1>', (lambda event, e=self.entries: fetch(e)))   \n",
    "        #b1 = Button(master, text='Submit', command=(lambda e=self.entries: self.fetch(e)))\n",
    "        b1 = Button(master, text='Submit', command=self.fetchDict)\n",
    "        b1.pack(side=BOTTOM, padx=5, pady=5)\n",
    "        #b2 = Button(root, text='Quit', command=root.quit)\n",
    "        #b2.pack(side=LEFT, padx=5, pady=5)\n",
    "            \n",
    "        #pakcing the frame\n",
    "        frame = Frame(self); frame.pack(side=LEFT, fill=Y)\n",
    "        \n",
    "        #packing the label\n",
    "        Label(frame, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "        #Setting a scrollbar \n",
    "#         sb = Scrollbar(frame, orient=VERTICAL, command=self._scroll)\n",
    "#         sb.pack(expand=YES, fill=Y)\n",
    "#         self.lists[0]['yscrollcommand']=sb.set\n",
    "\n",
    "    def _select(self, y):\n",
    "        row = self.lists[0].nearest(y)\n",
    "        self.selection_clear(0, END)\n",
    "        self.selection_set(row)\n",
    "        return 'break'\n",
    "    \n",
    "    #For checkbox \n",
    "    def cb(self, index):\n",
    "        print (\"variable is\", self.var[index].get())\n",
    "\n",
    "    def _button2(self, x, y):\n",
    "        for l in self.lists: l.scan_mark(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _b2motion(self, x, y):\n",
    "        for l in self.lists: l.scan_dragto(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _scroll(self, *args):\n",
    "        for l in self.lists:\n",
    "            apply(l.yview, args)\n",
    "\n",
    "    def curselection(self):\n",
    "        return self.lists[0].curselection()\n",
    "\n",
    "    def delete(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.delete(first, last)\n",
    "\n",
    "#     def get(self, first, last=None):\n",
    "#         result = []\n",
    "#         for l in self.lists:\n",
    "#             result.append(l.get(first,last))\n",
    "#         if last: return apply(map, [None] + result)\n",
    "#         return result\n",
    "\n",
    "    def index(self, index):\n",
    "        self.lists[0].index(index)\n",
    "\n",
    "    def insert(self, index, *elements):\n",
    "        #Loop through the elements \n",
    "        for element in elements:\n",
    "            i = 0\n",
    "            for l in self.lists:\n",
    "                l.insert(index, element[i])\n",
    "                i = i + 1\n",
    "\n",
    "    def size(self):\n",
    "        return self.lists[0].size()\n",
    "\n",
    "    def see(self, index):\n",
    "        for l in self.lists:\n",
    "            l.see(index)\n",
    "\n",
    "    def selection_anchor(self, index):\n",
    "        for l in self.lists:\n",
    "            l.selection_anchor(index)\n",
    "\n",
    "    def selection_clear(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_clear(first, last)\n",
    "\n",
    "    def selection_includes(self, index):\n",
    "        return self.lists[0].selection_includes(index)\n",
    "\n",
    "    def selection_set(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_set(first, last)\n",
    "            \n",
    "    def fetch(self,entries):\n",
    "        count = 1\n",
    "        \n",
    "        for entry in entries:\n",
    "            if count <= 2:\n",
    "                listCount = 1\n",
    "            elif count <= 4:\n",
    "                listCount = 2\n",
    "            elif count <= 6:\n",
    "                listCount = 3\n",
    "            elif count <= 8:\n",
    "                listCount = 4\n",
    "            elif count <= 10:\n",
    "                listCount = 5             \n",
    "            #print on odd number counts\n",
    "            if count %2 != 0:\n",
    "                print('list:', listCount)\n",
    "            #index 0 is the field \n",
    "            #index 1 is the entry data \n",
    "            field = entry[0]\n",
    "            text  = entry[1].get()\n",
    "            print('%s: \"%s\"' % (field, text))\n",
    "            \n",
    "            count =count + 1\n",
    "            \n",
    "        print(list(map((lambda var: var.get()), self.var)))\n",
    "   \n",
    "    #This function returns a dictionary of the results\n",
    "    def fetchDict(self):\n",
    "        responseDict = {}\n",
    "        count = 1\n",
    "        \n",
    "        #likeResult = list(map((lambda var: var.get()), self.var))\n",
    "        \n",
    "        for entry in self.entries:\n",
    "            tempDict = {}\n",
    "            \n",
    "            field = entry[0]\n",
    "            text  = entry[1].get()\n",
    "            # like:\"text content\"\n",
    "            tempDict[field] = text\n",
    "            \n",
    "            if count <= 2:\n",
    "                listCount = 1\n",
    "            elif count <= 4:\n",
    "                listCount = 2\n",
    "            elif count <= 6:\n",
    "                listCount = 3\n",
    "            elif count <= 8:\n",
    "                listCount = 4\n",
    "            elif count <= 10:\n",
    "                listCount = 5      \n",
    "                \n",
    "            #update the dictionary with corresponding listname :  \n",
    "            try:\n",
    "                responseDict[self.listNames[listCount-1]].update(tempDict) \n",
    "            except:\n",
    "                responseDict[self.listNames[listCount-1]] = tempDict \n",
    "            \n",
    "            if count %2 != 0:\n",
    "                #print on odd number counts\n",
    "                print('list:', listCount)\n",
    "                #Get the hit indicator and update the dictionary \n",
    "                ListRating = self.var[listCount-1][1].get()\n",
    "                tempRateDict = {'listRating': ListRating}\n",
    "                responseDict[self.listNames[listCount-1]].update(tempRateDict)\n",
    "            \n",
    "            #Print the current the field and entry text\n",
    "            print('%s: \"%s\", list rating: %s' % (field, text,ListRating))\n",
    "           \n",
    "            count =count + 1\n",
    "        \n",
    "        #print the hit list\n",
    "        #print(list(map((lambda var: var.get()), self.var)))\n",
    "        \n",
    "        self.responseDict = responseDict.copy()\n",
    "        \n",
    "        \n",
    "    #Make the entry form \n",
    "    def makeform(root, fields):\n",
    "        #For each field, like \n",
    "        for field in slef.fields:\n",
    "            row = Frame(master)\n",
    "            lab = Label(row, width=15, text=field, anchor='w')\n",
    "            ent = Entry(row)\n",
    "            row.pack(side=TOP, fill=X, padx=5, pady=5)\n",
    "            lab.pack(side=LEFT)\n",
    "            ent.pack(side=RIGHT, expand=YES, fill=X)\n",
    "            self.entries.append((field, ent))\n",
    "            \n",
    "        self.entries =  entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get original dataframe out of the review datastet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\\\data\\\\userStudy\\\\dfWhole.csv') \n",
    "rtrain = load_npz('..\\\\data\\\\userStudy\\\\Rtrain.npz').tocsr()\n",
    "rtrain_implicit = load_npz('..\\\\data\\\\userStudy\\\\Rtrain_implicit.npz').tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out desserts and tea rooms specially for this user study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df['categories'].str.contains('Barber','Desserts','Bakeries','Desserts, Bakeries')]\n",
    "#restaurantFilter = df[df['name'].isin(selectedBusiness)].business_num_id.unique()\n",
    "\n",
    "dontWantRestaurantString = \"Barber|Desserts|Bakeries|Tea Rooms\"\n",
    "\n",
    "# We only take restaurant business with the above keywords\n",
    "dontWant_restaurant = list(df[df[\"categories\"].str.contains(dontWantRestaurantString,case=False)].business_num_id.unique())\n",
    "\n",
    "dontWantRestaurantString2 = ['Coffee & Tea', 'Ice cream and Frozen Yogurt']\n",
    "donWant2 = list(df[df[\"categories\"].isin(dontWantRestaurantString2)].business_num_id.unique())\n",
    "\n",
    "for busId in donWant2:\n",
    "    dontWant_restaurant.append(busId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df[df[\"categories\"].isin(dontWantRestaurantString2)].business_num_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df[df[\"categories\"].isin(dontWantRestaurantString2)].business_num_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dontWant_restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store similarity matrices\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\UU_explicit.npy\",UU_similarity_explicit)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\UU_implicit.npy\",UU_similarity_implicit)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\II_usingIU.npy\",II_similarity_usingUI)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\II_usingIK.npy\", II_similarity_usingIK)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\II_usingIC.npy\",II_similarity_usingIC)\n",
    "\n",
    "UU_similarity_implicit = np.load('..\\\\data\\\\userStudy\\\\UU_implicit.npy')\n",
    "II_similarity_usingIK = np.load('..\\\\data\\\\userStudy\\\\II_usingIK.npy')\n",
    "II_similarity_usingIC = np.load('..\\\\data\\\\userStudy\\\\II_usingIC.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial User Input Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Popularity Metrics\n",
    "#### get the popular items in three ways\n",
    "1. avg stars\n",
    "2. number of reviews\n",
    "3. percentage liked\n",
    "\n",
    "The small analysis and the map are in the Analyse_3_ways_of_popularities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of reviews popularity list, redundent with the output of the next method\n",
    "dff_popular = df.copy()\n",
    "dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "#Get the list of restaurants accoridng to their popularity level\n",
    "popular_list = dff_popular[\"business_num_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3998/3998 [03:47<00:00, 16.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# get number of users and number of items\n",
    "numUsers = rtrain.shape[0]\n",
    "numItems = rtrain.shape[1]\n",
    "\n",
    "# get the 1d array of avg. stars, number of reviews and percentage liked ratio for the three popular metric\n",
    "popular_list_num_of_reviews,popular_list_avg_stars,popular_list_liked_ratio = get_three_popularity_matrix(df,rtrain)\n",
    "\n",
    "#Filter out restuarants not for meals\n",
    "popular_list_num_of_reviews = np.asarray([x for x in popular_list_num_of_reviews if x not in dontWant_restaurant])\n",
    "popular_list_avg_stars = np.asarray([x for x in popular_list_avg_stars if x not in dontWant_restaurant])\n",
    "popular_list_liked_ratio = np.asarray([x for x in popular_list_liked_ratio if x not in dontWant_restaurant])\n",
    "\n",
    "# transfer to a matrix(list * number of users)\n",
    "matrix_popular_list_num_of_reviews = np.tile(popular_list_num_of_reviews,(numUsers+1,1))\n",
    "#for propos, when taking in user data\n",
    "matrix_popular_list_avg_stars = np.tile(popular_list_avg_stars,(numUsers+1,1))\n",
    "#for recommendation\n",
    "matrix_popular_list_liked_ratio = np.tile(popular_list_liked_ratio,(numUsers+1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend 3 lists for three locations by using \"popular_list_liked_ratio\" method\n",
    "\n",
    "Note that the input of the geographical_dist method can only be list or n-d array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# get a copy of df\n",
    "df_location = df.copy()\n",
    "\n",
    "# three locations for user input\n",
    "yonge_and_finch = Point(\"43.779824, -79.415665\")\n",
    "bloor_and_bathurst = Point(\"43.665194,-79.411208\")\n",
    "queen_and_spadina = Point(\"43.648772,-79.396259\")\n",
    "\n",
    "# three locations for user recommendation\n",
    "bloor_and_yonge = Point(\"43.670409,-79.386814\")\n",
    "dundas_and_yonge = Point(\"43.6561,-79.3802\")\n",
    "spadina_and_dundas = Point(\"43.653004,-79.398082\")\n",
    "\n",
    "# list of percentage liked ratio (transfer the format in order to feed in to the geographical_dist method)\n",
    "list_popular_list_avg_stars = popular_list_avg_stars.tolist()\n",
    "\n",
    "# popularity list for input does not need to input the user_id\n",
    "# put user_id as 0 here but it does not matter\n",
    "# bus_indexRange = 15, gives a list of 15 restaurants per location\n",
    "bus_indexRange = 15\n",
    "yonge_and_finch_list = geographical_dist(list_popular_list_avg_stars,yonge_and_finch,0, bus_indexRange)\n",
    "bloor_and_bathurst_list = geographical_dist(list_popular_list_avg_stars,bloor_and_bathurst,0, bus_indexRange)\n",
    "queen_and_spadina_list = geographical_dist(list_popular_list_avg_stars,queen_and_spadina,0, bus_indexRange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of restaurants for user demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# df_location_yonge_and_finch=df_location[df_location[\"business_num_id\"].isin(yonge_and_finch_list)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\", \"price\", \"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})\n",
    "# df_location_yonge_and_finch.head(2)\n",
    "# df_location_bloor_and_bathurst_list=df_location[df_location[\"business_num_id\"].isin(bloor_and_bathurst_list)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\",\"price\",\"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})\n",
    "# df_location_bloor_and_bathurst_list.head(2)\n",
    "# df_location_queen_and_spadina_list=df_location[df_location[\"business_num_id\"].isin(queen_and_spadina_list)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\",\"price\",\"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})\n",
    "# df_location_queen_and_spadina_list.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the dictionary to be used for UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the dictionary to be used for UI \n",
    "#0 is hard coded, not used for now \n",
    "dict1_yongeFinch = constructResDictionary(0, bus_indexRange, yonge_and_finch_list)\n",
    "dict2_bloorBathurst = constructResDictionary(0, bus_indexRange, bloor_and_bathurst_list)\n",
    "dict3_queenSpadina = constructResDictionary(0, bus_indexRange, queen_and_spadina_list)\n",
    "\n",
    "\n",
    "#These construct the restaurant name : business id dictionary for initial user setting\n",
    "RestaurantBusId = {}\n",
    "\n",
    "# yonge_and_finch_list\n",
    "# bloor_and_bathurst_list\n",
    "# queen_and_spadina_list\n",
    "restYF = list(dict1_yongeFinch.keys())\n",
    "restBB = list(dict2_bloorBathurst.keys())\n",
    "restQS = list(dict3_queenSpadina.keys())\n",
    "\n",
    "#loop through all items\n",
    "for count in range(len(yonge_and_finch_list)):\n",
    "    RestaurantBusId[restYF[count]] = yonge_and_finch_list[count]\n",
    "    RestaurantBusId[restBB[count]] = bloor_and_bathurst_list[count]\n",
    "    RestaurantBusId[restQS[count]] = queen_and_spadina_list[count]\n",
    "\n",
    "#RestaurantBusId\n",
    "\n",
    "#Validation \n",
    "#Get the business information for the recommended business \n",
    "# businessSeries = df[df[\"business_num_id\"] == 1904].iloc[0]\n",
    "# #Get the business name \n",
    "# businessSeries['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial user setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected restaurants: ['Sushi Bong', 'Artisan Noodle', 'Sang-Ji Fried Bao', \"Little Piggy's\", 'Mr.Tonkatsu', 'Sunrise House', 'Mira', 'Kiin', 'Khao San Road']\n",
      "Your scores given to the restaurants ['5', '4', '3', '4', '5', '4', '5', '4', '4']\n",
      "Your final choice is : {'Sushi Bong': 5, 'Artisan Noodle': 4, 'Sang-Ji Fried Bao': 3, \"Little Piggy's\": 4, 'Mr.Tonkatsu': 5, 'Sunrise House': 4, 'Mira': 5, 'Kiin': 4, 'Khao San Road': 4}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Initiate a frame or master? \n",
    "    tk = Tk()\n",
    "    Label(tk, text='List of restaurants from 3 locations - choose 3 each').pack()\n",
    "    #Label(tk, text='List of restaurants from 3 locations - choose 3 each').grid()\n",
    "    \n",
    "    #Creating the multi-listbox object, pass in a tuple of tuple (lists), this will be the list objects\n",
    "    initialSetuUp = MultiListbox_Initialize(tk, (('Yonge & Finch Intersection', 20), ('Bloor & Bathurst Intersection', 20), \\\n",
    "                            ('Queen & Spadina Intersection', 20)),list(dict1_yongeFinch.keys()),list(dict2_bloorBathurst.keys()),\\\n",
    "                                 list(dict3_queenSpadina.keys()))\n",
    "\n",
    "    #loop through the length of recommend list, # = 5 \n",
    "    for index in range(len(dict1_yongeFinch)):\n",
    "        #First restaurant information to display \n",
    "        #Following the restaurants' name \n",
    "        restList1 = list(dict1_yongeFinch.keys())[index]\n",
    "        restList2 = list(dict2_bloorBathurst.keys())[index]\n",
    "        restList3 = list(dict3_queenSpadina.keys())[index]\n",
    "        \n",
    "        initialSetuUp.insert(END, (' ', ' ', ' '))\n",
    "        \n",
    "        #Inserting the restaurant names\n",
    "        initialSetuUp.insert(END, ('%d: %s' % (index + 1, restList1),'%d: %s' % (index + 1, restList2),\n",
    "                         '%d: %s' % (index + 1, restList3)))\n",
    "        \n",
    "        #Looping through each attribute keys - resinfo\n",
    "        for resinfo in dict1_yongeFinch.get(restList1).keys():\n",
    "            restList1Info = resinfo + ':' + str(dict1_yongeFinch.get(restList1).get(resinfo,''))\n",
    "            restList2Info = resinfo + ':' + str(dict2_bloorBathurst.get(restList2).get(resinfo,''))\n",
    "            restList3Info = resinfo + ':' + str(dict3_queenSpadina.get(restList3).get(resinfo,''))\n",
    "            \n",
    "            initialSetuUp.insert(END, (restList1Info, restList2Info, restList3Info))\n",
    "        \n",
    "        initialSetuUp.insert(END, ('----------------', '----------------', '----------------'))\n",
    "    \n",
    "    initialSetuUp.pack(expand=YES,fill=BOTH)\n",
    "    #initialSetuUp.grid(expand=YES,fill=BOTH)\n",
    "\n",
    "    tk.mainloop()\n",
    "    \n",
    "    #Get user response\n",
    "    UserInitialResponse = initialSetuUp.responseDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of restaurant names the user has been to \n",
    "selectedBusiness  = list(UserInitialResponse.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sushi Bong',\n",
       " 'Artisan Noodle',\n",
       " 'Sang-Ji Fried Bao',\n",
       " \"Little Piggy's\",\n",
       " 'Mr.Tonkatsu',\n",
       " 'Sunrise House',\n",
       " 'Mira',\n",
       " 'Kiin',\n",
       " 'Khao San Road']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedBusiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantFilter = list(df[df['name'].isin(selectedBusiness)].business_num_id.unique())\n",
    "#Add in the restaurants we don't want to recommend\n",
    "for busId in dontWant_restaurant:\n",
    "    restaurantFilter.append(busId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[868,\n",
       " 1643,\n",
       " 1450,\n",
       " 3371,\n",
       " 2933,\n",
       " 2399,\n",
       " 680,\n",
       " 2664,\n",
       " 3482,\n",
       " 1557,\n",
       " 1363,\n",
       " 54,\n",
       " 926,\n",
       " 2071,\n",
       " 3661,\n",
       " 869,\n",
       " 2985,\n",
       " 3914,\n",
       " 2757,\n",
       " 2143,\n",
       " 3708,\n",
       " 1839,\n",
       " 2720,\n",
       " 3327,\n",
       " 3175,\n",
       " 71,\n",
       " 703,\n",
       " 1396,\n",
       " 3943,\n",
       " 525,\n",
       " 130,\n",
       " 2891,\n",
       " 2439,\n",
       " 939,\n",
       " 1964,\n",
       " 719,\n",
       " 408,\n",
       " 1270,\n",
       " 2842,\n",
       " 193,\n",
       " 1993,\n",
       " 1917,\n",
       " 3656,\n",
       " 274,\n",
       " 2331,\n",
       " 1946,\n",
       " 2949,\n",
       " 947,\n",
       " 649,\n",
       " 2637,\n",
       " 34,\n",
       " 213,\n",
       " 748,\n",
       " 2326,\n",
       " 442,\n",
       " 2203,\n",
       " 2817,\n",
       " 3933,\n",
       " 2781,\n",
       " 2373,\n",
       " 1915,\n",
       " 1981,\n",
       " 617,\n",
       " 3517,\n",
       " 3527,\n",
       " 3809,\n",
       " 3373,\n",
       " 2687,\n",
       " 16,\n",
       " 1570,\n",
       " 2721,\n",
       " 3515,\n",
       " 3764,\n",
       " 662,\n",
       " 2315,\n",
       " 2352,\n",
       " 702,\n",
       " 3,\n",
       " 516,\n",
       " 1859,\n",
       " 589,\n",
       " 990,\n",
       " 897,\n",
       " 789,\n",
       " 2545,\n",
       " 1726,\n",
       " 369,\n",
       " 2458,\n",
       " 3766,\n",
       " 3507,\n",
       " 1545,\n",
       " 2402,\n",
       " 3813,\n",
       " 1437,\n",
       " 2727,\n",
       " 3684,\n",
       " 3481,\n",
       " 3064,\n",
       " 2900,\n",
       " 1323,\n",
       " 1103,\n",
       " 2205,\n",
       " 3202,\n",
       " 296,\n",
       " 2573,\n",
       " 3403,\n",
       " 227,\n",
       " 3106,\n",
       " 1555,\n",
       " 2413,\n",
       " 255,\n",
       " 3218,\n",
       " 1503,\n",
       " 2503,\n",
       " 2988,\n",
       " 3486,\n",
       " 29,\n",
       " 374,\n",
       " 1496,\n",
       " 2354,\n",
       " 1518,\n",
       " 2487,\n",
       " 2266,\n",
       " 791,\n",
       " 161,\n",
       " 3105,\n",
       " 1315,\n",
       " 11,\n",
       " 2612,\n",
       " 3098,\n",
       " 302,\n",
       " 2053,\n",
       " 3946,\n",
       " 1745,\n",
       " 930,\n",
       " 191,\n",
       " 1476,\n",
       " 671,\n",
       " 3020,\n",
       " 1484,\n",
       " 2614,\n",
       " 1728,\n",
       " 3532,\n",
       " 1287,\n",
       " 878,\n",
       " 3791,\n",
       " 3291,\n",
       " 1309,\n",
       " 1932,\n",
       " 3840,\n",
       " 3307,\n",
       " 3237,\n",
       " 1063,\n",
       " 389,\n",
       " 768,\n",
       " 1446,\n",
       " 2043,\n",
       " 929,\n",
       " 3798,\n",
       " 1802,\n",
       " 1004,\n",
       " 845,\n",
       " 603,\n",
       " 1923,\n",
       " 50,\n",
       " 1101,\n",
       " 2257,\n",
       " 909,\n",
       " 3937,\n",
       " 2695,\n",
       " 2976,\n",
       " 3227,\n",
       " 2041,\n",
       " 2405,\n",
       " 1038,\n",
       " 1740,\n",
       " 1383,\n",
       " 3212,\n",
       " 1381,\n",
       " 1565,\n",
       " 3913,\n",
       " 1422,\n",
       " 2590,\n",
       " 2894,\n",
       " 1086,\n",
       " 2794,\n",
       " 895,\n",
       " 650,\n",
       " 1249,\n",
       " 3398,\n",
       " 843,\n",
       " 1897,\n",
       " 3491,\n",
       " 2799,\n",
       " 3456,\n",
       " 3557,\n",
       " 2715,\n",
       " 3945,\n",
       " 576,\n",
       " 1930,\n",
       " 668,\n",
       " 3569,\n",
       " 2628,\n",
       " 3245,\n",
       " 1998,\n",
       " 798,\n",
       " 3143,\n",
       " 621,\n",
       " 2955,\n",
       " 963,\n",
       " 124,\n",
       " 1781,\n",
       " 2451,\n",
       " 1224,\n",
       " 1516,\n",
       " 1140,\n",
       " 484,\n",
       " 3759,\n",
       " 2772,\n",
       " 1139,\n",
       " 3867,\n",
       " 2068,\n",
       " 252,\n",
       " 1029,\n",
       " 3850,\n",
       " 1407,\n",
       " 2574,\n",
       " 916,\n",
       " 3409,\n",
       " 2872,\n",
       " 2915,\n",
       " 3997,\n",
       " 2287,\n",
       " 3191,\n",
       " 2753,\n",
       " 430,\n",
       " 211,\n",
       " 3362,\n",
       " 747,\n",
       " 2527,\n",
       " 3450,\n",
       " 1940,\n",
       " 3655,\n",
       " 1895,\n",
       " 2761,\n",
       " 3917,\n",
       " 2540,\n",
       " 1562,\n",
       " 3807,\n",
       " 1477,\n",
       " 77,\n",
       " 3099,\n",
       " 1612,\n",
       " 33,\n",
       " 282,\n",
       " 1812,\n",
       " 1522,\n",
       " 881,\n",
       " 2910,\n",
       " 3600,\n",
       " 919,\n",
       " 2075,\n",
       " 2631,\n",
       " 3357,\n",
       " 426,\n",
       " 2340,\n",
       " 1374,\n",
       " 1550,\n",
       " 3790,\n",
       " 2597,\n",
       " 1944,\n",
       " 3251,\n",
       " 3322,\n",
       " 600,\n",
       " 2263,\n",
       " 1941,\n",
       " 2984,\n",
       " 3932,\n",
       " 2390,\n",
       " 209,\n",
       " 3555,\n",
       " 1117,\n",
       " 1356,\n",
       " 178,\n",
       " 632,\n",
       " 1449,\n",
       " 3890,\n",
       " 1775,\n",
       " 1018,\n",
       " 1486,\n",
       " 2843,\n",
       " 280,\n",
       " 2165,\n",
       " 459,\n",
       " 1052,\n",
       " 422,\n",
       " 1443,\n",
       " 1090,\n",
       " 3232,\n",
       " 1771,\n",
       " 578,\n",
       " 1879,\n",
       " 557,\n",
       " 1784,\n",
       " 3213,\n",
       " 1949,\n",
       " 3394,\n",
       " 1523,\n",
       " 418,\n",
       " 1008,\n",
       " 3016,\n",
       " 1850,\n",
       " 1064,\n",
       " 796,\n",
       " 1623,\n",
       " 533,\n",
       " 2685,\n",
       " 673,\n",
       " 2375,\n",
       " 1525,\n",
       " 1627,\n",
       " 1406,\n",
       " 1474,\n",
       " 1379,\n",
       " 392,\n",
       " 3799,\n",
       " 2606,\n",
       " 1010,\n",
       " 3042,\n",
       " 1808,\n",
       " 3700,\n",
       " 1289,\n",
       " 1059,\n",
       " 2542,\n",
       " 234,\n",
       " 1353,\n",
       " 1586,\n",
       " 1575,\n",
       " 144,\n",
       " 3317,\n",
       " 1754,\n",
       " 1765,\n",
       " 1402,\n",
       " 368,\n",
       " 2880,\n",
       " 1894,\n",
       " 1877,\n",
       " 2208,\n",
       " 406,\n",
       " 1247,\n",
       " 1598,\n",
       " 225,\n",
       " 1492,\n",
       " 1190,\n",
       " 2190,\n",
       " 1113,\n",
       " 241,\n",
       " 1823,\n",
       " 597,\n",
       " 2231,\n",
       " 3462,\n",
       " 714,\n",
       " 2577,\n",
       " 658,\n",
       " 1348,\n",
       " 125,\n",
       " 1084,\n",
       " 3234,\n",
       " 1635,\n",
       " 182,\n",
       " 3884,\n",
       " 419,\n",
       " 958,\n",
       " 987,\n",
       " 3694,\n",
       " 744,\n",
       " 808,\n",
       " 2013,\n",
       " 2683,\n",
       " 2674,\n",
       " 1274,\n",
       " 3411,\n",
       " 2730,\n",
       " 3732,\n",
       " 488,\n",
       " 1364,\n",
       " 1701,\n",
       " 2021,\n",
       " 2039,\n",
       " 2308,\n",
       " 1091,\n",
       " 1088,\n",
       " 1276,\n",
       " 1499,\n",
       " 1421,\n",
       " 810,\n",
       " 3353,\n",
       " 3072,\n",
       " 177,\n",
       " 913,\n",
       " 2743,\n",
       " 1268,\n",
       " 2994,\n",
       " 988,\n",
       " 2980,\n",
       " 3654,\n",
       " 2609,\n",
       " 3407,\n",
       " 2591,\n",
       " 721,\n",
       " 293,\n",
       " 3172,\n",
       " 2844,\n",
       " 3889,\n",
       " 3749,\n",
       " 595,\n",
       " 3691,\n",
       " 3504,\n",
       " 2293,\n",
       " 2972,\n",
       " 1409,\n",
       " 3559,\n",
       " 1316,\n",
       " 3094,\n",
       " 2268,\n",
       " 2074,\n",
       " 3081,\n",
       " 553,\n",
       " 2700,\n",
       " 481,\n",
       " 3615,\n",
       " 1207,\n",
       " 1753,\n",
       " 565,\n",
       " 3939,\n",
       " 3054,\n",
       " 452,\n",
       " 118,\n",
       " 1195,\n",
       " 1417,\n",
       " 717,\n",
       " 2359,\n",
       " 3812,\n",
       " 1352,\n",
       " 937,\n",
       " 996,\n",
       " 3278,\n",
       " 1169,\n",
       " 2073,\n",
       " 1984,\n",
       " 1553,\n",
       " 3511,\n",
       " 113,\n",
       " 3369,\n",
       " 9,\n",
       " 2528,\n",
       " 391,\n",
       " 268,\n",
       " 1668,\n",
       " 1507,\n",
       " 4,\n",
       " 2802,\n",
       " 1682,\n",
       " 1716,\n",
       " 3919,\n",
       " 1996,\n",
       " 2826,\n",
       " 1524,\n",
       " 3535,\n",
       " 3942,\n",
       " 3669,\n",
       " 1434,\n",
       " 3334,\n",
       " 727,\n",
       " 773,\n",
       " 1574,\n",
       " 2484,\n",
       " 3255,\n",
       " 2411,\n",
       " 1974,\n",
       " 1924,\n",
       " 629,\n",
       " 2722,\n",
       " 1481,\n",
       " 325,\n",
       " 605,\n",
       " 2265,\n",
       " 1141,\n",
       " 1124,\n",
       " 2464,\n",
       " 138,\n",
       " 2986,\n",
       " 347,\n",
       " 1815,\n",
       " 3466,\n",
       " 3950,\n",
       " 1262,\n",
       " 2952,\n",
       " 3907,\n",
       " 143,\n",
       " 2549,\n",
       " 2531,\n",
       " 1768,\n",
       " 1921,\n",
       " 128,\n",
       " 95,\n",
       " 3762,\n",
       " 767,\n",
       " 3050,\n",
       " 879,\n",
       " 1483,\n",
       " 3258,\n",
       " 2274,\n",
       " 207,\n",
       " 1579,\n",
       " 3523,\n",
       " 3641,\n",
       " 1927,\n",
       " 1824,\n",
       " 366,\n",
       " 2431,\n",
       " 3199,\n",
       " 509,\n",
       " 2118,\n",
       " 968,\n",
       " 297,\n",
       " 303,\n",
       " 2682,\n",
       " 1495,\n",
       " 1795,\n",
       " 1703,\n",
       " 1926,\n",
       " 2129,\n",
       " 2115,\n",
       " 3406,\n",
       " 2764,\n",
       " 2059,\n",
       " 1864,\n",
       " 2779,\n",
       " 2636,\n",
       " 3275,\n",
       " 3647,\n",
       " 83,\n",
       " 2995,\n",
       " 2665,\n",
       " 1076,\n",
       " 3352,\n",
       " 2031,\n",
       " 2660,\n",
       " 1670,\n",
       " 423]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurantFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0] [1643 3371 2664  680 1450 3482 1363 1557 2399] [5 4 3 4 5 4 5 4 4]\n"
     ]
    }
   ],
   "source": [
    "#Process user inputs\n",
    "assert len(UserInitialResponse) ==9,\"User response has duplicates!\"\n",
    "\n",
    "import statistics \n",
    "#Get row lis\n",
    "rowList = [0] * len(UserInitialResponse)\n",
    "#Get col list\n",
    "colList = []\n",
    "#Get data list\n",
    "dataList = []\n",
    "\n",
    "for resName, rating in UserInitialResponse.items():\n",
    "    #Append the bus_num_id as column values\n",
    "    #RestaurantBusId mapps restuarnt names to business ids\n",
    "    colList.append(RestaurantBusId[resName])\n",
    "    dataList.append(rating)\n",
    "\n",
    "userAvg = statistics.mean(dataList) \n",
    "dataWuserAvgList = np.array(dataList) - np.array([userAvg] * len(UserInitialResponse))+ 0.001\n",
    "rows = np.array(rowList)\n",
    "cols = np.array(colList)\n",
    "data = np.array(dataList)\n",
    "dataWuser = np.array(dataWuserAvgList) \n",
    "print(rows, cols,data)\n",
    "\n",
    "#Get explicit data\n",
    "userSetUpMatrix = csr_matrix((data, (rows, cols)), shape=(1, rtrain.shape[1]))\n",
    "#Get with user rating\n",
    "userSetUpMatrix_WuserAvg = csr_matrix((dataWuser, (rows, cols)), shape=(1, rtrain.shape[1]))\n",
    "\n",
    "#Generate Implicit user rating vector\n",
    "implicitUserSetUpMtx = csr_matrix((data, (rows, cols)), shape=(1, rtrain.shape[1]))\n",
    "implicitUserSetUpMtx[(userSetUpMatrix > 3).nonzero()] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !Stacking new user data with original data, ONLY RUN ONCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6101x3998 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 180041 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This would overwrite rtrain,rtrain_implicit, and rtrain_WuserAvg\n",
    "csr_vappend(rtrain,userSetUpMatrix)\n",
    "csr_vappend(rtrain_implicit, implicitUserSetUpMtx)\n",
    "#csr_vappend(rtrain_userAvg, userSetUpMatrix_WuserAvg)\n",
    "\n",
    "#User_index = #This should be the user index rtrain.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity score for new user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update rtrain similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6100 * 6100\n",
    "#should import \n",
    "initial_rtrain_similarity = np.load('..\\\\data\\\\userStudy\\\\UU_explicit.npy')\n",
    "\n",
    "#Compute the similarity vector for the new user 1*6101\n",
    "newSimilarityVector_explicit = cosine_similarity(X=userSetUpMatrix, Y=rtrain, dense_output=True)\n",
    "\n",
    "#new user similarity row\n",
    "# 1 * 6100\n",
    "newSimilarity_row = newSimilarityVector_explicit[0][:-1]\n",
    "newSimilarity_row = np.expand_dims(newSimilarity_row, axis=0)\n",
    "\n",
    "#new user similarity column\n",
    "# 6101 * 1\n",
    "newSimilarity_col = newSimilarityVector_explicit.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6100)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newSimilarity_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack the bottom row\n",
    "new_rtrain_similarity = np.vstack((initial_rtrain_similarity, newSimilarity_row))\n",
    "\n",
    "#stack the last column\n",
    "#new trains similarity: 6101 * 6100, new similarity_col: 6101 * 1\n",
    "new_rtrain_similarity = np.hstack((new_rtrain_similarity, newSimilarity_col))\n",
    "\n",
    "#validation\n",
    "#(new_rtrain_similarity[-1,:] == newSimilarity_row).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update rtrain_implicit similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial rtrain implicit similarity: 6100 * 6100\n",
    "#should import \n",
    "initial_rtrainImplicit_similarity = np.load('..\\\\data\\\\userStudy\\\\UU_implicit.npy')\n",
    "\n",
    "#Compute the similarity vector for the new user 1*6101\n",
    "newSimilarityVector_implicit = cosine_similarity(X=implicitUserSetUpMtx, Y=rtrain_implicit, dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new user similarity row\n",
    "# 1 * 6100\n",
    "newSimilarity_implicit_row = newSimilarityVector_implicit[0][:-1]\n",
    "newSimilarity_implicit_row = np.expand_dims(newSimilarity_implicit_row, axis=0)\n",
    "\n",
    "#new user similarity column\n",
    "# 6101 * 1\n",
    "newSimilarity_implicit_col = newSimilarityVector_implicit.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack the bottom row\n",
    "new_rtrainImplicit_similarity = np.vstack((initial_rtrainImplicit_similarity, newSimilarity_implicit_row))\n",
    "\n",
    "#stack the last column\n",
    "#new trains similarity: 6101 * 6100, new similarity_col: 6101 * 1\n",
    "new_rtrainImplicit_similarity = np.hstack((new_rtrainImplicit_similarity, newSimilarity_implicit_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-rating KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implicit User-rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:16<00:00, 361.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:01<00:00, 4109.47it/s]\n"
     ]
    }
   ],
   "source": [
    "#UU similarity, using cosine similarity\n",
    "#similarity_2 = train(rtrain_implicit)\n",
    "UI_predictionScore_Implicit = predict(rtrain_implicit, 100, new_rtrainImplicit_similarity, item_similarity_en= False)\n",
    "UI_predict_Implicit = prediction(UI_predictionScore_Implicit, 50, rtrain_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out visited restaurants\n",
    "tr = UI_predict_Implicit[rtrain.shape[0]-1]\n",
    "tr = [x for x in tr if x not in restaurantFilter]\n",
    "lenDiff = len(UI_predict_Implicit[rtrain.shape[0]-1]) - len(tr)\n",
    "tr = tr + [0] * lenDiff\n",
    "UI_predict_Implicit[rtrain.shape[0]-1] = np.array(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implicit similarity, Explicit user-rating combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:16<00:00, 362.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:01<00:00, 4062.06it/s]\n"
     ]
    }
   ],
   "source": [
    "#similarity_3 = train(rtrain_implicit)\n",
    "#get a user-item matrix  UI prediction\n",
    "#Predict using UI matrix with ratings in it \n",
    "UI_predictionScore_IECombined = predict(rtrain, 100, new_rtrainImplicit_similarity, item_similarity_en= False)\n",
    "UI_predict_IECombined = prediction(UI_predictionScore_IECombined, 50, rtrain)\n",
    "# user_item_res1 = evaluate(UI_predict_IECombined, rvalid)\n",
    "# user_item_res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out visited restaurants\n",
    "tr = UI_predict_IECombined[rtrain.shape[0]-1]\n",
    "tr = [x for x in tr if x not in restaurantFilter]\n",
    "lenDiff = len(UI_predict_IECombined[rtrain.shape[0]-1]) - len(tr)\n",
    "tr = tr + [0] * lenDiff\n",
    "UI_predict_IECombined[rtrain.shape[0]-1] = np.array(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Item_based TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3998/3998 [00:04<00:00, 946.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:01<00:00, 3602.32it/s]\n"
     ]
    }
   ],
   "source": [
    "II_similarity_IK = np.load('..\\\\data\\\\userStudy\\\\II_usingIK.npy')\n",
    "item_based_prediction_score4 = predict(rtrain, 10, II_similarity_IK, item_similarity_en= True)\n",
    "#for each restuarant top50 users \n",
    "Item_predict_tfidf = prediction(item_based_prediction_score4, 50, rtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out visited restaurants\n",
    "tr = Item_predict_tfidf[rtrain.shape[0]-1]\n",
    "tr = [x for x in tr if x not in restaurantFilter]\n",
    "lenDiff = len(Item_predict_tfidf[rtrain.shape[0]-1]) - len(tr)\n",
    "tr = tr + [0] * lenDiff\n",
    "Item_predict_tfidf[rtrain.shape[0]-1] = np.array(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Item_based IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3998/3998 [00:03<00:00, 1112.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:01<00:00, 3782.51it/s]\n"
     ]
    }
   ],
   "source": [
    "item_based_prediction_IC = predict(rtrain, 10, II_similarity_usingIC, item_similarity_en= True)\n",
    "#for each restuarant top50 users \n",
    "Item_predict_IC = prediction(item_based_prediction_IC, 50, rtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out visited restaurants\n",
    "tr = Item_predict_IC[rtrain.shape[0]-1]\n",
    "tr = [x for x in tr if x not in restaurantFilter]\n",
    "lenDiff = len(Item_predict_IC[rtrain.shape[0]-1]) - len(tr)\n",
    "tr = tr + [0] * lenDiff\n",
    "Item_predict_IC[rtrain.shape[0]-1] = np.array(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Section: Produce the list of restaurants close to the set location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Remember to manually change this userIndex!!!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# three locations for user recommendation\n",
    "intersection = [bloor_and_yonge,dundas_and_yonge,spadina_and_dundas]\n",
    "# get 3 items for each location\n",
    "businessIndexRange = 3\n",
    "# 5 metrics and store them in a list\n",
    "metric = [UI_predict_Implicit, matrix_popular_list_liked_ratio, UI_predict_IECombined, Item_predict_IC, Item_predict_tfidf]\n",
    "\n",
    "# manually enter this number!!!!!!\n",
    "userIndex = rtrain.shape[0]\n",
    "\n",
    "#Need this number to perform the user test, so don't repeat, don't mess up\n",
    "userTestNumber = random.randint(1,1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** userIndex: 6101 userTestNumber on file: 328 **********************\n"
     ]
    }
   ],
   "source": [
    "print('********************** userIndex:',userIndex, 'userTestNumber on file:', userTestNumber,'**********************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the recommendations for each metric using loops, store in the res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# get 3 top recommendations for each locations\n",
    "# store three locations in one list for each metric\n",
    "\n",
    "#loop through the 5 recommendation algorithms, initialize the res list \n",
    "res = [[] for i in range(len(metric))]\n",
    "#Loop through the intersections \n",
    "for i in range(len(intersection)):\n",
    "    #loop through each metric \n",
    "    for j in range(len(metric)):\n",
    "        temp = geographical_dist(metric[j],intersection[i],userIndex-1,businessIndexRange)\n",
    "        res[j] += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1252, 2159, 2938, 2857, 1490],\n",
       " [2604, 2564, 2486, 2652, 2643, 2535, 2602, 2659, 2669],\n",
       " [1252, 2159, 2938, 2857, 1490],\n",
       " [2740, 2652, 1150, 1459],\n",
       " [3553, 3497, 2264, 363, 2882, 3595]]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 recommendations for each metric\n",
    "# the sequence is -> [UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf]\n",
    "# get three recommendations for each location, so the len for each row is 3*3\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look back the the origal prediction matrix and rearrange the recommendations list, choose the top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = []\n",
    "#loop through the elements in the res list (5 recommend lists)\n",
    "for element in range(len(res)):\n",
    "    dic = {}\n",
    "    #loop through each element in the recomemndation list (order:element)\n",
    "    for i in range(len(res[element])):\n",
    "        #if the recommendation is a list \n",
    "        if isinstance(metric[element], list):\n",
    "            dic[metric[element].index(res[element][i])] = res[element][i]\n",
    "        #if the recommendation is a matrix \n",
    "        else:\n",
    "            dic[metric[element][userIndex-1].tolist().index(res[element][i])] = res[element][i]\n",
    "    temp = []\n",
    "    for j in sorted(dic.keys()):\n",
    "        temp.append(int(dic[j]))\n",
    "    res_final.append(temp[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2938, 2857, 2159],\n",
       " [2602, 2604, 2564],\n",
       " [2938, 2857, 2159],\n",
       " [1150, 2740, 1459],\n",
       " [3553, 363, 3497]]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final recommendations for each metric\n",
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match restaurant information according to business_num_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current sequence: UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = [UI_predict_Implicit, matrix_popular_list_avg_stars, UI_predict_IECombined, Item_predict_IC, Item_predict_tfidf]\n",
    "#Trying to recommend for user 0 for now \n",
    "dict1_ImplicitRecommend = {}\n",
    "dict2_PopularityRecommend = {}\n",
    "dict3_EICombineRecommend = {}\n",
    "dict4_IIbasedICRecommend = {}\n",
    "dict5_IIbasedTFIDFRecommend = {}\n",
    "#User predict [user index] [item index]\n",
    "#Add a for loop for the top recommended items\n",
    "\n",
    "dict1_ImplicitRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[0])\n",
    "dict2_PopularityRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[1])\n",
    "dict3_EICombineRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[2])\n",
    "dict4_IIbasedICRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[3])\n",
    "dict5_IIbasedTFIDFRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence for now: UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list: 1\n",
      "Like: \"asdfa\", list rating: 3\n",
      "Dislike: \"sdf\", list rating: 3\n",
      "list: 2\n",
      "Like: \"asdf\", list rating: 4\n",
      "Dislike: \"asdf\", list rating: 4\n",
      "list: 3\n",
      "Like: \"asdf\", list rating: 1\n",
      "Dislike: \"asdf\", list rating: 1\n",
      "list: 4\n",
      "Like: \"asdf\", list rating: 2\n",
      "Dislike: \"asdf\", list rating: 2\n",
      "list: 5\n",
      "Like: \"asdf\", list rating: 5\n",
      "Dislike: \"asdf\", list rating: 5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Initiate a frame or master? \n",
    "    tk = Tk()\n",
    "    Label(tk, text='List of recommended restaurants').pack()\n",
    "    \n",
    "    #Creating the multi-listbox object, pass in a tuple of tuple (lists), this will be the list objects\n",
    "    mlb = MultiListbox_entries(tk, (('Implicit User-Rating', 20), ('Popularity List', 20), \\\n",
    "                            ('Explicit Implicit Combined', 20), ('Explicit Item-Rating', 20), ('TF-IDF Score of Item', 20)))\n",
    "\n",
    "    #loop through the length of recommend list, # = 5 \n",
    "    for index in range(len(dict1_ImplicitRecommend)):\n",
    "        #First restaurant information to display \n",
    "        #Following the restaurants' name \n",
    "        restList1 = list(dict1_ImplicitRecommend.keys())[index]\n",
    "        restList2 = list(dict2_PopularityRecommend.keys())[index]\n",
    "        restList3 = list(dict3_EICombineRecommend.keys())[index]\n",
    "        restList4 = list(dict4_IIbasedICRecommend.keys())[index]\n",
    "        restList5 = list(dict5_IIbasedTFIDFRecommend.keys())[index]\n",
    "        \n",
    "        mlb.insert(END, (' ', ' ', ' ', ' ', ' '))\n",
    "        \n",
    "        #Inserting the restaurant names\n",
    "        mlb.insert(END, ('%d: %s' % (index + 1, restList1),'%d: %s' % (index + 1, restList2),\n",
    "                         '%d: %s' % (index + 1, restList3),'%d: %s' % (index + 1, restList4),\n",
    "                         '%d: %s' % (index + 1, restList5)))\n",
    "        \n",
    "        #Looping through each attribute keys - resinfo\n",
    "        for resinfo in dict1_ImplicitRecommend.get(restList1).keys():\n",
    "            restList1Info = resinfo + ':' + str(dict1_ImplicitRecommend.get(restList1).get(resinfo,''))\n",
    "            restList2Info = resinfo + ':' + str(dict2_PopularityRecommend.get(restList2).get(resinfo,''))\n",
    "            restList3Info = resinfo + ':' + str(dict3_EICombineRecommend.get(restList3).get(resinfo,''))\n",
    "            restList4Info = resinfo + ':' + str(dict4_IIbasedICRecommend.get(restList4).get(resinfo,''))\n",
    "            restList5Info = resinfo + ':' + str(dict5_IIbasedTFIDFRecommend.get(restList5).get(resinfo,''))\n",
    "            \n",
    "            mlb.insert(END, (restList1Info, restList2Info, restList3Info, restList4Info, restList5Info))\n",
    "        \n",
    "        mlb.insert(END, ('----------------', '----------------', '----------------', '----------------', '----------------'))\n",
    "    \n",
    "    mlb.pack(expand=YES,fill=BOTH)\n",
    "\n",
    "    tk.mainloop()\n",
    "    \n",
    "    #Get user response\n",
    "    response = mlb.responseDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get user response\n",
    "response = mlb.responseDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['userinitialResponse'] = UserInitialResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Implicit User-Rating': {'Like': 'asdfa',\n",
       "  'listRating': '3',\n",
       "  'Dislike': 'sdf'},\n",
       " 'Popularity List': {'Like': 'asdf', 'listRating': '4', 'Dislike': 'asdf'},\n",
       " 'Explicit Implicit Combined': {'Like': 'asdf',\n",
       "  'listRating': '1',\n",
       "  'Dislike': 'asdf'},\n",
       " 'Explicit Item-Rating': {'Like': 'asdf',\n",
       "  'listRating': '2',\n",
       "  'Dislike': 'asdf'},\n",
       " 'TF-IDF Score of Item': {'Like': 'asdf',\n",
       "  'listRating': '5',\n",
       "  'Dislike': 'asdf'},\n",
       " 'userinitialResponse': {'Sushi Bong': 5,\n",
       "  'Artisan Noodle': 4,\n",
       "  'Sang-Ji Fried Bao': 3,\n",
       "  \"Little Piggy's\": 4,\n",
       "  'Mr.Tonkatsu': 5,\n",
       "  'Sunrise House': 4,\n",
       "  'Mira': 5,\n",
       "  'Kiin': 4,\n",
       "  'Khao San Road': 4}}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendationDict = {}\n",
    "recommendationDict['ImplicitRecommend'] = dict1_ImplicitRecommend\n",
    "recommendationDict['PopularityRecommend'] = dict2_PopularityRecommend\n",
    "recommendationDict['EICombineRecommend'] = dict3_EICombineRecommend\n",
    "recommendationDict['IIbasedICRecommend'] = dict4_IIbasedICRecommend\n",
    "recommendationDict['IIbasedTFIDFRecommend'] = dict5_IIbasedTFIDFRecommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the user response into local file\n",
    "csv_fileName = \"UserTestResult{:d}.json\".format(userTestNumber)\n",
    "with open('userStudyResults//'+csv_fileName, 'w') as fp:\n",
    "    json.dump(response, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#store the user recommendation into local file\n",
    "csv_fileName = \"UserTestRecommendation{:d}.csv\".format(userTestNumber)\n",
    "w = csv.writer(open(\"output.csv\", \"w\"))\n",
    "for key, val in recommendationDict.items():\n",
    "    w.writerow([key, val])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I get the user response information here, so please make sure the sequence for list names are correct when initializing our mlb object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load the result file with json \n",
    "# with open(csv_fileName, 'r') as fp:\n",
    "#     test = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 680, 1363, 1450, 1557, 1643, 2399, 2664, 3371, 3482])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the 0th user review data \n",
    "rows, cols = rtrain[rtrain.shape[0]-1].nonzero()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_num_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42716</th>\n",
       "      <td>1643</td>\n",
       "      <td>Sushi Bong</td>\n",
       "      <td>Sushi Bars, Japanese</td>\n",
       "      <td>4.0</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56469</th>\n",
       "      <td>1450</td>\n",
       "      <td>Mr.Tonkatsu</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>4.0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65585</th>\n",
       "      <td>3371</td>\n",
       "      <td>Artisan Noodle</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>3.5</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72222</th>\n",
       "      <td>2399</td>\n",
       "      <td>Khao San Road</td>\n",
       "      <td>Thai</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129109</th>\n",
       "      <td>680</td>\n",
       "      <td>Little Piggy's</td>\n",
       "      <td>Korean, Barbeque</td>\n",
       "      <td>4.0</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134039</th>\n",
       "      <td>2664</td>\n",
       "      <td>Sang-Ji Fried Bao</td>\n",
       "      <td>Noodles, Dim Sum, Soup</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161798</th>\n",
       "      <td>3482</td>\n",
       "      <td>Sunrise House</td>\n",
       "      <td>Korean</td>\n",
       "      <td>4.0</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161965</th>\n",
       "      <td>1557</td>\n",
       "      <td>Kiin</td>\n",
       "      <td>Thai</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186801</th>\n",
       "      <td>1363</td>\n",
       "      <td>Mira</td>\n",
       "      <td>Peruvian</td>\n",
       "      <td>4.5</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        business_num_id               name              categories  \\\n",
       "42716   1643             Sushi Bong         Sushi Bars, Japanese     \n",
       "56469   1450             Mr.Tonkatsu        Japanese                 \n",
       "65585   3371             Artisan Noodle     Chinese                  \n",
       "72222   2399             Khao San Road      Thai                     \n",
       "129109  680              Little Piggy's     Korean, Barbeque         \n",
       "134039  2664             Sang-Ji Fried Bao  Noodles, Dim Sum, Soup   \n",
       "161798  3482             Sunrise House      Korean                   \n",
       "161965  1557             Kiin               Thai                     \n",
       "186801  1363             Mira               Peruvian                 \n",
       "\n",
       "        business_stars  review_count  \n",
       "42716   4.0             272           \n",
       "56469   4.0             174           \n",
       "65585   3.5             106           \n",
       "72222   4.0             1428          \n",
       "129109  4.0             133           \n",
       "134039  4.0             93            \n",
       "161798  4.0             183           \n",
       "161965  4.0             150           \n",
       "186801  4.5             103           "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the corresponding business information using the business num id \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df[df[\"business_num_id\"].isin(cols)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\",\"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_yelp_df(path = 'data/', filename = 'data0.txt', sampling=False, top_user_num=6100, top_item_num=4000):\n",
    "    \"\"\"\n",
    "    Get the pandas dataframe\n",
    "    Sampling only the top users/items by density \n",
    "    Implicit representation applies\n",
    "    \"\"\"\n",
    "    with open(filename,'r') as f:\n",
    "        data = f.readlines()\n",
    "        data = list(map(json.loads, data))\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df.rename(columns={'stars': 'review_stars', 'text': 'review_text', 'cool': 'review_cool',\n",
    "                       'funny': 'review_funny', 'useful': 'review_useful'},\n",
    "              inplace=True)\n",
    "\n",
    "    df['business_num_id'] = df.business_id.astype('category').\\\n",
    "        cat.rename_categories(range(0, df.business_id.nunique()))\n",
    "    df['business_num_id'] = df['business_num_id'].astype('int')\n",
    "\n",
    "    df['user_num_id'] = df.user_id.astype('category').\\\n",
    "    cat.rename_categories(range(0, df.user_id.nunique()))\n",
    "    df['user_num_id'] = df['user_num_id'].astype('int')\n",
    "\n",
    "    df['timestamp'] = df['date'].apply(date_to_timestamp)\n",
    "\n",
    "    if sampling:\n",
    "        df = filter_yelp_df(df, top_user_num=top_user_num, top_item_num=top_item_num)\n",
    "        # Refresh num id\n",
    "        df['business_num_id'] = df.business_id.astype('category').\\\n",
    "        cat.rename_categories(range(0, df.business_id.nunique()))\n",
    "        df['business_num_id'] = df['business_num_id'].astype('int')\n",
    "        \n",
    "        df['user_num_id'] = df.user_id.astype('category').\\\n",
    "        cat.rename_categories(range(0, df.user_id.nunique()))\n",
    "        df['user_num_id'] = df['user_num_id'].astype('int')\n",
    "#     drop_list = ['date','review_id','review_funny','review_cool','review_useful']\n",
    "#     df = df.drop(drop_list, axis=1)\n",
    "\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    return df \n",
    "\n",
    "\n",
    "def filter_yelp_df(df, top_user_num=6100, top_item_num=4000):\n",
    "    #Getting the reviews where starts are above 3\n",
    "    df_implicit = df[df['review_stars']>3]\n",
    "    frequent_user_id = df_implicit['user_num_id'].value_counts().head(top_user_num).index.values\n",
    "    frequent_item_id = df_implicit['business_num_id'].value_counts().head(top_item_num).index.values\n",
    "    return df.loc[(df['user_num_id'].isin(frequent_user_id)) & (df['business_num_id'].isin(frequent_item_id))]\n",
    "\n",
    "\n",
    "def date_to_timestamp(date):\n",
    "    dt = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "    return time.mktime(dt.timetuple())\n",
    "\n",
    "def df_to_sparse(df, row_name='userId', col_name='movieId', value_name='rating',\n",
    "                 shape=(138494, 131263)):\n",
    "    rows = df[row_name]\n",
    "    cols = df[col_name]\n",
    "    if value_name is not None:\n",
    "        values = df[value_name]\n",
    "    else:\n",
    "        values = [1]*len(rows)\n",
    "\n",
    "    return csr_matrix((values, (rows, cols)), shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = get_yelp_df(path = '', filename=\"0.txt\", sampling= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_cool</th>\n",
       "      <th>date</th>\n",
       "      <th>review_funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_num_id</th>\n",
       "      <th>user_num_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vsFFbN71ehRCp46KeR5RdQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>0</td>\n",
       "      <td>OyFVGLDZ52Hl8BviXszNrw</td>\n",
       "      <td>5</td>\n",
       "      <td>Fab.U.Lous. Best scrambles eggs. Fluffy and ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0pf5VuzE4_1pwj5NJHG5TQ</td>\n",
       "      <td>3660</td>\n",
       "      <td>172</td>\n",
       "      <td>1.478405e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jj8ubiwwuCR-rrhrrjcryw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>0</td>\n",
       "      <td>3zNW-BK3YlJnGBdCxpE46g</td>\n",
       "      <td>2</td>\n",
       "      <td>Been here 3x and no beef #45, will stop coming...</td>\n",
       "      <td>0</td>\n",
       "      <td>0pf5VuzE4_1pwj5NJHG5TQ</td>\n",
       "      <td>1254</td>\n",
       "      <td>172</td>\n",
       "      <td>1.471147e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e9UsRb-fmza5ukU8Ftduew</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>1</td>\n",
       "      <td>w78rEDYoPU_PVklmfBsOWA</td>\n",
       "      <td>2</td>\n",
       "      <td>Overall rating: 2.5 for a 4:30 weekday visit (...</td>\n",
       "      <td>1</td>\n",
       "      <td>0pf5VuzE4_1pwj5NJHG5TQ</td>\n",
       "      <td>2574</td>\n",
       "      <td>172</td>\n",
       "      <td>1.467432e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7m1Oa1VYV98UUuo_6i0EZg</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>1</td>\n",
       "      <td>iJmz50_PKFNydHNK9uV86g</td>\n",
       "      <td>5</td>\n",
       "      <td>Deeeeeeeeeeellllliiiissssshhhhhh!  More than a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0pf5VuzE4_1pwj5NJHG5TQ</td>\n",
       "      <td>531</td>\n",
       "      <td>172</td>\n",
       "      <td>1.463890e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>szhJLmdLDVFTevm8fu0T4A</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>8k2WpYJFfsPL3kupmvGjWA</td>\n",
       "      <td>5</td>\n",
       "      <td>Best place for dim sum in the valley.  Prefer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0pf5VuzE4_1pwj5NJHG5TQ</td>\n",
       "      <td>3457</td>\n",
       "      <td>172</td>\n",
       "      <td>1.462075e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  review_cool        date  review_funny  \\\n",
       "0  vsFFbN71ehRCp46KeR5RdQ            0  2016-11-06             0   \n",
       "1  Jj8ubiwwuCR-rrhrrjcryw            0  2016-08-14             0   \n",
       "2  e9UsRb-fmza5ukU8Ftduew            1  2016-07-02             1   \n",
       "3  7m1Oa1VYV98UUuo_6i0EZg            0  2016-05-22             1   \n",
       "4  szhJLmdLDVFTevm8fu0T4A            0  2016-05-01             0   \n",
       "\n",
       "                review_id  review_stars  \\\n",
       "0  OyFVGLDZ52Hl8BviXszNrw             5   \n",
       "1  3zNW-BK3YlJnGBdCxpE46g             2   \n",
       "2  w78rEDYoPU_PVklmfBsOWA             2   \n",
       "3  iJmz50_PKFNydHNK9uV86g             5   \n",
       "4  8k2WpYJFfsPL3kupmvGjWA             5   \n",
       "\n",
       "                                         review_text  review_useful  \\\n",
       "0  Fab.U.Lous. Best scrambles eggs. Fluffy and ta...              0   \n",
       "1  Been here 3x and no beef #45, will stop coming...              0   \n",
       "2  Overall rating: 2.5 for a 4:30 weekday visit (...              1   \n",
       "3  Deeeeeeeeeeellllliiiissssshhhhhh!  More than a...              0   \n",
       "4  Best place for dim sum in the valley.  Prefer ...              0   \n",
       "\n",
       "                  user_id  business_num_id  user_num_id     timestamp  \n",
       "0  0pf5VuzE4_1pwj5NJHG5TQ             3660          172  1.478405e+09  \n",
       "1  0pf5VuzE4_1pwj5NJHG5TQ             1254          172  1.471147e+09  \n",
       "2  0pf5VuzE4_1pwj5NJHG5TQ             2574          172  1.467432e+09  \n",
       "3  0pf5VuzE4_1pwj5NJHG5TQ              531          172  1.463890e+09  \n",
       "4  0pf5VuzE4_1pwj5NJHG5TQ             3457          172  1.462075e+09  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rating_timestamp_matrix(df, sampling=False, top_user_num=6100, top_item_num=4000):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if sampling:\n",
    "        df = filter_yelp_df(df, top_user_num=top_user_num, top_item_num=top_item_num)\n",
    "\n",
    "    rating_matrix = df_to_sparse(df, row_name='user_num_id',\n",
    "                                 col_name='business_num_id',\n",
    "                                 value_name='review_stars',\n",
    "                                 shape=None)\n",
    "\n",
    "    timestamp_matrix = df_to_sparse(df, row_name='user_num_id',\n",
    "                                    col_name='business_num_id',\n",
    "                                    value_name='timestamp',\n",
    "                                    shape=None)\n",
    "\n",
    "    return rating_matrix, timestamp_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating_matrix, timestamp_matrix = get_rating_timestamp_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5791x3906 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 39620 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5791x3906 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 39620 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time ordered split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_ordered_split(rating_matrix, timestamp_matrix, ratio=[0.5, 0.2, 0.3],\n",
    "                       implicit=True, remove_empty=False, threshold=3,\n",
    "                       sampling=False, sampling_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split the data to train,valid,test by time\n",
    "    ratio:  train:valid:test\n",
    "    threshold: for implicit representation\n",
    "    \"\"\"\n",
    "    if implicit:\n",
    "        temp_rating_matrix = sparse.csr_matrix(rating_matrix.shape)\n",
    "        temp_rating_matrix[(rating_matrix > threshold).nonzero()] = 1\n",
    "        rating_matrix = temp_rating_matrix\n",
    "        timestamp_matrix = timestamp_matrix.multiply(rating_matrix)\n",
    "\n",
    "    nonzero_index = None\n",
    "\n",
    "    if remove_empty:\n",
    "        # Remove empty columns. record original item index\n",
    "        nonzero_index = np.unique(rating_matrix.nonzero()[1])\n",
    "        rating_matrix = rating_matrix[:, nonzero_index]\n",
    "        timestamp_matrix = timestamp_matrix[:, nonzero_index]\n",
    "\n",
    "        # Remove empty rows. record original user index\n",
    "        nonzero_rows = np.unique(rating_matrix.nonzero()[0])\n",
    "        rating_matrix = rating_matrix[nonzero_rows]\n",
    "        timestamp_matrix = timestamp_matrix[nonzero_rows]\n",
    "\n",
    "    user_num, item_num = rating_matrix.shape\n",
    "\n",
    "    rtrain = []\n",
    "    rtime = []\n",
    "    rvalid = []\n",
    "    rtest = []\n",
    "    # Get the index list corresponding to item for train,valid,test\n",
    "    item_idx_train = []\n",
    "    item_idx_valid = []\n",
    "    item_idx_test = []\n",
    "    \n",
    "    for i in tqdm(range(user_num)):\n",
    "        item_indexes = rating_matrix[i].nonzero()[1]\n",
    "        data = rating_matrix[i].data\n",
    "        timestamp = timestamp_matrix[i].data\n",
    "        num_nonzeros = len(item_indexes)\n",
    "        if num_nonzeros >= 1:\n",
    "            num_test = int(num_nonzeros * ratio[2])\n",
    "            num_valid = int(num_nonzeros * (ratio[1] + ratio[2]))\n",
    "\n",
    "            valid_offset = num_nonzeros - num_valid\n",
    "            test_offset = num_nonzeros - num_test\n",
    "\n",
    "            argsort = np.argsort(timestamp)\n",
    "            data = data[argsort]\n",
    "            item_indexes = item_indexes[argsort]\n",
    "            rtrain.append([data[:valid_offset], np.full(valid_offset, i), item_indexes[:valid_offset]])\n",
    "            rvalid.append([data[valid_offset:test_offset], np.full(test_offset - valid_offset, i),\n",
    "                           item_indexes[valid_offset:test_offset]])\n",
    "            rtest.append([data[test_offset:], np.full(num_test, i), item_indexes[test_offset:]])\n",
    "            \n",
    "            item_idx_train.append(item_indexes[:valid_offset])\n",
    "#             item_idx_valid.append(item_indexes[valid_offset:test_offset])\n",
    "#             item_idx_test.append(item_indexes[test_offset:])\n",
    "        else:\n",
    "            item_idx_train.append([])\n",
    "#             item_idx_valid.append([])\n",
    "#             item_idx_test.append([])\n",
    "    rtrain = np.array(rtrain)\n",
    "    rvalid = np.array(rvalid)\n",
    "    rtest = np.array(rtest)\n",
    "\n",
    "    rtrain = sparse.csr_matrix((np.hstack(rtrain[:, 0]), (np.hstack(rtrain[:, 1]), np.hstack(rtrain[:, 2]))),\n",
    "                               shape=rating_matrix.shape, dtype=np.float32)\n",
    "    rvalid = sparse.csr_matrix((np.hstack(rvalid[:, 0]), (np.hstack(rvalid[:, 1]), np.hstack(rvalid[:, 2]))),\n",
    "                               shape=rating_matrix.shape, dtype=np.float32)\n",
    "    rtest = sparse.csr_matrix((np.hstack(rtest[:, 0]), (np.hstack(rtest[:, 1]), np.hstack(rtest[:, 2]))),\n",
    "                              shape=rating_matrix.shape, dtype=np.float32)\n",
    "\n",
    "\n",
    "    return rtrain, rvalid, rtest, nonzero_index, timestamp_matrix, item_idx_train, item_idx_valid, item_idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5791/5791 [00:01<00:00, 2927.70it/s]\n"
     ]
    }
   ],
   "source": [
    "rtrain, rvalid, rtest, nonzero_index, rtime, item_idx_matrix_train,item_idx_matrix_valid, item_idx_matrix_test = time_ordered_split(rating_matrix=rating_matrix,timestamp_matrix=timestamp_matrix,\n",
    "                                                                     ratio=[0.5,0.2,0.3],\n",
    "                                                                     implicit=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rtrain_implicit, rvalid_implicit, rtest_implicit, nonzero_index, rtime, item_idx_matrix_train_implicit,item_idx_matrix_valid_implicit, item_idx_matrix_test_implicit = time_ordered_split(rating_matrix=rating_matrix,timestamp_matrix=timestamp_matrix,\n",
    "                                                                     ratio=[0.5,0.2,0.3],\n",
    "                                                                     implicit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get df for training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corpus_idx_list(df, item_idx_matrix):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    df: total dataframe\n",
    "    item_idx_matrix: train index list got from time_split \n",
    "    Output: row index in original dataframe for training data by time split\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    for i in tqdm(range(len(item_idx_matrix))):\n",
    "        a = df.index[df['user_num_id'] == i].tolist()\n",
    "        \n",
    "        for item_idx in  item_idx_matrix[i]:\n",
    "            b = df.index[df['business_num_id'] == item_idx].tolist()\n",
    "            idx_to_add = list(set(a).intersection(b))\n",
    "            if idx_to_add not in lst:\n",
    "                lst.extend(idx_to_add)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 5782/5791 [10:26<00:02,  4.05it/s]"
     ]
    }
   ],
   "source": [
    "lst_train = get_corpus_idx_list(df, item_idx_matrix_train)\n",
    "# Get the training dataframe from the original dataframe\n",
    "df_train = df.loc[lst_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "# Save and load df_train\n",
    "# with open('df_train.pkl', 'wb') as handle:\n",
    "#     pkl.dump(df_train, handle)\n",
    "\n",
    "# with open('df_train.pkl', 'rb') as handle:\n",
    "#     df_train = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('stemming:', u'invers')\n",
      "('lemmatization:', 'inversely')\n"
     ]
    }
   ],
   "source": [
    "#Stemming and Lemmatisation\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "word = 'inversely'\n",
    "print ('stemming:', stem.stem(word))\n",
    "print ('lemmatization:', lem.lemmatize(word, \"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of stopwords and add custom stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "# stop_words.remove('not')\n",
    "## A list of custom stopwords\n",
    "# new_words = ['using','show','result','large','also']\n",
    "new_words = ['not_the']\n",
    "stop_words = stop_words.union(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get corpus and CountVector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 66155/66155 [00:32<00:00, 2038.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# The entire corpus\n",
    "corpus = preprocess(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X row: df_train row, column: key words frequency \n",
    "cv=CountVectorizer(max_df=0.9,stop_words=stop_words, max_features=5000, ngram_range=(1,1))\n",
    "X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def train(matrix_train):\n",
    "    similarity = cosine_similarity(X=matrix_train, Y=None, dense_output=True)\n",
    "    return similarity\n",
    "\n",
    "def get_I_K(df, X, row_name = 'business_num_id', binary = True, shape = (121994,6000)):\n",
    "    \"\"\"\n",
    "    get the item-keyphrase matrix\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        arr = X[i].toarray() \n",
    "        nonzero_element = arr.nonzero()[1]  # Get nonzero element in each line\n",
    "        length_of_nonzero = len(nonzero_element) \n",
    "        # df[row_name][i] is the item idex\n",
    "        rows.extend(np.array([df[row_name][i]]*length_of_nonzero)) ## Item index\n",
    "        cols.extend(nonzero_element) ## Keyword Index\n",
    "        if binary:\n",
    "            vals.extend(np.array([1]*length_of_nonzero))\n",
    "        else:\n",
    "            vals.extend(arr[arr.nonzero()])    \n",
    "    return csr_matrix((vals, (rows, cols)), shape=shape)\n",
    "\n",
    "def predict(matrix_train, k, similarity, item_similarity_en = False):\n",
    "    prediction_scores = []\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        matrix_train = matrix_train.transpose()\n",
    "        \n",
    "    for user_index in tqdm(range(matrix_train.shape[0])):\n",
    "        # Get user u's prediction scores for all items\n",
    "        vector_u = similarity[user_index]\n",
    "\n",
    "        # Get closest K neighbors excluding user u self\n",
    "        similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "        # Get neighbors similarity weights and ratings\n",
    "        similar_users_weights = similarity[user_index][similar_users]\n",
    "        similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "\n",
    "        prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "\n",
    "        prediction_scores.append(np.sum(prediction_scores_u, axis=0))\n",
    "    res = np.array(prediction_scores)\n",
    "    if item_similarity_en:\n",
    "        res = res.transpose()\n",
    "    return res\n",
    "\n",
    "def prediction(prediction_score, topK, matrix_Train):\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    for user_index in tqdm(range(matrix_Train.shape[0])):\n",
    "        vector_u = prediction_score[user_index]\n",
    "        vector_train = matrix_Train[user_index]\n",
    "        if len(vector_train.nonzero()[0]) > 0:\n",
    "            vector_predict = sub_routine(vector_u, vector_train, topK=topK)\n",
    "        else:\n",
    "            vector_predict = np.zeros(topK, dtype=np.float32)\n",
    "\n",
    "        prediction.append(vector_predict)\n",
    "\n",
    "    return np.vstack(prediction)\n",
    "\n",
    "\n",
    "def sub_routine(vector_u, vector_train, topK=500):\n",
    "\n",
    "    train_index = vector_train.nonzero()[1]\n",
    "\n",
    "    vector_u = vector_u\n",
    "\n",
    "    candidate_index = np.argpartition(-vector_u, topK+len(train_index))[:topK+len(train_index)]\n",
    "    vector_u = candidate_index[vector_u[candidate_index].argsort()[::-1]]\n",
    "    vector_u = np.delete(vector_u, np.isin(vector_u, train_index).nonzero()[0])\n",
    "\n",
    "    return vector_u[:topK]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recallk(vector_true_dense, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "\n",
    "def precisionk(vector_predict, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_predict)\n",
    "\n",
    "\n",
    "def average_precisionk(vector_predict, hits, **unused):\n",
    "    precisions = np.cumsum(hits, dtype=np.float32)/range(1, len(vector_predict)+1)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "\n",
    "def r_precision(vector_true_dense, vector_predict, **unused):\n",
    "    vector_predict_short = vector_predict[:len(vector_true_dense)]\n",
    "    hits = len(np.isin(vector_predict_short, vector_true_dense).nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "\n",
    "def _dcg_support(size):\n",
    "    arr = np.arange(1, size+1)+1\n",
    "    return 1./np.log2(arr)\n",
    "\n",
    "\n",
    "def ndcg(vector_true_dense, vector_predict, hits):\n",
    "    idcg = np.sum(_dcg_support(len(vector_true_dense)))\n",
    "    dcg_base = _dcg_support(len(vector_predict))\n",
    "    dcg_base[np.logical_not(hits)] = 0\n",
    "    dcg = np.sum(dcg_base)\n",
    "    return dcg/idcg\n",
    "\n",
    "\n",
    "def click(hits, **unused):\n",
    "    first_hit = next((i for i, x in enumerate(hits) if x), None)\n",
    "    if first_hit is None:\n",
    "        return 5\n",
    "    else:\n",
    "        return first_hit/10\n",
    "\n",
    "\n",
    "def evaluate(matrix_Predict, matrix_Test, metric_names =['R-Precision', 'NDCG', 'Precision', 'Recall', 'MAP'], atK = [5, 10, 15, 20, 50], analytical=False):\n",
    "    \"\"\"\n",
    "    :param matrix_U: Latent representations of users, for LRecs it is RQ, for ALSs it is U\n",
    "    :param matrix_V: Latent representations of items, for LRecs it is Q, for ALSs it is V\n",
    "    :param matrix_Train: Rating matrix for training, features.\n",
    "    :param matrix_Test: Rating matrix for evaluation, true labels.\n",
    "    :param k: Top K retrieval\n",
    "    :param metric_names: Evaluation metrics\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global_metrics = {\n",
    "        \"R-Precision\": r_precision,\n",
    "        \"NDCG\": ndcg,\n",
    "        \"Clicks\": click\n",
    "    }\n",
    "\n",
    "    local_metrics = {\n",
    "        \"Precision\": precisionk,\n",
    "        \"Recall\": recallk,\n",
    "        \"MAP\": average_precisionk\n",
    "    }\n",
    "\n",
    "    output = dict()\n",
    "\n",
    "    num_users = matrix_Predict.shape[0]\n",
    "\n",
    "    for k in atK:\n",
    "\n",
    "        local_metric_names = list(set(metric_names).intersection(local_metrics.keys()))\n",
    "        results = {name: [] for name in local_metric_names}\n",
    "        topK_Predict = matrix_Predict[:, :k]\n",
    "\n",
    "        for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "            vector_predict = topK_Predict[user_index]\n",
    "            if len(vector_predict.nonzero()[0]) > 0:\n",
    "                vector_true = matrix_Test[user_index]\n",
    "                vector_true_dense = vector_true.nonzero()[1]\n",
    "                hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "                if vector_true_dense.size > 0:\n",
    "                    for name in local_metric_names:\n",
    "                        results[name].append(local_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                                 vector_predict=vector_predict,\n",
    "                                                                 hits=hits))\n",
    "\n",
    "        results_summary = dict()\n",
    "        if analytical:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = results[name]\n",
    "        else:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = (np.average(results[name]),\n",
    "                                                              1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "        output.update(results_summary)\n",
    "\n",
    "    global_metric_names = list(set(metric_names).intersection(global_metrics.keys()))\n",
    "    results = {name: [] for name in global_metric_names}\n",
    "\n",
    "    topK_Predict = matrix_Predict[:]\n",
    "\n",
    "    for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "        vector_predict = topK_Predict[user_index]\n",
    "\n",
    "        if len(vector_predict.nonzero()[0]) > 0:\n",
    "            vector_true = matrix_Test[user_index]\n",
    "            vector_true_dense = vector_true.nonzero()[1]\n",
    "            hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "            # if user_index == 1:\n",
    "            #     import ipdb;\n",
    "            #     ipdb.set_trace()\n",
    "\n",
    "            if vector_true_dense.size > 0:\n",
    "                for name in global_metric_names:\n",
    "                    results[name].append(global_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                              vector_predict=vector_predict,\n",
    "                                                              hits=hits))\n",
    "\n",
    "    results_summary = dict()\n",
    "    if analytical:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = results[name]\n",
    "    else:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = (np.average(results[name]), 1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "    output.update(results_summary)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Utility functions\n",
    "def add_two_matrix(ratio, U_I_matrix,I_K_matrix, shape = (3906, 3000+5791)):\n",
    "    # ratio determine Keywords/User in the matrix\n",
    "    rows = []\n",
    "    cols = []\n",
    "    datas = []\n",
    "    I_U_matrix = U_I_matrix.transpose()\n",
    "    \n",
    "    for i in tqdm(range(I_K_matrix.shape[0])):\n",
    "        nonzero1 = I_K_matrix[i].nonzero()\n",
    "        nonzero2 = I_U_matrix[i].nonzero()\n",
    "        row = [i]*(len(nonzero1[1])+len(nonzero2[1]))\n",
    "        col = nonzero1[1].tolist()+ nonzero2[1].tolist()\n",
    "        data = [ratio]*len(nonzero1[1])+[1-ratio]*len(nonzero2[1]) # Binary representation of I-K/U matrix\n",
    "        \n",
    "        rows.extend(row)\n",
    "        cols.extend(col)\n",
    "        datas.extend(data)\n",
    "    return csr_matrix( (datas,(rows,cols)), shape=shape )\n",
    "\n",
    "def transfer_to_implicit(rating_matrix, threshold = 0):\n",
    "    temp_rating_matrix = sparse.csr_matrix(rating_matrix.shape)\n",
    "    temp_rating_matrix[(rating_matrix > threshold).nonzero()] = 1\n",
    "    rating_matrix = temp_rating_matrix\n",
    "    return rating_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_item KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:02<00:00, 2210.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 3490.48it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity = train(rtrain)\n",
    "user_item_prediction_score = predict(rtrain, 10, similarity, item_similarity_en= False)\n",
    "user_item_predict = prediction(user_item_prediction_score, 50, rtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5642.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5549.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5367.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5580.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5575.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5053.47it/s]\n"
     ]
    }
   ],
   "source": [
    "user_item_res = evaluate(user_item_predict, rvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.02710392937964054, 0.0018589669589317238),\n",
       " 'MAP@15': (0.02523885442081032, 0.0015466265673299132),\n",
       " 'MAP@20': (0.02379531287259721, 0.0013522753982744486),\n",
       " 'MAP@5': (0.029704875722381195, 0.0024992475614289034),\n",
       " 'MAP@50': (0.01893826979833535, 0.0008669320850484647),\n",
       " 'NDCG': (0.07725899306480281, 0.0033271488690248107),\n",
       " 'Precision@10': (0.0228917690624474, 0.0013146055251977375),\n",
       " 'Precision@15': (0.02060259215620266, 0.0010445671412010298),\n",
       " 'Precision@20': (0.018860461201817877, 0.0008860460963517407),\n",
       " 'Precision@5': (0.027234472311058747, 0.0019340957052222721),\n",
       " 'Precision@50': (0.01333445547887561, 0.000525574749297669),\n",
       " 'R-Precision': (0.02768017448043488, 0.0023639578207140352),\n",
       " 'Recall@10': (0.06098453989266356, 0.004257775984290726),\n",
       " 'Recall@15': (0.08052449276592342, 0.00481523183203922),\n",
       " 'Recall@20': (0.09833807536314372, 0.005297603088858921),\n",
       " 'Recall@5': (0.03647361905747988, 0.003323868308953383),\n",
       " 'Recall@50': (0.16139346076384697, 0.006429386611429088)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item_based KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66155x5000 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 3538734 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 66155/66155 [00:11<00:00, 5886.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3987/3987 [00:09<00:00, 432.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 3132.57it/s]\n"
     ]
    }
   ],
   "source": [
    "I_K_matrix = get_I_K(df_train, X, shape = (3987, 5000))\n",
    "I_I_similarity = train(I_K_matrix)\n",
    "item_based_prediction_score = predict(rtrain, 10, I_I_similarity, item_similarity_en= True)\n",
    "item_based_predict = prediction(item_based_prediction_score, 50, rtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5595.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5595.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5549.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5611.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5585.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5057.69it/s]\n"
     ]
    }
   ],
   "source": [
    "item_based_res = evaluate(item_based_predict, rvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.012977613196431578, 0.001301836139180071),\n",
       " 'MAP@15': (0.011900690343713403, 0.001069197503725034),\n",
       " 'MAP@20': (0.011137524178044075, 0.0009266088557605926),\n",
       " 'MAP@5': (0.014530101554171575, 0.0017761721891771062),\n",
       " 'MAP@50': (0.00887961391427507, 0.0005875984691827512),\n",
       " 'NDCG': (0.034751960958586466, 0.002216054313528139),\n",
       " 'Precision@10': (0.01057061100824777, 0.0008807204823807665),\n",
       " 'Precision@15': (0.009336250911743253, 0.0006849489230783388),\n",
       " 'Precision@20': (0.008542332940582393, 0.0005897822743621817),\n",
       " 'Precision@5': (0.012826123548224207, 0.0013152530431177123),\n",
       " 'Precision@50': (0.006520787746170678, 0.0003659216042044714),\n",
       " 'R-Precision': (0.013233672384498223, 0.0015638166877467766),\n",
       " 'Recall@10': (0.025063070709347216, 0.0026219404726645756),\n",
       " 'Recall@15': (0.03323949266131971, 0.0029950856504994583),\n",
       " 'Recall@20': (0.03981375565671403, 0.003215133244664721),\n",
       " 'Recall@5': (0.016422294340609225, 0.0021923228923539204),\n",
       " 'Recall@50': (0.06923257857168126, 0.004076416394551685)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_based_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User_based KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 66155/66155 [00:10<00:00, 6142.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:09<00:00, 619.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 3566.63it/s]\n"
     ]
    }
   ],
   "source": [
    "U_K_matrix = get_I_K(df, X, row_name = 'user_num_id', shape = (6049,5000))\n",
    "U_U_similarity = train(U_K_matrix)\n",
    "user_based_prediction_score = predict(rtrain, 10, U_U_similarity, item_similarity_en= False)\n",
    "user_based_predict = prediction(user_based_prediction_score, 50, rtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5632.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5653.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5663.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5575.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5606.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5070.41it/s]\n"
     ]
    }
   ],
   "source": [
    "user_based_res = evaluate(user_based_predict, rvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.0021977487623001846, 0.0005241216960679545),\n",
       " 'MAP@15': (0.002147236393996199, 0.0004328366423481947),\n",
       " 'MAP@20': (0.002136696437473284, 0.0003779366436513026),\n",
       " 'MAP@5': (0.0023391123828760585, 0.0007188190751865096),\n",
       " 'MAP@50': (0.0020416725178185762, 0.0002522720800183391),\n",
       " 'NDCG': (0.007609778509186537, 0.0008643031748169708),\n",
       " 'Precision@10': (0.002053526342366605, 0.0003720578706948452),\n",
       " 'Precision@15': (0.002075969253212142, 0.00031378283466876246),\n",
       " 'Precision@20': (0.002045110250799529, 0.00027112454104888725),\n",
       " 'Precision@5': (0.00208719070863491, 0.0005286243523277106),\n",
       " 'Precision@50': (0.0019087695674128934, 0.00018939393655635224),\n",
       " 'R-Precision': (0.002023868423139019, 0.0005658197298234915),\n",
       " 'Recall@10': (0.003922596689846546, 0.0009169625677552557),\n",
       " 'Recall@15': (0.005564292441961419, 0.0010615318566500511),\n",
       " 'Recall@20': (0.007356171015930382, 0.0012626595789420763),\n",
       " 'Recall@5': (0.001952104582192326, 0.0006291609519337194),\n",
       " 'Recall@50': (0.01686950880692029, 0.0018306945112706839)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_based_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lambda = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:23: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n"
     ]
    }
   ],
   "source": [
    "## Change to implicit first\n",
    "I_K_matrix_implicit = transfer_to_implicit(I_K_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3987/3987 [00:02<00:00, 1441.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3987/3987 [00:08<00:00, 447.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 3233.03it/s]\n"
     ]
    }
   ],
   "source": [
    "I_K_U_matrix = add_two_matrix(0.001, rtrain_implicit, I_K_matrix_implicit, shape = (3987, 5000+6049))\n",
    "I_I_matrix_combined = train(I_K_U_matrix)\n",
    "combined_prediction_score = predict(rtrain_implicit, 10, I_I_matrix_combined, item_similarity_en= True)\n",
    "combined_predict = prediction(combined_prediction_score, 50, rtrain_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5717.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5669.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5685.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5728.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5534.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5161.26it/s]\n"
     ]
    }
   ],
   "source": [
    "combined_res = evaluate(combined_predict, rvalid_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.016551389970157, 0.0014251974368925276),\n",
       " 'MAP@15': (0.015651023401364, 0.0011796526622812828),\n",
       " 'MAP@20': (0.014921041748229969, 0.0010278370910462996),\n",
       " 'MAP@5': (0.01772649863760218, 0.0019234190361711334),\n",
       " 'MAP@50': (0.01236942415493763, 0.0006536945765055305),\n",
       " 'NDCG': (0.062282043385999374, 0.0030791327448591228),\n",
       " 'Precision@10': (0.014713896457765668, 0.0010066103007188327),\n",
       " 'Precision@15': (0.013340145322434152, 0.0008037300979764147),\n",
       " 'Precision@20': (0.012431880108991825, 0.00068452478206729),\n",
       " 'Precision@5': (0.016553133514986378, 0.0014850493813221453),\n",
       " 'Precision@50': (0.009329019073569483, 0.0004099856037731842),\n",
       " 'R-Precision': (0.01611231696960322, 0.0019191223080083394),\n",
       " 'Recall@10': (0.05408607771103389, 0.00441060139905048),\n",
       " 'Recall@15': (0.07170493951738674, 0.004979169564754949),\n",
       " 'Recall@20': (0.08685982724846508, 0.00538949160669556),\n",
       " 'Recall@5': (0.031098310449065143, 0.003396807565673421),\n",
       " 'Recall@50': (0.14630483670608876, 0.00660397773526429)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lambda = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3987/3987 [00:02<00:00, 1448.24it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3987/3987 [00:09<00:00, 428.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:02<00:00, 2926.46it/s]\n"
     ]
    }
   ],
   "source": [
    "I_K_U_matrix = add_two_matrix(0.5, rtrain_implicit, I_K_matrix_implicit, shape = (3987, 5000+6049))\n",
    "I_I_matrix_combined = train(I_K_U_matrix)\n",
    "combined_prediction_score = predict(rtrain_implicit, 10, I_I_matrix_combined, item_similarity_en= True)\n",
    "combined_predict = prediction(combined_prediction_score, 50, rtrain_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5489.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5396.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5196.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5429.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5246.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 4905.92it/s]\n"
     ]
    }
   ],
   "source": [
    "combined_res = evaluate(combined_predict, rvalid_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.01037957241252541, 0.0011477024672926247),\n",
       " 'MAP@15': (0.009843439529236532, 0.0009485781830960456),\n",
       " 'MAP@20': (0.00939157058794265, 0.0008262428185845103),\n",
       " 'MAP@5': (0.011268165304268845, 0.0015703915362870525),\n",
       " 'MAP@50': (0.0077837122183294265, 0.0005176071583209709),\n",
       " 'NDCG': (0.03604253854788796, 0.0023568999100955393),\n",
       " 'Precision@10': (0.009247275204359674, 0.0008074270613270085),\n",
       " 'Precision@15': (0.00850363306085377, 0.0006405042420073831),\n",
       " 'Precision@20': (0.007825272479564034, 0.0005401775018695553),\n",
       " 'Precision@5': (0.010047683923705721, 0.0011695484551867941),\n",
       " 'Precision@50': (0.00593324250681199, 0.0003135966881570066),\n",
       " 'R-Precision': (0.01209785691389885, 0.0017236601606660375),\n",
       " 'Recall@10': (0.028126143640612233, 0.002954415609814675),\n",
       " 'Recall@15': (0.037298622000563116, 0.003311270967660442),\n",
       " 'Recall@20': (0.04511841792780182, 0.003613311188263803),\n",
       " 'Recall@5': (0.016341927204293654, 0.0023200712249954463),\n",
       " 'Recall@50': (0.07896979236330558, 0.0045551576354919835)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lambda = .99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3987/3987 [00:02<00:00, 1458.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3987/3987 [00:08<00:00, 445.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 3162.05it/s]\n"
     ]
    }
   ],
   "source": [
    "I_K_U_matrix = add_two_matrix(0.99, rtrain_implicit, I_K_matrix_implicit, shape = (3987, 5000+6049))\n",
    "I_I_matrix_combined = train(I_K_U_matrix)\n",
    "combined_prediction_score = predict(rtrain_implicit, 10, I_I_matrix_combined, item_similarity_en= True)\n",
    "combined_predict = prediction(combined_prediction_score, 50, rtrain_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5706.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5674.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5722.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5728.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5663.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5096.04it/s]\n"
     ]
    }
   ],
   "source": [
    "combined_res = evaluate(combined_predict, rvalid_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.009510313946196098, 0.0010990420600406968),\n",
       " 'MAP@15': (0.008942397829489109, 0.0009054306066055214),\n",
       " 'MAP@20': (0.008530492137471342, 0.000785431171138736),\n",
       " 'MAP@5': (0.010362738419618529, 0.0015085243271887874),\n",
       " 'MAP@50': (0.0071179913391400985, 0.00049215268635643),\n",
       " 'NDCG': (0.03307563322647713, 0.0022643486338727588),\n",
       " 'Precision@10': (0.008242506811989101, 0.0007671196716409187),\n",
       " 'Precision@15': (0.007572661217075386, 0.0006057023863693612),\n",
       " 'Precision@20': (0.007092983651226158, 0.0005160266029371115),\n",
       " 'Precision@5': (0.009196185286103543, 0.0011192816785831896),\n",
       " 'Precision@50': (0.005456403269754769, 0.0003021964872911058),\n",
       " 'R-Precision': (0.010494951519773537, 0.0016002149384129565),\n",
       " 'Recall@10': (0.02518932439098375, 0.002802487395398227),\n",
       " 'Recall@15': (0.03317440710583823, 0.0031249195664490347),\n",
       " 'Recall@20': (0.04039670337826926, 0.003378429238233643),\n",
       " 'Recall@5': (0.014792140430277994, 0.0022029750671236394),\n",
       " 'Recall@50': (0.07272108034716922, 0.004387014271756076)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lambda = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3987/3987 [00:02<00:00, 1387.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3987/3987 [00:08<00:00, 456.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 3215.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5777.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5771.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5760.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5750.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5706.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6049/6049 [00:01<00:00, 5134.97it/s]\n"
     ]
    }
   ],
   "source": [
    "I_K_U_matrix = add_two_matrix(0.3, rtrain_implicit, I_K_matrix_implicit, shape = (3987, 5000+6049))\n",
    "I_I_matrix_combined = train(I_K_U_matrix)\n",
    "combined_prediction_score = predict(rtrain_implicit, 10, I_I_matrix_combined, item_similarity_en= True)\n",
    "combined_predict = prediction(combined_prediction_score, 50, rtrain_implicit)\n",
    "combined_res = evaluate(combined_predict, rvalid_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.01626825991522858, 0.0014443780966594975),\n",
       " 'MAP@15': (0.015117642663623589, 0.0011852917650198027),\n",
       " 'MAP@20': (0.01426729237058212, 0.001026859943796448),\n",
       " 'MAP@5': (0.018037579473206177, 0.0019912770410484277),\n",
       " 'MAP@50': (0.011341957402844556, 0.0006444732410712395),\n",
       " 'NDCG': (0.05179422666939772, 0.0028825390042058535),\n",
       " 'Precision@10': (0.013760217983651228, 0.0009815571947617695),\n",
       " 'Precision@15': (0.012295640326975478, 0.0007730552066659302),\n",
       " 'Precision@20': (0.011401566757493188, 0.0006576668064319196),\n",
       " 'Precision@5': (0.01600817438692098, 0.0014683578132339591),\n",
       " 'Precision@50': (0.00808242506811989, 0.00038408710899893696),\n",
       " 'R-Precision': (0.017582991082070367, 0.002127472999561414),\n",
       " 'Recall@10': (0.04237830795398685, 0.0036203858096929774),\n",
       " 'Recall@15': (0.05612415809098409, 0.004105389903191877),\n",
       " 'Recall@20': (0.06783047869341836, 0.004441758962643903),\n",
       " 'Recall@5': (0.025184439078953912, 0.002856624054518497),\n",
       " 'Recall@50': (0.1102068564927076, 0.005410583892218727)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

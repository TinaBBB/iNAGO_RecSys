{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This files combines the basic structures and logic of the implementation of user study, sequence is not correct, the final version will be in another file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\programdata\\anaconda3\\lib\\site-packages (1.20.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in c:\\programdata\\anaconda3\\lib\\site-packages (from geopy) (1.50)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "import statistics as stats\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "import scipy.sparse as sparse\n",
    "import yaml\n",
    "from tkinter import *\n",
    "import tkinter\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy import distance\n",
    "from geopy import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewJson = \"..\\\\data\\\\Export_CleanedReview.json\"\n",
    "#reviewJsonWithClosedRes = \"..\\\\data\\\\Export_CleanedReviewWithClosedRes.json\"\n",
    "reviewJsonToronto = \"..\\\\data\\\\Export_TorontoData.json\"\n",
    "UserTestResult40 = \"..\\\\data\\\\Export_TorontoData.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Select top frenquent user and top frequenty restaurants that had at least 1 review >= 4 stars (Kickking out users that gave all  reviews <=3 and restaurants that never got start >= 4 stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yelp_df(path = 'data/', filename = 'Export_CleanedReview.json', sampling=False, top_user_num=6100, top_item_num=4000):\n",
    "    \"\"\"\n",
    "    Get the pandas dataframe\n",
    "    Sampling only the top users/items by density \n",
    "    Implicit representation applies\n",
    "    \"\"\"\n",
    "    with open(filename,'r') as f:\n",
    "        data = f.readlines()\n",
    "        data = list(map(json.loads, data))\n",
    "    \n",
    "    data = data[0]\n",
    "    #Get all the data from the dggeata file\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df.rename(columns={'stars': 'review_stars', 'text': 'review_text', 'cool': 'review_cool',\n",
    "                       'funny': 'review_funny', 'useful': 'review_useful'},\n",
    "              inplace=True)\n",
    "\n",
    "    df['business_num_id'] = df.business_id.astype('category').\\\n",
    "        cat.rename_categories(range(0, df.business_id.nunique()))\n",
    "    df['business_num_id'] = df['business_num_id'].astype('int')\n",
    "\n",
    "    df['user_num_id'] = df.user_id.astype('category').\\\n",
    "    cat.rename_categories(range(0, df.user_id.nunique()))\n",
    "    df['user_num_id'] = df['user_num_id'].astype('int')\n",
    "\n",
    "    df['timestamp'] = df['date'].apply(date_to_timestamp)\n",
    "\n",
    "    if sampling:\n",
    "        df = filter_yelp_df(df, top_user_num=top_user_num, top_item_num=top_item_num)\n",
    "        # Refresh num id\n",
    "        df['business_num_id'] = df.business_id.astype('category').\\\n",
    "        cat.rename_categories(range(0, df.business_id.nunique()))\n",
    "        df['business_num_id'] = df['business_num_id'].astype('int')\n",
    "        \n",
    "        df['user_num_id'] = df.user_id.astype('category').\\\n",
    "        cat.rename_categories(range(0, df.user_id.nunique()))\n",
    "        df['user_num_id'] = df['user_num_id'].astype('int')\n",
    "#     drop_list = ['date','review_id','review_funny','review_cool','review_useful']\n",
    "#     df = df.drop(drop_list, axis=1)\n",
    "\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    return df \n",
    "\n",
    "def filter_yelp_df(df, top_user_num=6100, top_item_num=4000):\n",
    "    #Getting the reviews where starts are above 3\n",
    "    df_implicit = df[df['review_stars']>3]\n",
    "    frequent_user_id = df_implicit['user_num_id'].value_counts().head(top_user_num).index.values\n",
    "    frequent_item_id = df_implicit['business_num_id'].value_counts().head(top_item_num).index.values\n",
    "    return df.loc[(df['user_num_id'].isin(frequent_user_id)) & (df['business_num_id'].isin(frequent_item_id))]\n",
    "\n",
    "def date_to_timestamp(date):\n",
    "    dt = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "    return time.mktime(dt.timetuple())\n",
    "\n",
    "def df_to_sparse(df, row_name='userId', col_name='movieId', value_name='rating',\n",
    "                 shape=None):\n",
    "    rows = df[row_name]\n",
    "    cols = df[col_name]\n",
    "    if value_name is not None:\n",
    "        values = df[value_name]\n",
    "    else:\n",
    "        values = [1]*len(rows)\n",
    "\n",
    "    return csr_matrix((values, (rows, cols)), shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rating-UI and timestamp-UI matrix from original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_timestamp_matrix(df, sampling=False, top_user_num=6100, top_item_num=4000):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #make the df implicit with top frenquent users and \n",
    "    #no need to sample anymore if df was sampled before \n",
    "    if sampling:\n",
    "        df = filter_yelp_df(df, top_user_num=top_user_num, top_item_num=top_item_num)\n",
    "\n",
    "    rating_matrix = df_to_sparse(df, row_name='user_num_id',\n",
    "                                 col_name='business_num_id',\n",
    "                                 value_name='review_stars',\n",
    "                                 shape=None)\n",
    "    \n",
    "    #Have same dimension and data entries with rating_matrix, except that the review stars are - user avg\n",
    "#     ratingWuserAvg_matrix = df_to_sparse(df, row_name='user_num_id',\n",
    "#                                  col_name='business_num_id',\n",
    "#                                  value_name='reviewStars_userAvg',\n",
    "#                                  shape=None)\n",
    "    \n",
    "    timestamp_matrix = df_to_sparse(df, row_name='user_num_id',\n",
    "                                    col_name='business_num_id',\n",
    "                                    value_name='timestamp',\n",
    "                                    shape=None)\n",
    "    \n",
    "    \n",
    "    IC_matrix = get_I_C(df)\n",
    "#     ratingWuserAvg_matrix\n",
    "    return rating_matrix, timestamp_matrix, IC_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_I_C(df):\n",
    "    lst = df.categories.values.tolist()\n",
    "    cat = []\n",
    "    for i in range(len(lst)):\n",
    "        cat.extend(lst[i].split(', '))\n",
    "    unique_cat = set(cat)\n",
    "    #     set categories id\n",
    "    df_cat = pd.DataFrame(list(unique_cat),columns=[\"Categories\"])\n",
    "    df_cat['cat_id'] = df_cat.Categories.astype('category').cat.rename_categories(range(0, df_cat.Categories.nunique()))\n",
    "    dict_cat = df_cat.set_index('Categories')['cat_id'].to_dict()\n",
    "    \n",
    "    df_I_C = pd.DataFrame(columns=['business_num_id', 'cat_id'])\n",
    "    \n",
    "    for i in range((df['business_num_id'].unique().shape)[0]):\n",
    "        df_temp = df[df['business_num_id'] == i].iloc[:1]\n",
    "        temp_lst = df_temp['categories'].to_list()[0].split(\",\")\n",
    "        for j in range(len(temp_lst)):\n",
    "            df_I_C = df_I_C.append({'business_num_id' : i  , 'cat_id' : dict_cat[temp_lst[j].strip()]} , ignore_index=True)\n",
    "    \n",
    "    IC_Matrix = df_to_sparse(df_I_C, row_name='business_num_id',\n",
    "                                 col_name='cat_id',\n",
    "                                 value_name=None,\n",
    "                                 shape=None)    \n",
    "    return IC_Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time ordered split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_ordered_split(rating_matrix, ratingWuserAvg_matrix, timestamp_matrix, ratio=[0.5, 0.2, 0.3],\n",
    "                       implicit=True, remove_empty=False, threshold=3,\n",
    "                       sampling=False, sampling_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split the data to train,valid,test by time\n",
    "    ratio:  train:valid:test\n",
    "    threshold: for implicit representation\n",
    "    \"\"\"\n",
    "    if implicit:\n",
    "        temp_rating_matrix = sparse.csr_matrix(rating_matrix.shape)\n",
    "        temp_rating_matrix[(rating_matrix > threshold).nonzero()] = 1\n",
    "        rating_matrix = temp_rating_matrix\n",
    "        timestamp_matrix = timestamp_matrix.multiply(rating_matrix)\n",
    "        #ratingWuserAvg_matrix = ratingWuserAvg_matrix.multiply(rating_matrix)\n",
    "\n",
    "    nonzero_index = None\n",
    "\n",
    "    #Default false, not removing empty columns and rows\n",
    "    #Should not have this case, since users should have at least 1 record of 4,5 \n",
    "    #And restuarant should have at least 1 record of 4,5 \n",
    "    if remove_empty:\n",
    "        # Remove empty columns. record original item index\n",
    "        nonzero_index = np.unique(rating_matrix.nonzero()[1])\n",
    "        rating_matrix = rating_matrix[:, nonzero_index]\n",
    "        timestamp_matrix = timestamp_matrix[:, nonzero_index]\n",
    "        ratingWuserAvg_matrix = ratingWuserAvg_matrix[:, nonzero_index]\n",
    "\n",
    "        # Remove empty rows. record original user index\n",
    "        nonzero_rows = np.unique(rating_matrix.nonzero()[0])\n",
    "        rating_matrix = rating_matrix[nonzero_rows]\n",
    "        timestamp_matrix = timestamp_matrix[nonzero_rows]\n",
    "        ratingWuserAvg_matrix = ratingWuserAvg_matrix[nonzero_rows]\n",
    "\n",
    "    user_num, item_num = rating_matrix.shape\n",
    "\n",
    "    rtrain = []\n",
    "    rtrain_userAvg = []\n",
    "    rtime = []\n",
    "    rvalid = []\n",
    "    rvalid_userAvg = []\n",
    "    rtest = []\n",
    "    rtest_userAvg = []\n",
    "    # Get the index list corresponding to item for train,valid,test\n",
    "    item_idx_train = []\n",
    "    item_idx_valid = []\n",
    "    item_idx_test = []\n",
    "    \n",
    "    for i in tqdm(range(user_num)):\n",
    "        #Get the non_zero indexs, restuarants where the user visited/liked if implicit \n",
    "        item_indexes = rating_matrix[i].nonzero()[1]\n",
    "        \n",
    "        #Get the data for the user\n",
    "        data = rating_matrix[i].data\n",
    "        \n",
    "        #Get time stamp value \n",
    "        timestamp = timestamp_matrix[i].data\n",
    "        \n",
    "        #Get review stars with user avg data \n",
    "        if implicit == False:\n",
    "            dataWuserAvg = ratingWuserAvg_matrix[i].data\n",
    "        \n",
    "        #Non zero reviews for this user\n",
    "        num_nonzeros = len(item_indexes)\n",
    "        \n",
    "        #If the user has at least one review\n",
    "        if num_nonzeros >= 1:\n",
    "            #Get number of test and valid data \n",
    "            #train is 30%\n",
    "            num_test = int(num_nonzeros * ratio[2])\n",
    "            #validate is 50%\n",
    "            num_valid = int(num_nonzeros * (ratio[1] + ratio[2]))\n",
    "\n",
    "            valid_offset = num_nonzeros - num_valid\n",
    "            test_offset = num_nonzeros - num_test\n",
    "\n",
    "            #Sort the timestamp for each review for the user\n",
    "            argsort = np.argsort(timestamp)\n",
    "            \n",
    "            #Sort the reviews for the user according to the time stamp \n",
    "            data = data[argsort]\n",
    "            \n",
    "            #Sort the review with user avg accoridng to the time stamp\n",
    "            if implicit == False:\n",
    "                dataWuserAvg = dataWuserAvg[argsort]\n",
    "            \n",
    "            #Non-zero review index sort according to time\n",
    "            item_indexes = item_indexes[argsort]\n",
    "            \n",
    "            #list of ratings, num of valid_offset index, index where there's non-zeros\n",
    "            rtrain.append([data[:valid_offset], np.full(valid_offset, i), item_indexes[:valid_offset]])\n",
    "            \n",
    "            if implicit == False:\n",
    "                #Changing valid set to binary\n",
    "                count=valid_offset\n",
    "                for eachData in data[valid_offset:test_offset]:\n",
    "                    #if rating-avgRating > 0 then like\n",
    "                    if eachData >= 4:\n",
    "                        data[count] = 1\n",
    "                    else:\n",
    "                        data[count] = 0\n",
    "                    count += 1\n",
    "                \n",
    "            #50%-70%\n",
    "            rvalid.append([data[valid_offset:test_offset], np.full(test_offset - valid_offset, i),\n",
    "                           item_indexes[valid_offset:test_offset]])\n",
    "            #remaining 30%\n",
    "            rtest.append([data[test_offset:], np.full(num_test, i), item_indexes[test_offset:]])\n",
    "            \n",
    "            if implicit == False:\n",
    "                #Now for the rating matrix that considers user average rating\n",
    "                #list of ratings, num of valid_offset index, index where there's non-zeros\n",
    "                rtrain_userAvg.append([dataWuserAvg[:valid_offset], np.full(valid_offset, i), item_indexes[:valid_offset]])\n",
    "                #50%-70%\n",
    "\n",
    "                #Changing valid set to binary\n",
    "                count=valid_offset\n",
    "                for eachData in dataWuserAvg[valid_offset:test_offset]:\n",
    "                    #if rating-avgRating > 0 then like\n",
    "                    if eachData > 0:\n",
    "                        dataWuserAvg[count] = 1\n",
    "                    else:\n",
    "                        dataWuserAvg[count] = 0\n",
    "                    count += 1\n",
    "\n",
    "                rvalid_userAvg.append([dataWuserAvg[valid_offset:test_offset], np.full(test_offset - valid_offset, i),\n",
    "                               item_indexes[valid_offset:test_offset]])\n",
    "\n",
    "                #Change test set to binary even we don't use it\n",
    "                countTest = test_offset\n",
    "                for eachData in dataWuserAvg[test_offset:]:\n",
    "                    #if rating-avgRating > 0 then like\n",
    "                    if eachData > 0:\n",
    "                        dataWuserAvg[count] = 1\n",
    "                    else:\n",
    "                        dataWuserAvg[count] = 0\n",
    "                    count += 1\n",
    "\n",
    "\n",
    "                #remaining 30%\n",
    "                rtest_userAvg.append([dataWuserAvg[test_offset:], np.full(num_test, i), item_indexes[test_offset:]])\n",
    "                \n",
    "            item_idx_train.append(item_indexes[:valid_offset])\n",
    "            \n",
    "#             item_idx_valid.append(item_indexes[valid_offset:test_offset])\n",
    "#             item_idx_test.append(item_indexes[test_offset:])\n",
    "        else:\n",
    "            item_idx_train.append([])\n",
    "#             item_idx_valid.append([])\n",
    "#             item_idx_test.append([])\n",
    "    \n",
    "    rtrain = np.array(rtrain)\n",
    "    rvalid = np.array(rvalid)\n",
    "    rtest = np.array(rtest)\n",
    "    if implicit == False:\n",
    "        rtrain_userAvg = np.array(rtrain_userAvg)\n",
    "        rvalid_userAvg = np.array(rvalid_userAvg)\n",
    "        rtest_userAvg = np.array(rtest_userAvg)\n",
    "\n",
    "    #take non-zeros values, row index, and column (non-zero) index and store into sparse matrix\n",
    "    rtrain = sparse.csr_matrix((np.hstack(rtrain[:, 0]), (np.hstack(rtrain[:, 1]), np.hstack(rtrain[:, 2]))),\n",
    "                               shape=rating_matrix.shape, dtype=np.float32)\n",
    "    rvalid = sparse.csr_matrix((np.hstack(rvalid[:, 0]), (np.hstack(rvalid[:, 1]), np.hstack(rvalid[:, 2]))),\n",
    "                               shape=rating_matrix.shape, dtype=np.float32)\n",
    "    rtest = sparse.csr_matrix((np.hstack(rtest[:, 0]), (np.hstack(rtest[:, 1]), np.hstack(rtest[:, 2]))),\n",
    "                              shape=rating_matrix.shape, dtype=np.float32)\n",
    "    \n",
    "    if implicit == False:\n",
    "        rtrain_userAvg = sparse.csr_matrix((np.hstack(rtrain_userAvg[:, 0]), (np.hstack(rtrain_userAvg[:, 1]), np.hstack(rtrain_userAvg[:, 2]))),\n",
    "                                   shape=rating_matrix.shape, dtype=np.float32)\n",
    "        rvalid_userAvg = sparse.csr_matrix((np.hstack(rvalid_userAvg[:, 0]), (np.hstack(rvalid_userAvg[:, 1]), np.hstack(rvalid_userAvg[:, 2]))),\n",
    "                                   shape=rating_matrix.shape, dtype=np.float32)\n",
    "        rtest_userAvg = sparse.csr_matrix((np.hstack(rtest_userAvg[:, 0]), (np.hstack(rtest_userAvg[:, 1]), np.hstack(rtest_userAvg[:, 2]))),\n",
    "                                  shape=rating_matrix.shape, dtype=np.float32)\n",
    "\n",
    "    return rtrain, rvalid, rtest,rtrain_userAvg, rvalid_userAvg, rtest_userAvg, nonzero_index, timestamp_matrix, item_idx_train, item_idx_valid, item_idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_ordered_splitModified(rating_matrix, ratingWuserAvg_matrix, timestamp_matrix, ratio=[0.5, 0.2, 0.3],\n",
    "                       implicit=True, remove_empty=False, threshold=3,\n",
    "                       sampling=False, sampling_ratio=0.1, trainSampling=1):\n",
    "    \"\"\"\n",
    "    Split the data to train,valid,test by time\n",
    "    ratio:  train:valid:test\n",
    "    threshold: for implicit representation\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if implicit:\n",
    "        temp_rating_matrix = sparse.csr_matrix(rating_matrix.shape)\n",
    "        temp_rating_matrix[(rating_matrix > threshold).nonzero()] = 1\n",
    "        rating_matrix = temp_rating_matrix\n",
    "        timestamp_matrix = timestamp_matrix.multiply(rating_matrix)\n",
    "        #ratingWuserAvg_matrix = ratingWuserAvg_matrix.multiply(rating_matrix)\n",
    "\n",
    "    nonzero_index = None\n",
    "\n",
    "    #Default false, not removing empty columns and rows\n",
    "    #Should not have this case, since users should have at least 1 record of 4,5 \n",
    "    #And restuarant should have at least 1 record of 4,5 \n",
    "    if remove_empty:\n",
    "        # Remove empty columns. record original item index\n",
    "        nonzero_index = np.unique(rating_matrix.nonzero()[1])\n",
    "        rating_matrix = rating_matrix[:, nonzero_index]\n",
    "        timestamp_matrix = timestamp_matrix[:, nonzero_index]\n",
    "        ratingWuserAvg_matrix = ratingWuserAvg_matrix[:, nonzero_index]\n",
    "\n",
    "        # Remove empty rows. record original user index\n",
    "        nonzero_rows = np.unique(rating_matrix.nonzero()[0])\n",
    "        rating_matrix = rating_matrix[nonzero_rows]\n",
    "        timestamp_matrix = timestamp_matrix[nonzero_rows]\n",
    "        ratingWuserAvg_matrix = ratingWuserAvg_matrix[nonzero_rows]\n",
    "\n",
    "    user_num, item_num = rating_matrix.shape\n",
    "\n",
    "    rtrain = []\n",
    "    rtrain_userAvg = []\n",
    "    rtime = []\n",
    "    rvalid = []\n",
    "    rvalid_userAvg = []\n",
    "    rtest = []\n",
    "    rtest_userAvg = []\n",
    "    # Get the index list corresponding to item for train,valid,test\n",
    "    item_idx_train = []\n",
    "    item_idx_valid = []\n",
    "    item_idx_test = []\n",
    "    \n",
    "    for i in tqdm(range(user_num)):\n",
    "        #Get the non_zero indexs, restuarants where the user visited/liked if implicit \n",
    "        item_indexes = rating_matrix[i].nonzero()[1]        \n",
    "        #Get the data for the user\n",
    "        data = rating_matrix[i].data      \n",
    "        #Get time stamp value \n",
    "        timestamp = timestamp_matrix[i].data \n",
    "        #Get review stars with user avg data \n",
    "        if implicit == False:\n",
    "            dataWuserAvg = ratingWuserAvg_matrix[i].data\n",
    "\n",
    "            \n",
    "        #Non zero reviews for this user\n",
    "        num_nonzeros = len(item_indexes)\n",
    "        \n",
    "        #If the user has at least one review\n",
    "        if num_nonzeros >= 1:\n",
    "            num_test = int(num_nonzeros * ratio[2])\n",
    "            num_valid = int(num_nonzeros * (ratio[1] + ratio[2]))\n",
    "            valid_offset = num_nonzeros - num_valid\n",
    "            \n",
    "            # Adding this for sampling for training set\n",
    "            valid_offsetSample = int(valid_offset*trainSampling)\n",
    "            test_offset = num_nonzeros - num_test\n",
    "            \n",
    "            #Sort the timestamp for each review for the user\n",
    "            argsort = np.argsort(timestamp)\n",
    "            \n",
    "            #Sort the reviews for the user according to the time stamp \n",
    "            data = data[argsort]\n",
    "            \n",
    "            #Sort the review with user avg accoridng to the time stamp\n",
    "            if implicit == False:\n",
    "                dataWuserAvg = dataWuserAvg[argsort]\n",
    "            \n",
    "            #Non-zero review index sort according to time\n",
    "            item_indexes = item_indexes[argsort]\n",
    "            \n",
    "            #list of ratings, num of valid_offset index, index where there's non-zeros\n",
    "            #if take from old to new\n",
    "            #rtrain.append([data[:valid_offsetSample], np.full(valid_offsetSample, i), item_indexes[:valid_offsetSample]])\n",
    "            #if take from new to old\n",
    "            rtrain.append([data[valid_offset-valid_offsetSample:valid_offset], np.full(valid_offsetSample, i), item_indexes[valid_offset-valid_offsetSample:valid_offset]])\n",
    "            rvalid.append([data[valid_offset:test_offset], np.full(test_offset - valid_offset, i),\n",
    "                           item_indexes[valid_offset:test_offset]])\n",
    "            rtest.append([data[test_offset:], np.full(num_test, i), item_indexes[test_offset:]])\n",
    "            \n",
    "            if implicit == False:\n",
    "                #Now for the rating matrix that considers user average rating\n",
    "                #list of ratings, num of valid_offset index, index where there's non-zeros\n",
    "                #from old to new\n",
    "                #rtrain_userAvg.append([dataWuserAvg[:valid_offsetSample], np.full(valid_offsetSample, i), item_indexes[:valid_offsetSample]])\n",
    "                #take nearest\n",
    "                rtrain_userAvg.append([dataWuserAvg[valid_offset-valid_offsetSample:valid_offset], np.full(valid_offsetSample, i), item_indexes[valid_offset-valid_offsetSample:valid_offset]])                \n",
    "                    \n",
    "                rvalid_userAvg.append([dataWuserAvg[valid_offset:test_offset], np.full(test_offset - valid_offset, i),\n",
    "                               item_indexes[valid_offset:test_offset]])\n",
    "                \n",
    "                rtest_userAvg.append([dataWuserAvg[test_offset:], np.full(num_test, i), item_indexes[test_offset:]])\n",
    "                \n",
    "            item_idx_train.append(item_indexes[:valid_offsetSample])\n",
    "            \n",
    "        else:\n",
    "            item_idx_train.append([])\n",
    "    \n",
    "    rtrain = np.array(rtrain)\n",
    "    rvalid = np.array(rvalid)\n",
    "    rtest = np.array(rtest)\n",
    "   \n",
    "    if implicit == False:\n",
    "        rtrain_userAvg = np.array(rtrain_userAvg)\n",
    "        rvalid_userAvg = np.array(rvalid_userAvg)\n",
    "        rtest_userAvg = np.array(rtest_userAvg)\n",
    "\n",
    "    #take non-zeros values, row index, and column (non-zero) index and store into sparse matrix\n",
    "    rtrain = sparse.csr_matrix((np.hstack(rtrain[:, 0]), (np.hstack(rtrain[:, 1]), np.hstack(rtrain[:, 2]))),\n",
    "                               shape=rating_matrix.shape, dtype=np.float32)\n",
    "    rvalid = sparse.csr_matrix((np.hstack(rvalid[:, 0]), (np.hstack(rvalid[:, 1]), np.hstack(rvalid[:, 2]))),\n",
    "                               shape=rating_matrix.shape, dtype=np.float32)\n",
    "    rtest = sparse.csr_matrix((np.hstack(rtest[:, 0]), (np.hstack(rtest[:, 1]), np.hstack(rtest[:, 2]))),\n",
    "                              shape=rating_matrix.shape, dtype=np.float32)\n",
    "    \n",
    "    if implicit == False:\n",
    "        rtrain_userAvg = sparse.csr_matrix((np.hstack(rtrain_userAvg[:, 0]), (np.hstack(rtrain_userAvg[:, 1]), np.hstack(rtrain_userAvg[:, 2]))),\n",
    "                                   shape=rating_matrix.shape, dtype=np.float32)\n",
    "        rvalid_userAvg = sparse.csr_matrix((np.hstack(rvalid_userAvg[:, 0]), (np.hstack(rvalid_userAvg[:, 1]), np.hstack(rvalid_userAvg[:, 2]))),\n",
    "                                   shape=rating_matrix.shape, dtype=np.float32)\n",
    "        rtest_userAvg = sparse.csr_matrix((np.hstack(rtest_userAvg[:, 0]), (np.hstack(rtest_userAvg[:, 1]), np.hstack(rtest_userAvg[:, 2]))),\n",
    "                                  shape=rating_matrix.shape, dtype=np.float32)\n",
    "\n",
    "    return rtrain, rvalid, rtest,rtrain_userAvg, rvalid_userAvg, rtest_userAvg, nonzero_index, timestamp_matrix, item_idx_train, item_idx_valid, item_idx_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get df for training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Item idex matrix stores the reivews starts\n",
    "#This function returns a list of index for the reviews included in training set \n",
    "def get_corpus_idx_list(df, item_idx_matrix):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    df: total dataframe\n",
    "    item_idx_matrix: train index list got from time_split \n",
    "    Output: row index in original dataframe for training data by time split\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    #For all the users: 5791\n",
    "    for i in tqdm(range(len(item_idx_matrix))):\n",
    "        \n",
    "        #find row index where user_num_id is i\n",
    "        a = df.index[df['user_num_id'] == i].tolist()\n",
    "        \n",
    "        #loop through the busienss id that the user i reviewed for in offvalid set \n",
    "        for item_idx in  item_idx_matrix[i]:\n",
    "            \n",
    "            #get the row index for reviews for business that the user liked in the train set\n",
    "            b = df.index[df['business_num_id'] == item_idx].tolist()\n",
    "            \n",
    "            #Find the index for which this user liked, one user only rate a business once\n",
    "            idx_to_add = list(set(a).intersection(b))\n",
    "            \n",
    "            if idx_to_add not in lst:\n",
    "                lst.extend(idx_to_add)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess using Term Frequency - CounterVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\songya25\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\songya25\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Stemming and Lemmatisation\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# Get corpus and CountVector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_words = ['not_the']\n",
    "stop_words = stop_words.union(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#Should 'because' added?\n",
    "def preprocess(df, reset_list = [',','.','?',';','however','but']):\n",
    "    corpus = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        text = df['review_text'][i]\n",
    "        change_flg = 0\n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        ##Convert to list from string, loop through the review text\n",
    "        text = text.split()\n",
    "        \n",
    "        #any sentence that encounters a not, the folloing words will become not phrase until hit the sentence end\n",
    "        for j in range(len(text)):\n",
    "            #Make the not_ hack\n",
    "            if text[j] == 'not':\n",
    "                change_flg = 1\n",
    "#                 print 'changes is made after ', i\n",
    "                continue\n",
    "            #if was 1 was round and not hit a 'not' in this round\n",
    "            if change_flg == 1 and any(reset in text[j] for reset in reset_list):\n",
    "                text[j] = 'not_' + text[j]\n",
    "                change_flg = 0\n",
    "#                 print 'reset at ', i\n",
    "            if change_flg == 1:\n",
    "                text[j] = 'not_' + text[j]\n",
    "        \n",
    "        #Convert back to string\n",
    "        text = \" \".join(text)\n",
    "        \n",
    "        #Remove punctuations\n",
    "#       text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        \n",
    "        #remove tags\n",
    "        text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "        \n",
    "        # remove special characters and digits\n",
    "        text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "        \n",
    "        ##Convert to list from string\n",
    "        text = text.split()\n",
    "        \n",
    "        ##Stemming\n",
    "        ps=PorterStemmer()\n",
    "        \n",
    "        #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in  \n",
    "                stop_words] \n",
    "        text = \" \".join(text)\n",
    "        corpus.append(text)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def train(matrix_train):\n",
    "    similarity = cosine_similarity(X=matrix_train, Y=None, dense_output=True)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "\n",
    "#Get a UI matrix if it's not item_similarity based or else IU\n",
    "def predict(matrix_train, k, similarity, item_similarity_en = False):\n",
    "    prediction_scores = []\n",
    "    \n",
    "    #inverse to IU matrix\n",
    "    if item_similarity_en:\n",
    "        matrix_train = matrix_train.transpose()\n",
    "        \n",
    "    #for each user or item, depends UI or IU \n",
    "    for user_index in tqdm(range(matrix_train.shape[0])):\n",
    "        # Get user u's prediction scores for all items\n",
    "        #Get prediction/similarity score for each user 1*num or user or num of items\n",
    "        vector_u = similarity[user_index]\n",
    "\n",
    "        # Get closest K neighbors excluding user u self\n",
    "        #Decending accoding to similarity score, select top k\n",
    "        similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "        \n",
    "        # Get neighbors similarity weights and ratings\n",
    "        similar_users_weights = similarity[user_index][similar_users]\n",
    "        \n",
    "        #similar_users_weights_sum = np.sum(similar_users_weights)\n",
    "        #print(similar_users_weights.shape)\n",
    "        #shape: num of res * k\n",
    "        similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "              \n",
    "        prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "        #print(prediction_scores_u)\n",
    "        \n",
    "        \n",
    "        prediction_scores.append(np.sum(prediction_scores_u, axis=0))\n",
    "        \n",
    "    res = np.array(prediction_scores)\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        res = res.transpose()\n",
    "    return res\n",
    "\n",
    "\n",
    "#Preidction score is UI or IU?\n",
    "def prediction(prediction_score, topK, matrix_Train):\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    #for each user\n",
    "    for user_index in tqdm(range(matrix_Train.shape[0])):\n",
    "        \n",
    "        #take the prediction scores for user 1 * num res\n",
    "        vector_u = prediction_score[user_index]\n",
    "        \n",
    "        #The restuarant the user rated\n",
    "        vector_train = matrix_Train[user_index]\n",
    "        \n",
    "        if len(vector_train.nonzero()[0]) > 0:\n",
    "            vector_predict = sub_routine(vector_u, vector_train, topK=topK)\n",
    "        else:\n",
    "            vector_predict = np.zeros(topK, dtype=np.float32)\n",
    "\n",
    "        prediction.append(vector_predict)\n",
    "\n",
    "    return np.vstack(prediction)\n",
    "\n",
    "#topK: the number of restuarants we are suggesting \n",
    "#if vector_train has number, then the user has visited\n",
    "def sub_routine(vector_u, vector_train, topK=500):\n",
    "\n",
    "    #index where non-zero\n",
    "    train_index = vector_train.nonzero()[1]\n",
    "    \n",
    "    vector_u = vector_u\n",
    "    \n",
    "    #get topk + num rated res prediction score descending, top index \n",
    "    candidate_index = np.argpartition(-vector_u, topK+len(train_index))[:topK+len(train_index)]\n",
    "    \n",
    "    #sort top prediction score index in range topK+len(train_index) into vector_u`\n",
    "    vector_u = candidate_index[vector_u[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "    #deleted the rated res from the topk+train_index prediction score vector for user u \n",
    "    #Delete the user rated res index from the topk+numRated index\n",
    "    vector_u = np.delete(vector_u, np.isin(vector_u, train_index).nonzero()[0])\n",
    "\n",
    "    #so we only include the top K prediction score here\n",
    "    return vector_u[:topK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImplicitMatrix(sparseMatrix, threashold=0):\n",
    "    temp_matrix = sparse.csr_matrix(sparseMatrix.shape)\n",
    "    temp_matrix[(sparseMatrix > threashold).nonzero()] = 1\n",
    "    return temp_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictUU(matrix_train, k, chooseWeigthMethod, similarity1=None, similarity2=None, similarity3=None, similarity4=None, similarity5=None, item_similarity_en = False):\n",
    "    prediction_scores = []\n",
    "    #Convert from list to ndarray, add an axis\n",
    "    if isinstance(chooseWeigthMethod, list):\n",
    "        chooseWeigthMethod = np.array(chooseWeigthMethod)[:, np.newaxis]\n",
    "   \n",
    "    \"make sure that when passing in chooseWeightMethod, the weight must be aligned with similarity metrices, even if set to None\"\n",
    "    \"They should add to 1 as well\"\n",
    "    #inverse to IU matrix\n",
    "    if item_similarity_en:\n",
    "        matrix_train = matrix_train.transpose()\n",
    "        \n",
    "    #for each user or item, depends UI or IU \n",
    "    for user_index in tqdm(range(matrix_train.shape[0])):\n",
    "    #for user_index in tqdm(range(10,20)):\n",
    "        \n",
    "        numberSimilarMatrix = 0\n",
    "        # Get user u's prediction scores for all items \n",
    "        #Get prediction/similarity score for each user 1*num or user or num of items\n",
    "        if similarity1 is not None:\n",
    "            vector_u1 = similarity1[user_index]\n",
    "            numberSimilarMatrix += 1\n",
    "        else:\n",
    "            vector_u1 = [0]*matrix_train.shape[0]\n",
    "            \n",
    "        if similarity2 is not None:\n",
    "            vector_u2 = similarity2[user_index]\n",
    "            numberSimilarMatrix += 1\n",
    "        else:\n",
    "            vector_u2 = [0]*len(vector_u1)\n",
    "            \n",
    "        if similarity3 is not None:\n",
    "            vector_u3 = similarity3[user_index]\n",
    "            numberSimilarMatrix += 1\n",
    "        else:\n",
    "            vector_u3 = [0]*len(vector_u1)\n",
    "            \n",
    "        if similarity4 is not None:\n",
    "            vector_u4 = similarity4[user_index]\n",
    "            numberSimilarMatrix += 1\n",
    "        else:\n",
    "            vector_u4 = [0]*len(vector_u1)\n",
    "        \n",
    "        if similarity5 is not None:\n",
    "            vector_u5 = similarity5[user_index]\n",
    "            numberSimilarMatrix += 1\n",
    "        else:\n",
    "            vector_u5 = [0]*len(vector_u1)\n",
    "        \n",
    "        #Temperary vector that stacks all 4 vectors together\n",
    "        tempVector = np.array([vector_u1,vector_u2,vector_u3,vector_u4, vector_u5])\n",
    "        \n",
    "        if chooseWeigthMethod is None:\n",
    "            #Get the similarity score from the first similarity matrix anyways \n",
    "            vector_u = vector_u1.copy()\n",
    "            \n",
    "        #If we are choosing the max, min, avg or similarity scores\n",
    "        if chooseWeigthMethod is not None:\n",
    "            if chooseWeigthMethod == 'max':\n",
    "                vector_u = tempVector.max(axis=0)\n",
    "            elif chooseWeigthMethod == 'min':\n",
    "                vector_u = tempVector.min(axis=0)\n",
    "            elif chooseWeigthMethod == 'average':\n",
    "                vector_u = tempVector.mean(axis=0)\n",
    "            elif isinstance(chooseWeigthMethod, np.ndarray):\n",
    "                #Validate that number of weights passed in equals number of matrices\n",
    "                #assert(len(chooseWeigthMethod) == numberSimilarMatrix)\n",
    "                #Get the new combined similarity vector \n",
    "                weighted_u = tempVector * chooseWeigthMethod\n",
    "                vector_u =np.sum(weighted_u, axis=0)\n",
    "                #print((vector_u == vector_u4).sum())\n",
    "                \n",
    "        similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "        \n",
    "        # Get neighbors similarity weights and ratings\n",
    "        #similar_users_weights = similarity1[user_index][similar_users]\n",
    "        similar_users_weights = vector_u[similar_users]\n",
    "        \n",
    "        #similar_users_weights_sum = np.sum(similar_users_weights)\n",
    "        #print(similar_users_weights.shape)\n",
    "        #shape: num of res * k\n",
    "        similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "              \n",
    "        prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "        #print(prediction_scores_u)\n",
    "        \n",
    "        prediction_scores.append(np.sum(prediction_scores_u, axis=0))\n",
    "        \n",
    "    res = np.array(prediction_scores)\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        res = res.transpose()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the user number that we are trying to recommend for\n",
    "#Enter the # of businesses that we want to recommend for them \n",
    "#Pass in the UI_Prediction matrix for users \n",
    "#userIndex parameter not used \n",
    "def constructResDictionary(userIndex, busIndexRange, UI_prediction):\n",
    "    #Construct the dictionary for the recommended restaurants to display \n",
    "    dictionaryToConstruct = {}\n",
    "    \n",
    "    #Loop through the number of businesses \n",
    "    for busIndex in range(busIndexRange):\n",
    "        #Get the business information for the recommended business \n",
    "        businessSeries = df[df[\"business_num_id\"] == UI_prediction[busIndex]].iloc[0]\n",
    "        #Get the business name \n",
    "        busName = businessSeries['name']\n",
    "        \n",
    "        #get the list of strings to generate the address information \n",
    "        address_generator = (str(w) for w in yaml.safe_load(businessSeries.location)['display_address'])\n",
    "        busLocation = ', '.join(address_generator)\n",
    "        bus_Price = businessSeries.price\n",
    "        busStars = businessSeries.business_stars\n",
    "        busReviewCount = businessSeries.review_count_y \n",
    "        #category_generator = (str(s) for s in [cateDict['title'] for cateDict in yaml.safe_load(businessSeries.categories)])\n",
    "        #busCategories = [cateDict['title'] for cateDict in yaml.safe_load(businessSeries.categories)]\n",
    "        #busCategories = ', '.join(category_generator)\n",
    "        busCategories = businessSeries.categories\n",
    "        #Now add the restaurant to the dictionary\n",
    "        dictionaryToConstruct[busName] = {'Address': busLocation,\\\n",
    "                                'Price': bus_Price,\\\n",
    "                                 'Star': busStars, \\\n",
    "                                 'Review Count': busReviewCount, \\\n",
    "                                 'Category': busCategories}\n",
    "    return dictionaryToConstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial method\n",
    "# def get_three_popularity_matrix(df_original,rtrain):\n",
    "#     # get the list of popular items by ranking the number of reviews\n",
    "#     dff_popular = df_original.copy()\n",
    "#     dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "#     popular_list_num_of_reviews = dff_popular[\"business_num_id\"].tolist()\n",
    "    \n",
    "#     # get the list of popular items by ranking average rating score\n",
    "#     dff_popular_rating = df_original.copy()\n",
    "#     dff_popular_rating = dff_popular.sort_values(by=[\"business_stars\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "#     popular_list_avg_stars = dff_popular_rating[\"business_num_id\"].tolist()\n",
    "    \n",
    "#     # get the popularity items by using the percentage liked method(number of liked items / total items)\n",
    "#     numUsers = rtrain.shape[0]\n",
    "#     numItems = rtrain.shape[1]\n",
    "    \n",
    "#     predictionMatrix = np.zeros((numUsers , numItems))\n",
    "\n",
    "#     # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "#     vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "#     rtrain_array = rtrain.toarray()\n",
    "#     # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "#     itemPopularity = np.zeros((numItems))\n",
    "#     for item in range(numItems):\n",
    "#         numOfUsersRated = len(rtrain_array[:, item].nonzero()[0])\n",
    "#         numOfUsersLiked = len(vf(rtrain_array[:, item]).nonzero()[0])\n",
    "# #         if numOfUsersRated == 0:\n",
    "#         # set a threshold to filter out restaurants with very few reviews\n",
    "#         if numOfUsersRated <= 100:\n",
    "#             itemPopularity[item] = 0\n",
    "#         else:\n",
    "#             itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "#     popular_list_liked_ratio = itemPopularity.argsort()\n",
    "    \n",
    "#     return np.asarray(popular_list_num_of_reviews),np.asarray(popular_list_avg_stars),popular_list_liked_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_three_popularity_matrix(df_original,rtrain):\n",
    "    # get the list of popular items by ranking the number of reviews\n",
    "    numUsers = rtrain.shape[0]\n",
    "    numItems = rtrain.shape[1]\n",
    "    \n",
    "    dff_popular = df_original.copy()\n",
    "    dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "    popular_list_num_of_reviews = dff_popular[\"business_num_id\"].tolist()\n",
    "    \n",
    "    # get the list of popular items by ranking average rating score\n",
    "    dff_popular_rating = df_original.copy()\n",
    "    dff_popular_rating = dff_popular_rating.sort_values(by=[\"business_stars\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "    popular_list_avg_stars = dff_popular_rating[\"business_num_id\"].tolist()\n",
    "    \n",
    "    lst_temp = []\n",
    "    for item in tqdm(range(numItems)):\n",
    "        numOfUsersRated = len(rtrain.toarray()[:, item].nonzero()[0])\n",
    "        if numOfUsersRated <= 50:\n",
    "            lst_temp.append(item)\n",
    "    popular_list_avg_stars = [x for x in popular_list_avg_stars if x not in lst_temp]\n",
    "    \n",
    "    # get the popularity items by using the percentage liked method(number of liked items / total items)\n",
    "    predictionMatrix = np.zeros((numUsers , numItems))\n",
    "\n",
    "    # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "    vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "    rtrain_array = rtrain.toarray()\n",
    "    # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "    itemPopularity = np.zeros((numItems))\n",
    "    for item in range(numItems):\n",
    "        numOfUsersRated = len(rtrain_array[:, item].nonzero()[0])\n",
    "        numOfUsersLiked = len(vf(rtrain_array[:, item]).nonzero()[0])\n",
    "#         if numOfUsersRated == 0:\n",
    "        # set a threshold to filter out restaurants with very few reviews\n",
    "        if numOfUsersRated <= 30:\n",
    "            itemPopularity[item] = 0\n",
    "        else:\n",
    "            itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "    popular_list_liked_ratio = itemPopularity.argsort()\n",
    "    \n",
    "    return np.asarray(popular_list_num_of_reviews),np.asarray(popular_list_avg_stars),popular_list_liked_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either a list or an array\n",
    "def geographical_dist(prediction_matrix,intersection,user_id, bus_indexRange):\n",
    "    lst = []\n",
    "    length = 0\n",
    "    #if the prediction matrix is a list of items for an user \n",
    "    print(type(prediction_matrix))\n",
    "    if isinstance(prediction_matrix, list):\n",
    "        print('isList')\n",
    "        length = len(prediction_matrix)\n",
    "        print(length)\n",
    "    #loop through the prediction matrix for the user, if passed in a prediction matrix \n",
    "    else:\n",
    "        length = prediction_matrix[user_id].shape[0]\n",
    "        #length = prediction_matrix.shape[0]\n",
    "    for j in range(length):\n",
    "        if isinstance(prediction_matrix, list):\n",
    "            coordinateDict = yaml.safe_load(df_location[df_location[\"business_num_id\"] == prediction_matrix[j]].iloc[0].coordinates)\n",
    "        else:    \n",
    "            coordinateDict = yaml.safe_load(df_location[df_location[\"business_num_id\"] == prediction_matrix[user_id][j]].iloc[0].coordinates)\n",
    "        test_point = Point(coordinateDict['latitude'],coordinateDict['longitude'])\n",
    "        \n",
    "        #Get the distance with the test point\n",
    "        result = distance.distance(intersection,test_point).kilometers\n",
    "        if result<=0.6:\n",
    "            #append the jth item if the condition matches\n",
    "            if isinstance(prediction_matrix, list):\n",
    "                lst.append(prediction_matrix[j])\n",
    "            else:\n",
    "                lst.append(prediction_matrix[user_id][j])\n",
    "        lst = lst[0:bus_indexRange]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiListbox_Initialize(Frame):\n",
    "    \n",
    "    def __init__(self, master, lists,list1Res,list2Res,list3Res):\n",
    "        Frame.__init__(self, master)\n",
    "        self.lists = []\n",
    "        #self.entries = []\n",
    "        #self.fields = 'Like', 'Dislike'\n",
    "        self.dropDownTextBox = 'Rank1','Score1', 'Rank2','Score2','Rank3','Score3'\n",
    "        #Var for checkbox\n",
    "        #self.var = IntVar()\n",
    "        self.var = []\n",
    "        self.listNames = []\n",
    "        self.responseDict = {}\n",
    "        #self.options = [\"Jan\", \"Feb\", \"Mar\"] #etc\n",
    "        #No 0s or else you won't choose it as liked \n",
    "        self.scores = [5, 4, 3, 2, 1]\n",
    "        #stores the list of restaurants for list 1-3\n",
    "        self.list1Name = list1Res\n",
    "        self.list2Name = list2Res\n",
    "        self.list3Name = list3Res\n",
    "        #To get response from dropdowns \n",
    "        self.rankVar = []\n",
    "        self.scoreVar = []\n",
    "        \n",
    "        #list count 0,1,2\n",
    "        listCount = 0 \n",
    "        #Loop through the lists, l is the list label and widthW is the width \n",
    "        for l,widthW in lists:\n",
    "            \n",
    "            frame = Frame(self); \n",
    "            frame.pack(side=LEFT, expand=YES, fill=BOTH)\n",
    "            \n",
    "            Label(frame, text=l, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "            \n",
    "            #store the list names \n",
    "            self.listNames.append(l)\n",
    "            \n",
    "            lb = Listbox(frame, width=widthW, borderwidth=0, selectborderwidth=0,\n",
    "                 relief=FLAT, exportselection=FALSE)\n",
    "            lb.pack(expand=YES, fill=BOTH)\n",
    "            #lb.pack(fill=X,expand=1)\n",
    "            #lb.pack\n",
    "            self.lists.append(lb)\n",
    "            \n",
    "            #lb.bind('<B1-Motion>', lambda e, s=self: s._select(e.y))\n",
    "            #lb.bind('<Button-1>', lambda e, s=self: s._select(e.y))\n",
    "            \n",
    "            #lb.bind('<Leave>', lambda e: 'break')\n",
    "            \n",
    "            #lb.bind('<B2-Motion>', lambda e, s=self: s._b2motion(e.x, e.y))\n",
    "            #lb.bind('<Button-2>', lambda e, s=self: s._button2(e.x, e.y))\n",
    "             \n",
    "            for fieldText in self.dropDownTextBox:\n",
    "\n",
    "                if('Rank' in fieldText):\n",
    "                    lab = Label(frame, text=fieldText, borderwidth=0, relief=RAISED)\n",
    "                    lab.pack(side=TOP,fill=BOTH)\n",
    "            \n",
    "                    #Get the current list number \n",
    "                    if listCount+1 == 1:\n",
    "                        currentOptions = self.list1Name\n",
    "                    elif listCount+1 == 2:\n",
    "                        currentOptions = self.list2Name\n",
    "                    elif listCount+1 == 3:\n",
    "                        currentOptions = self.list3Name\n",
    "                        \n",
    "                    variable = StringVar(master)\n",
    "                    variable.set(currentOptions[0]) # default value\n",
    "\n",
    "                    #row = Frame(self)\n",
    "                    #lab = Label(frame, width=15, text=fieldText, anchor='center')\n",
    "                    drowDwn = OptionMenu(frame, variable, *currentOptions)\n",
    "                    \n",
    "                    #Append the variable set from dropdown \n",
    "                    self.rankVar.append(variable)\n",
    "                    \n",
    "                    #lab.pack(side=LEFT,fill=X)\n",
    " \n",
    "                    drowDwn.pack(side=TOP)\n",
    "\n",
    "\n",
    "                elif('Score' in fieldText ):\n",
    "                    variable = StringVar(master)\n",
    "                    variable.set(self.scores[0]) # default value\n",
    "\n",
    "                    #row = Frame(self)\n",
    "                    lab = Label(frame, width=15, text=fieldText, anchor='center')\n",
    "                    drowDwn = OptionMenu(frame, variable, *self.scores)\n",
    "                    \n",
    "                    #Append te varaible set from dropdown \n",
    "                    self.scoreVar.append(variable)\n",
    "\n",
    "                    #lab.pack(side=RIGHT, fill=X)\n",
    "                    drowDwn.pack(side=TOP)\n",
    "            \n",
    "            listCount += 1\n",
    "            \n",
    "        #Set the submit button  \n",
    "        b1 = Button(master, text='Submit', command=self.fetch)\n",
    "        b1.pack(side=BOTTOM, padx=5, pady=5)\n",
    "\n",
    "        #pakcing the frame\n",
    "        #frame = Frame(self); frame.pack(side=LEFT, fill=Y)\n",
    "        \n",
    "        #packing the label\n",
    "        #Label(frame, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "\n",
    "    def _select(self, y):\n",
    "        row = self.lists[0].nearest(y)\n",
    "        self.selection_clear(0, END)\n",
    "        self.selection_set(row)\n",
    "        return 'break'\n",
    "\n",
    "    def _button2(self, x, y):\n",
    "        for l in self.lists: l.scan_mark(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _b2motion(self, x, y):\n",
    "        for l in self.lists: l.scan_dragto(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _scroll(self, *args):\n",
    "        for l in self.lists:\n",
    "            apply(l.yview, args)\n",
    "\n",
    "    def curselection(self):\n",
    "        return self.lists[0].curselection()\n",
    "\n",
    "    def delete(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.delete(first, last)\n",
    "\n",
    "#     def get(self, first, last=None):\n",
    "#         result = []\n",
    "#         for l in self.lists:\n",
    "#             result.append(l.get(first,last))\n",
    "#         if last: return apply(map, [None] + result)\n",
    "#         return result\n",
    "\n",
    "    def index(self, index):\n",
    "        self.lists[0].index(index)\n",
    "\n",
    "    def insert(self, index, *elements):\n",
    "        #Loop through the elements \n",
    "        for element in elements:\n",
    "            i = 0\n",
    "            for l in self.lists:\n",
    "                l.insert(index, element[i])\n",
    "                i = i + 1\n",
    "\n",
    "    def size(self):\n",
    "        return self.lists[0].size()\n",
    "\n",
    "    def see(self, index):\n",
    "        for l in self.lists:\n",
    "            l.see(index)\n",
    "\n",
    "    def selection_anchor(self, index):\n",
    "        for l in self.lists:\n",
    "            l.selection_anchor(index)\n",
    "\n",
    "    def selection_clear(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_clear(first, last)\n",
    "\n",
    "    def selection_includes(self, index):\n",
    "        return self.lists[0].selection_includes(index)\n",
    "\n",
    "    def selection_set(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_set(first, last)\n",
    "            \n",
    "    def fetch(self):\n",
    "        localDict = {}\n",
    "        localRankList = list(map((lambda var: var.get()), self.rankVar))\n",
    "        localScoreList = list(map((lambda var: var.get()), self.scoreVar))\n",
    "        \n",
    "        #lop through each selected restaurant and score, construct the dictionary \n",
    "        for count in range(len(localRankList)):\n",
    "            localDict[localRankList[count]] = int(localScoreList[count])\n",
    "            \n",
    "        print('Your selected restaurants:', localRankList)\n",
    "        print('Your scores given to the restaurants', localScoreList)\n",
    "        print('Your final choice is :', localDict)\n",
    "         \n",
    "        self.responseDict = localDict.copy()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiListbox_entries(Frame):\n",
    "    \n",
    "    def __init__(self, master, lists):\n",
    "        Frame.__init__(self, master)\n",
    "        self.lists = []\n",
    "        self.entries = []\n",
    "        self.fields = 'Like', 'Dislike'\n",
    "        #Var for checkbox\n",
    "        #self.var = IntVar()\n",
    "        self.var = []\n",
    "        self.listNames = []\n",
    "        self.responseDict = {}\n",
    "        \n",
    "        #Loop through the lists, l is the list label and widthW is the width \n",
    "        for l,widthW in lists:\n",
    "            \n",
    "            frame = Frame(self); frame.pack(side=LEFT, expand=YES, fill=BOTH)\n",
    "            \n",
    "            Label(frame, text=l, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "            \n",
    "            #store the list names \n",
    "            self.listNames.append(l)\n",
    "            \n",
    "            lb = Listbox(frame, width=widthW, borderwidth=0, selectborderwidth=0,\n",
    "                 relief=FLAT, exportselection=FALSE)\n",
    "            lb.pack(expand=YES, fill=BOTH)\n",
    "            \n",
    "            self.lists.append(lb)\n",
    "            \n",
    "            lb.bind('<B1-Motion>', lambda e, s=self: s._select(e.y))\n",
    "            lb.bind('<Button-1>', lambda e, s=self: s._select(e.y))\n",
    "            \n",
    "            lb.bind('<Leave>', lambda e: 'break')\n",
    "            \n",
    "            lb.bind('<B2-Motion>', lambda e, s=self: s._b2motion(e.x, e.y))\n",
    "            lb.bind('<Button-2>', lambda e, s=self: s._button2(e.x, e.y))\n",
    "             \n",
    "             #loop through the fields to \n",
    "            for field in self.fields:\n",
    "                #row = Frame(self)\n",
    "                lab = Label(frame, width=15, text=field, anchor='w')\n",
    "                ent = Entry(frame)\n",
    "                #row.pack(side=BOTTOM, fill=Y, padx=5, pady=5) #=BOTTOM\n",
    "                lab.pack()\n",
    "                #ent.pack(side=RIGHT, expand=YES, fill=Y)\n",
    "                ent.pack(side=TOP, fill=X)\n",
    "                self.entries.append((field, ent))\n",
    "            \n",
    "            localVar = IntVar()\n",
    "            \n",
    "            self.var.append(localVar)\n",
    "            \n",
    "            #Checkbox \n",
    "            #c = Checkbutton(frame, text=\"Liked\", variable=localVar, command=self.cb(count))\n",
    "            c = Checkbutton(frame, text=\"Liked\", variable=localVar)\n",
    "            c.pack()\n",
    "            \n",
    "        print(self.var)\n",
    "        #Set the submit button \n",
    "        #master.bind('<Button-1>', (lambda event, e=self.entries: fetch(e)))   \n",
    "        #b1 = Button(master, text='Submit', command=(lambda e=self.entries: self.fetch(e)))\n",
    "        b1 = Button(master, text='Submit', command=self.fetchDict)\n",
    "        b1.pack(side=BOTTOM, padx=5, pady=5)\n",
    "        #b2 = Button(root, text='Quit', command=root.quit)\n",
    "        #b2.pack(side=LEFT, padx=5, pady=5)\n",
    "            \n",
    "        #pakcing the frame\n",
    "        frame = Frame(self); frame.pack(side=LEFT, fill=Y)\n",
    "        \n",
    "        #packing the label\n",
    "        Label(frame, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "        #Setting a scrollbar \n",
    "#         sb = Scrollbar(frame, orient=VERTICAL, command=self._scroll)\n",
    "#         sb.pack(expand=YES, fill=Y)\n",
    "#         self.lists[0]['yscrollcommand']=sb.set\n",
    "\n",
    "    def _select(self, y):\n",
    "        row = self.lists[0].nearest(y)\n",
    "        self.selection_clear(0, END)\n",
    "        self.selection_set(row)\n",
    "        return 'break'\n",
    "    \n",
    "    #For checkbox \n",
    "    def cb(self, index):\n",
    "        print (\"variable is\", self.var[index].get())\n",
    "\n",
    "    def _button2(self, x, y):\n",
    "        for l in self.lists: l.scan_mark(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _b2motion(self, x, y):\n",
    "        for l in self.lists: l.scan_dragto(x, y)\n",
    "        return 'break'\n",
    "\n",
    "    def _scroll(self, *args):\n",
    "        for l in self.lists:\n",
    "            apply(l.yview, args)\n",
    "\n",
    "    def curselection(self):\n",
    "        return self.lists[0].curselection()\n",
    "\n",
    "    def delete(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.delete(first, last)\n",
    "\n",
    "#     def get(self, first, last=None):\n",
    "#         result = []\n",
    "#         for l in self.lists:\n",
    "#             result.append(l.get(first,last))\n",
    "#         if last: return apply(map, [None] + result)\n",
    "#         return result\n",
    "\n",
    "    def index(self, index):\n",
    "        self.lists[0].index(index)\n",
    "\n",
    "    def insert(self, index, *elements):\n",
    "        #Loop through the elements \n",
    "        for element in elements:\n",
    "            i = 0\n",
    "            for l in self.lists:\n",
    "                l.insert(index, element[i])\n",
    "                i = i + 1\n",
    "\n",
    "    def size(self):\n",
    "        return self.lists[0].size()\n",
    "\n",
    "    def see(self, index):\n",
    "        for l in self.lists:\n",
    "            l.see(index)\n",
    "\n",
    "    def selection_anchor(self, index):\n",
    "        for l in self.lists:\n",
    "            l.selection_anchor(index)\n",
    "\n",
    "    def selection_clear(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_clear(first, last)\n",
    "\n",
    "    def selection_includes(self, index):\n",
    "        return self.lists[0].selection_includes(index)\n",
    "\n",
    "    def selection_set(self, first, last=None):\n",
    "        for l in self.lists:\n",
    "            l.selection_set(first, last)\n",
    "            \n",
    "    def fetch(self,entries):\n",
    "        count = 1\n",
    "        \n",
    "        for entry in entries:\n",
    "            if count <= 2:\n",
    "                listCount = 1\n",
    "            elif count <= 4:\n",
    "                listCount = 2\n",
    "            elif count <= 6:\n",
    "                listCount = 3\n",
    "            elif count <= 8:\n",
    "                listCount = 4\n",
    "            elif count <= 10:\n",
    "                listCount = 5             \n",
    "            #print on odd number counts\n",
    "            if count %2 != 0:\n",
    "                print('list:', listCount)\n",
    "            #index 0 is the field \n",
    "            #index 1 is the entry data \n",
    "            field = entry[0]\n",
    "            text  = entry[1].get()\n",
    "            print('%s: \"%s\"' % (field, text))\n",
    "            \n",
    "            count =count + 1\n",
    "            \n",
    "        print(list(map((lambda var: var.get()), self.var)))\n",
    "   \n",
    "    #This function returns a dictionary of the results\n",
    "    def fetchDict(self):\n",
    "        responseDict = {}\n",
    "        count = 1\n",
    "        \n",
    "        likeResult = list(map((lambda var: var.get()), self.var))\n",
    "        \n",
    "        for entry in self.entries:\n",
    "            tempDict = {}\n",
    "            \n",
    "            field = entry[0]\n",
    "            text  = entry[1].get()\n",
    "            # like:\"text content\"\n",
    "            tempDict[field] = text\n",
    "            \n",
    "            if count <= 2:\n",
    "                listCount = 1\n",
    "            elif count <= 4:\n",
    "                listCount = 2\n",
    "            elif count <= 6:\n",
    "                listCount = 3\n",
    "            elif count <= 8:\n",
    "                listCount = 4\n",
    "            elif count <= 10:\n",
    "                listCount = 5      \n",
    "                \n",
    "            #update the dictionary with corresponding listname :  \n",
    "            try:\n",
    "                responseDict[self.listNames[listCount-1]].update(tempDict) \n",
    "            except:\n",
    "                responseDict[self.listNames[listCount-1]] = tempDict \n",
    "            \n",
    "            if count %2 != 0:\n",
    "                #print on odd number counts\n",
    "                print('list:', listCount)\n",
    "                #Get the hit indicator and update the dictionary \n",
    "                tempLikeDict = {'hit': likeResult[listCount-1]}\n",
    "                responseDict[self.listNames[listCount-1]].update(tempLikeDict)\n",
    "            \n",
    "            #Print the current the field and entry text\n",
    "            print('%s: \"%s\"' % (field, text))\n",
    "           \n",
    "            count =count + 1\n",
    "        \n",
    "        #print the hit list\n",
    "        print(list(map((lambda var: var.get()), self.var)))\n",
    "\n",
    "        self.responseDict = responseDict.copy()\n",
    "        \n",
    "        \n",
    "    #Make the entry form \n",
    "    def makeform(root, fields):\n",
    "        #For each field, like \n",
    "        for field in slef.fields:\n",
    "            row = Frame(master)\n",
    "            lab = Label(row, width=15, text=field, anchor='w')\n",
    "            ent = Entry(row)\n",
    "            row.pack(side=TOP, fill=X, padx=5, pady=5)\n",
    "            lab.pack(side=LEFT)\n",
    "            ent.pack(side=RIGHT, expand=YES, fill=X)\n",
    "            self.entries.append((field, ent))\n",
    "            \n",
    "        self.entries =  entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_vappend(a,b):\n",
    "    \"\"\" Takes in 2 csr_matrices and appends the second one to the bottom of the first one. \n",
    "    Much faster than scipy.sparse.vstack but assumes the type to be csr and overwrites\n",
    "    the first matrix instead of copying it. The data, indices, and indptr still get copied.\"\"\"\n",
    "\n",
    "    a.data = np.hstack((a.data,b.data))\n",
    "    a.indices = np.hstack((a.indices,b.indices))\n",
    "    a.indptr = np.hstack((a.indptr,(b.indptr + a.nnz)[1:]))\n",
    "    a._shape = (a.shape[0]+b.shape[0],b.shape[1])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get original dataframe out of the review datastet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_yelp_df(path ='', filename=reviewJsonToronto, sampling= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: categories, dtype: object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking invalid businesses\n",
    "pd.options.display.max_colwidth = 90  \n",
    "df[df[\"categories\"].str.contains('barber',case=False)].categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'..\\\\data\\\\userStudy\\\\dfWhole.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Year</th>\n",
       "      <th>alias</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>...</th>\n",
       "      <th>review_text</th>\n",
       "      <th>transactions</th>\n",
       "      <th>ufc</th>\n",
       "      <th>url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>business_num_id</th>\n",
       "      <th>user_num_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I ordered the lemon mango slush and the lemon taste is very strong.  If you love lemon...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>zsJFjhBQEFQ6gJ7BsNM_Ug</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>6086</td>\n",
       "      <td>1.471925e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Came here on a Sunday afternoon, it wasn't busy at all. I came here for the Sunday spe...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>P7YuMh74-I2cDq7oU8frww</td>\n",
       "      <td>York Regional Municipality, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>2479</td>\n",
       "      <td>1.475381e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>{Grapefruit &amp; Yakult Green Tea with Aloe Jelly} I have found my #1 favourite drink fro...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>C91it8b3odRg0503asUaJA</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>1285</td>\n",
       "      <td>1.478405e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Saw this newly opened bubble tea shop and wanted to give it a try as the whole store i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>dAB-v4B-5_8QgTcoVSnZOw</td>\n",
       "      <td>Vaughan, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>3937</td>\n",
       "      <td>1.474776e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Walked by pmall and the poster of the salty cheese series of drinks caught my attentio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, 2, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>UxwiJpYSqOZJQzUMF6Xl6A</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>3040</td>\n",
       "      <td>1.473134e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I have been debating on whether or not I wanted to give this place a try and yeah, I e...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 2, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>0U52n_sqA9j6UmB4mNVT9A</td>\n",
       "      <td>Richmond Hill, Canada</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>135</td>\n",
       "      <td>1.474085e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Happy Lemon has become my new favourite place for a sweet and refreshing drink!This lo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[5, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>Dt_h4Dt0lVblqRxLLV25YQ</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>1446</td>\n",
       "      <td>1.530331e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Refreshing and different than bubble tea places. They offer interesting special flavor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>SAeScmq3cxbikwnjyTqjxQ</td>\n",
       "      <td>Saint-Laurent, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>2785</td>\n",
       "      <td>1.546924e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>This will be short and sweet. The overall logo is cute. Like most thing in PMall the s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 2]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>XjkgUNYAqnVcuFmU53xP2Q</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>3323</td>\n",
       "      <td>1.527998e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Happy Lemon is one of the numerous Bubble Tea Shops inside Pacific Mall.The first time...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[6, 1, 3]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>CxDOIDnH8gp9KXzpBHJYXw</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>1364</td>\n",
       "      <td>1.521432e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>As \"temporary\" duchess I guess I'll finally write a review :p Drinks I have tried:-hon...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>L_OxAt1gt9l1gokgGoW7Sg</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>1.517116e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I was honestly not satisfied with this place at all. It was my first time and the drin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>51_EJUsPW8NpsO8C9N4JqA</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>590</td>\n",
       "      <td>1.530850e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>21653</td>\n",
       "      <td>True</td>\n",
       "      <td>2018</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>An additional note, I tried the grapefruit lemon slushy &amp; honestly it tastes relativel...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, 0, 1, 0, 0, 1, 2, 1, 2]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>nMAq9WizgiDkZA11GrGLbA</td>\n",
       "      <td>Scarborough, Toronto, Canada</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>4908</td>\n",
       "      <td>1.526616e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I always wanted to try Happy Lemon in PMall as the lemon person with the cute smiling ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3, 2, 6]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>DG1QPjVVsCcXiKP3xGh3pQ</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>1387</td>\n",
       "      <td>1.503202e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I'll try anything once. Salted cheese (iced) coffee was my order. I tried the salted c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8, 5, 7]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>pn_flI3EBNugBEYFp9okxQ</td>\n",
       "      <td>Cerritos, CA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>5136</td>\n",
       "      <td>1.485320e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>My go to is always the milk tea especially when I'm trying a new bubble tea place. So ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>Mql2iMhK_5rS0Co5uRctFQ</td>\n",
       "      <td>Guelph, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>2280</td>\n",
       "      <td>1.522901e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Finally came to Pmall and tried the salted Cheese drink series.Salted Cheese Oolong Te...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>26WgdHfEjWj4BrN-cUNhVw</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>297</td>\n",
       "      <td>1.479532e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I am absolutely in love with happy lemon! I remember having it in Asia and it was neve...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 2]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>7HFkF9A2xaHxLqwcFnJ0JQ</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>803</td>\n",
       "      <td>1.484543e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4 stars for the lemon tea.3 for the Oreo milk tea.They have a promo till August 15 for...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>XbWP6vAli3waJ0iR_lcjOg</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>3314</td>\n",
       "      <td>1.471147e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>This place is located inside Pacific Mall and I believe it's the first store in Toront...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, 1, 2]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>UC27mopi9fL9lVoSyonwSQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>2984</td>\n",
       "      <td>1.471234e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Came across this store at pacfic mall on their grand opening day.Thought maybe i could...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>Ylw1l9OqrzZEiltcEJly9Q</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>3429</td>\n",
       "      <td>1.473653e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>While shopping at Pacific Mall, I was so happy to see a Happy Lemon in the mall. The W...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>EiT_pSuIb08oRn4CfwfMJg</td>\n",
       "      <td>Rockville, MD</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>1531</td>\n",
       "      <td>1.502338e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Salted cheese foam is their specialty. Got it with a green tea. Thought the drink was ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[4, 3, 2]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>2e5V6M4GNufEnbGJpVdCjw</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>354</td>\n",
       "      <td>1.474603e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>21653</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>happy-lemon-markham</td>\n",
       "      <td>Xo1LNzhnwE-ilqsM3ybs9Q</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I was really unimpressed by the customer service I received from this store. I went to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3, 1, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&amp;ut...</td>\n",
       "      <td>ISbHIVNZQoeMchsQUiKQpg</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2169</td>\n",
       "      <td>1877</td>\n",
       "      <td>1.491883e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>272</td>\n",
       "      <td>272</td>\n",
       "      <td>12154</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>the-one-that-got-away-toronto-2</td>\n",
       "      <td>GxxHvymHBJrowNEZG6kNkQ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5*Oh boy,  this may be the first time where Yelp has lead me astray... I've lived by...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, 0, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...</td>\n",
       "      <td>fjNNUJS0dtMr7W0hHMiNVw</td>\n",
       "      <td>Brampton, Canada</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>4189</td>\n",
       "      <td>1.434168e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>273</td>\n",
       "      <td>12154</td>\n",
       "      <td>False</td>\n",
       "      <td>2013</td>\n",
       "      <td>the-one-that-got-away-toronto-2</td>\n",
       "      <td>GxxHvymHBJrowNEZG6kNkQ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I've been to TOTGA location on King West before so I was excited to see this branch op...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[5, 3, 2]</td>\n",
       "      <td>https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...</td>\n",
       "      <td>WXlxViTwXHPBvhioljN9PQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>3189</td>\n",
       "      <td>1.378440e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>12154</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>the-one-that-got-away-toronto-2</td>\n",
       "      <td>GxxHvymHBJrowNEZG6kNkQ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I really wanted to like this place. I've been twice so far though and both times the f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...</td>\n",
       "      <td>QKHgPggBTlP00v3RR8FgRw</td>\n",
       "      <td>The Beach, Toronto, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>2587</td>\n",
       "      <td>1.400386e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "      <td>12154</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>the-one-that-got-away-toronto-2</td>\n",
       "      <td>GxxHvymHBJrowNEZG6kNkQ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>I have to agree with the over reviewers here; great staff but meh food. We ordered the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...</td>\n",
       "      <td>lJp8balcwfW95HnoFCHBBg</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>4723</td>\n",
       "      <td>1.410408e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>12154</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>the-one-that-got-away-toronto-2</td>\n",
       "      <td>GxxHvymHBJrowNEZG6kNkQ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>This place is pretty good. Its small and there's not much seating. The staff are frien...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...</td>\n",
       "      <td>NAcOrPUT_8kze3cXhym_SQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>2308</td>\n",
       "      <td>1.429589e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>12154</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>the-one-that-got-away-toronto-2</td>\n",
       "      <td>GxxHvymHBJrowNEZG6kNkQ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>The service was good and friendly, and the food quite delicious.  I would want to go b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...</td>\n",
       "      <td>hqAr5h90By9XhU0JJaGqcQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>4388</td>\n",
       "      <td>1.418274e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187882</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>747081</td>\n",
       "      <td>747081</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>So happy that Butter Avenue opened on Queen St as it is more accessible for me then th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>FlroRLQ6hWhRApL9tWSO5A</td>\n",
       "      <td>Richmond Hill, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>1623</td>\n",
       "      <td>1.416287e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187883</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>747086</td>\n",
       "      <td>747086</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Don't waste your money for tiny stale macaroons !! $15 for a box of stale dessert !! R...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>E1hLHq6LZ6AoSJzW-oT4FQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>1462</td>\n",
       "      <td>1.458014e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187884</th>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>747088</td>\n",
       "      <td>747088</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Service was great, walked in around 6pm tonight and my friends and I were the only one...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>Zu4jUcx8kTnFDiLIyGcLfg</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>3538</td>\n",
       "      <td>1.414469e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187885</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>747089</td>\n",
       "      <td>747089</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>It may appear large in size especially seeing the photos, but this shop is actually ve...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>LQG9wFTmscbAATp8QWj1hg</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>2149</td>\n",
       "      <td>1.425186e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187886</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>747095</td>\n",
       "      <td>747095</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>The Matcha Lattes keep bringing me back!  They're the only things that keep me sane du...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>8EMxc1vnsLJG3bJuARMItg</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>888</td>\n",
       "      <td>1.418620e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187887</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>747096</td>\n",
       "      <td>747096</td>\n",
       "      <td>13942</td>\n",
       "      <td>True</td>\n",
       "      <td>2016</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>best nutty dark chocolate mousse cake I've ever had.very strong and tasty chocolate fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>dayNT2ayiN_XoU_IWf5lTg</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>3982</td>\n",
       "      <td>1.455426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187888</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>747097</td>\n",
       "      <td>747097</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Bright and cozy place..a perfect place to sit back and relax. I love their macarons.. ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>HxgbvA05jmRxKyJSq4ZmrA</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>1839</td>\n",
       "      <td>1.421471e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187889</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>747098</td>\n",
       "      <td>747098</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>I've always wanted to try the Yonge location but never got a chance because you would ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>46_hoG1edSoTrtfGvmQKRg</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>495</td>\n",
       "      <td>1.422162e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187890</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>747101</td>\n",
       "      <td>747101</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>a Japanese inspired dessert place with great macaroons and tarts. offers a variety of ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>w60EUG_C6iDM5Xd2J-a0Ag</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>5721</td>\n",
       "      <td>1.485839e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187891</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>747104</td>\n",
       "      <td>747104</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>I'm giving this a 2 star solely on their macaroons.  First off, the pistachio macaroon...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>2K58nkDk7Cp9_dezPeJaSA</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>318</td>\n",
       "      <td>1.441944e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187892</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>747106</td>\n",
       "      <td>747106</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A simple designed dessert shop focusing on two main items, macarons and tarts/cakes wi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>lXjgtWP8RdP7LmsZmosdxQ</td>\n",
       "      <td>Thornhill, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>4749</td>\n",
       "      <td>1.415164e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187893</th>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>747108</td>\n",
       "      <td>747108</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>This rating is based solely on the dessert it self and not the customer service becaus...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>qwvqOG9UoClcR4iFnmAPHw</td>\n",
       "      <td>Scarborough, Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>5236</td>\n",
       "      <td>1.545023e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187894</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>747109</td>\n",
       "      <td>747109</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>This is one of my favorite patisseries in the city. I have been a huge fan of Butter A...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>eZeBuiVZWT7u3SktO7mv9w</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>4076</td>\n",
       "      <td>1.544072e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187895</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>747110</td>\n",
       "      <td>747110</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Their desserts are absolutely divine. Butter Avenue has some of the best macarons.. ye...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>AfiSqDmx7Q3qLLgAvhHSRQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>1135</td>\n",
       "      <td>1.547615e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187896</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>747111</td>\n",
       "      <td>747111</td>\n",
       "      <td>13942</td>\n",
       "      <td>True</td>\n",
       "      <td>2018</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Shortly after writing this review I was contacted directly by the owner to rectify the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>9njVfLsRhJgKpJNSPvC38Q</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>1051</td>\n",
       "      <td>1.538539e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187897</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>747112</td>\n",
       "      <td>747112</td>\n",
       "      <td>13942</td>\n",
       "      <td>True</td>\n",
       "      <td>2018</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>I got the St. Honore Pistachio (pistachio tart) and the Terret et Neige for my sister'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[11, 2, 7, 5, 0, 2]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>vs8aSP9ArwqAlb0LeCnFeQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>11.0</td>\n",
       "      <td>990</td>\n",
       "      <td>5692</td>\n",
       "      <td>1.528171e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187898</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>747113</td>\n",
       "      <td>747113</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Came for dessert for a girl's day. We had the Ontario Strawberry Tart, lychee strawber...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>2YRpKZgzi8rdW1rvaiSSMA</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>344</td>\n",
       "      <td>1.531627e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187899</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>747117</td>\n",
       "      <td>747117</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>I had tried BA ages ago but their Yonge location and I can't remember wanting to write...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>L2QfL9m2TOqJLlGZA5M59A</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>2131</td>\n",
       "      <td>1.524370e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187900</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>747119</td>\n",
       "      <td>747119</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>I was able to get myself to the Queen and Spadina location of Butter Avenue to pick up...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>jwctwzboGhQmtC50Juxa9A</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>4580</td>\n",
       "      <td>1.515820e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187901</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>747120</td>\n",
       "      <td>747120</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>We ventured to Butter Avenue on a whim when a food magazine brought them up as one go-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>jsEzCXrpP4jiHVLiAmCwdA</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>4574</td>\n",
       "      <td>1.513228e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187902</th>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>747121</td>\n",
       "      <td>747121</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>My friend bought the movember limited edition cake and pink lady cake as a surprise gi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>pHUutGZOxIEARm27ODBgvw</td>\n",
       "      <td>Ajax, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>5097</td>\n",
       "      <td>1.511845e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187903</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>747125</td>\n",
       "      <td>747125</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tried 2 pastries the matcha one (terre et neige) and the ube chestnut one. The matcha ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>088ICGWrFMiVAzD5vS0cRQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>95</td>\n",
       "      <td>1.508040e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187904</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>747126</td>\n",
       "      <td>747126</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pros:- Nice ambiance - Ok tasting foodCons:- Pricey for the quantity offered.- Tiny po...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>Ko4y7jIissMR8ZGQlMdpaA</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>2114</td>\n",
       "      <td>1.507954e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187905</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>747127</td>\n",
       "      <td>747127</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Wow this place is over priced. I bought some Earl Grey macarons here and they were rea...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>NAcOrPUT_8kze3cXhym_SQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>2308</td>\n",
       "      <td>1.443845e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187906</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>747129</td>\n",
       "      <td>747129</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Their sea salt caramel macarons are my life! This is such a beautiful and inviting pla...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>z0pcAfQINNCncw-YN4umxg</td>\n",
       "      <td>Markham, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>5987</td>\n",
       "      <td>1.468814e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187907</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>747130</td>\n",
       "      <td>747130</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>This store is Butter Avenue's second location in Toronto. The store is slightly smalle...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[4, 0, 2]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>K-U4VE6zMtxrOuezSN0xCQ</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>4.0</td>\n",
       "      <td>990</td>\n",
       "      <td>2031</td>\n",
       "      <td>1.409976e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187908</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>747131</td>\n",
       "      <td>747131</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>The first time I had a macaron, I was really confused. I didn't get the hype surroundi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>-MMPFsniPVNPT42Oigwmpg</td>\n",
       "      <td>Richmond Hill, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>38</td>\n",
       "      <td>1.428293e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187909</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>747134</td>\n",
       "      <td>747134</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>I think Butter Avenue is wonderful! Not only are their macarons some of the very best ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>fOq1xpfj6lfKLq1WANOC_Q</td>\n",
       "      <td>St Catharines, Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>990</td>\n",
       "      <td>4150</td>\n",
       "      <td>1.417928e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187910</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>747136</td>\n",
       "      <td>747136</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>One of the best macaroons I've ever had! If you're a dessert enthusiast you've got to ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>G-Ad4u9rdw2qkfXeQGm7Pw</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>1647</td>\n",
       "      <td>1.430885e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187911</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>747142</td>\n",
       "      <td>747142</td>\n",
       "      <td>13942</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>butter-avenue-toronto-5</td>\n",
       "      <td>EyxQNX6e5V6ggOWnvQyqWg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Wonderful teas and macarons- this particular location is fairly new.  Grab some loose ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...</td>\n",
       "      <td>aBXJK7fk2GDhDmgJEKiBeA</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990</td>\n",
       "      <td>3656</td>\n",
       "      <td>1.428725e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187912 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Day  Month  Unnamed: 0.1  Unnamed: 0_x  Unnamed: 0_y  Updated  Year  \\\n",
       "0        23      8             6             6         21653    False  2016   \n",
       "1         2     10             7             7         21653    False  2016   \n",
       "2         6     11             8             8         21653    False  2016   \n",
       "3        25      9             9             9         21653    False  2016   \n",
       "4         6      9            10            10         21653    False  2016   \n",
       "5        17      9            13            13         21653    False  2016   \n",
       "6        30      6            22            22         21653    False  2018   \n",
       "7         8      1            23            23         21653    False  2019   \n",
       "8         3      6            24            24         21653    False  2018   \n",
       "9        19      3            25            25         21653    False  2018   \n",
       "10       28      1            26            26         21653    False  2018   \n",
       "11        6      7            27            27         21653    False  2018   \n",
       "12       18      5            28            28         21653     True  2018   \n",
       "13       20      8            29            29         21653    False  2017   \n",
       "14       25      1            30            30         21653    False  2017   \n",
       "15        5      4            31            31         21653    False  2018   \n",
       "16       19     11            32            32         21653    False  2016   \n",
       "17       16      1            33            33         21653    False  2017   \n",
       "18       14      8            34            34         21653    False  2016   \n",
       "19       15      8            35            35         21653    False  2016   \n",
       "20       12      9            36            36         21653    False  2016   \n",
       "21       10      8            37            37         21653    False  2017   \n",
       "22       23      9            38            38         21653    False  2016   \n",
       "23       11      4            41            41         21653    False  2017   \n",
       "24       13      6           272           272         12154    False  2015   \n",
       "25        6      9           273           273         12154    False  2013   \n",
       "26       18      5           276           276         12154    False  2014   \n",
       "27       11      9           278           278         12154    False  2014   \n",
       "28       21      4           280           280         12154    False  2015   \n",
       "29       11     12           283           283         12154    False  2014   \n",
       "...     ...    ...           ...           ...           ...      ...   ...   \n",
       "187882   18     11        747081        747081         13942    False  2014   \n",
       "187883   15      3        747086        747086         13942    False  2016   \n",
       "187884   28     10        747088        747088         13942    False  2014   \n",
       "187885    1      3        747089        747089         13942    False  2015   \n",
       "187886   15     12        747095        747095         13942    False  2014   \n",
       "187887   14      2        747096        747096         13942     True  2016   \n",
       "187888   17      1        747097        747097         13942    False  2015   \n",
       "187889   25      1        747098        747098         13942    False  2015   \n",
       "187890   31      1        747101        747101         13942    False  2017   \n",
       "187891   11      9        747104        747104         13942    False  2015   \n",
       "187892    5     11        747106        747106         13942    False  2014   \n",
       "187893   17     12        747108        747108         13942    False  2018   \n",
       "187894    6     12        747109        747109         13942    False  2018   \n",
       "187895   16      1        747110        747110         13942    False  2019   \n",
       "187896    3     10        747111        747111         13942     True  2018   \n",
       "187897    5      6        747112        747112         13942     True  2018   \n",
       "187898   15      7        747113        747113         13942    False  2018   \n",
       "187899   22      4        747117        747117         13942    False  2018   \n",
       "187900   13      1        747119        747119         13942    False  2018   \n",
       "187901   14     12        747120        747120         13942    False  2017   \n",
       "187902   28     11        747121        747121         13942    False  2017   \n",
       "187903   15     10        747125        747125         13942    False  2017   \n",
       "187904   14     10        747126        747126         13942    False  2017   \n",
       "187905    3     10        747127        747127         13942    False  2015   \n",
       "187906   18      7        747129        747129         13942    False  2016   \n",
       "187907    6      9        747130        747130         13942    False  2014   \n",
       "187908    6      4        747131        747131         13942    False  2015   \n",
       "187909    7     12        747134        747134         13942    False  2014   \n",
       "187910    6      5        747136        747136         13942    False  2015   \n",
       "187911   11      4        747142        747142         13942    False  2015   \n",
       "\n",
       "                                  alias             business_id  \\\n",
       "0                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "1                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "2                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "3                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "4                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "5                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "6                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "7                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "8                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "9                   happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "10                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "11                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "12                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "13                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "14                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "15                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "16                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "17                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "18                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "19                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "20                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "21                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "22                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "23                  happy-lemon-markham  Xo1LNzhnwE-ilqsM3ybs9Q   \n",
       "24      the-one-that-got-away-toronto-2  GxxHvymHBJrowNEZG6kNkQ   \n",
       "25      the-one-that-got-away-toronto-2  GxxHvymHBJrowNEZG6kNkQ   \n",
       "26      the-one-that-got-away-toronto-2  GxxHvymHBJrowNEZG6kNkQ   \n",
       "27      the-one-that-got-away-toronto-2  GxxHvymHBJrowNEZG6kNkQ   \n",
       "28      the-one-that-got-away-toronto-2  GxxHvymHBJrowNEZG6kNkQ   \n",
       "29      the-one-that-got-away-toronto-2  GxxHvymHBJrowNEZG6kNkQ   \n",
       "...                                 ...                     ...   \n",
       "187882          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187883          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187884          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187885          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187886          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187887          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187888          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187889          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187890          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187891          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187892          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187893          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187894          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187895          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187896          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187897          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187898          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187899          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187900          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187901          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187902          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187903          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187904          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187905          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187906          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187907          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187908          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187909          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187910          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "187911          butter-avenue-toronto-5  EyxQNX6e5V6ggOWnvQyqWg   \n",
       "\n",
       "        business_stars  ...  \\\n",
       "0                  3.5  ...   \n",
       "1                  3.5  ...   \n",
       "2                  3.5  ...   \n",
       "3                  3.5  ...   \n",
       "4                  3.5  ...   \n",
       "5                  3.5  ...   \n",
       "6                  3.5  ...   \n",
       "7                  3.5  ...   \n",
       "8                  3.5  ...   \n",
       "9                  3.5  ...   \n",
       "10                 3.5  ...   \n",
       "11                 3.5  ...   \n",
       "12                 3.5  ...   \n",
       "13                 3.5  ...   \n",
       "14                 3.5  ...   \n",
       "15                 3.5  ...   \n",
       "16                 3.5  ...   \n",
       "17                 3.5  ...   \n",
       "18                 3.5  ...   \n",
       "19                 3.5  ...   \n",
       "20                 3.5  ...   \n",
       "21                 3.5  ...   \n",
       "22                 3.5  ...   \n",
       "23                 3.5  ...   \n",
       "24                 3.5  ...   \n",
       "25                 3.5  ...   \n",
       "26                 3.5  ...   \n",
       "27                 3.5  ...   \n",
       "28                 3.5  ...   \n",
       "29                 3.5  ...   \n",
       "...                ...  ...   \n",
       "187882             4.0  ...   \n",
       "187883             4.0  ...   \n",
       "187884             4.0  ...   \n",
       "187885             4.0  ...   \n",
       "187886             4.0  ...   \n",
       "187887             4.0  ...   \n",
       "187888             4.0  ...   \n",
       "187889             4.0  ...   \n",
       "187890             4.0  ...   \n",
       "187891             4.0  ...   \n",
       "187892             4.0  ...   \n",
       "187893             4.0  ...   \n",
       "187894             4.0  ...   \n",
       "187895             4.0  ...   \n",
       "187896             4.0  ...   \n",
       "187897             4.0  ...   \n",
       "187898             4.0  ...   \n",
       "187899             4.0  ...   \n",
       "187900             4.0  ...   \n",
       "187901             4.0  ...   \n",
       "187902             4.0  ...   \n",
       "187903             4.0  ...   \n",
       "187904             4.0  ...   \n",
       "187905             4.0  ...   \n",
       "187906             4.0  ...   \n",
       "187907             4.0  ...   \n",
       "187908             4.0  ...   \n",
       "187909             4.0  ...   \n",
       "187910             4.0  ...   \n",
       "187911             4.0  ...   \n",
       "\n",
       "                                                                                      review_text  \\\n",
       "0       I ordered the lemon mango slush and the lemon taste is very strong.  If you love lemon...   \n",
       "1       Came here on a Sunday afternoon, it wasn't busy at all. I came here for the Sunday spe...   \n",
       "2       {Grapefruit & Yakult Green Tea with Aloe Jelly} I have found my #1 favourite drink fro...   \n",
       "3       Saw this newly opened bubble tea shop and wanted to give it a try as the whole store i...   \n",
       "4       Walked by pmall and the poster of the salty cheese series of drinks caught my attentio...   \n",
       "5       I have been debating on whether or not I wanted to give this place a try and yeah, I e...   \n",
       "6       Happy Lemon has become my new favourite place for a sweet and refreshing drink!This lo...   \n",
       "7       Refreshing and different than bubble tea places. They offer interesting special flavor...   \n",
       "8       This will be short and sweet. The overall logo is cute. Like most thing in PMall the s...   \n",
       "9       Happy Lemon is one of the numerous Bubble Tea Shops inside Pacific Mall.The first time...   \n",
       "10      As \"temporary\" duchess I guess I'll finally write a review :p Drinks I have tried:-hon...   \n",
       "11      I was honestly not satisfied with this place at all. It was my first time and the drin...   \n",
       "12      An additional note, I tried the grapefruit lemon slushy & honestly it tastes relativel...   \n",
       "13      I always wanted to try Happy Lemon in PMall as the lemon person with the cute smiling ...   \n",
       "14      I'll try anything once. Salted cheese (iced) coffee was my order. I tried the salted c...   \n",
       "15      My go to is always the milk tea especially when I'm trying a new bubble tea place. So ...   \n",
       "16      Finally came to Pmall and tried the salted Cheese drink series.Salted Cheese Oolong Te...   \n",
       "17      I am absolutely in love with happy lemon! I remember having it in Asia and it was neve...   \n",
       "18      4 stars for the lemon tea.3 for the Oreo milk tea.They have a promo till August 15 for...   \n",
       "19      This place is located inside Pacific Mall and I believe it's the first store in Toront...   \n",
       "20      Came across this store at pacfic mall on their grand opening day.Thought maybe i could...   \n",
       "21      While shopping at Pacific Mall, I was so happy to see a Happy Lemon in the mall. The W...   \n",
       "22      Salted cheese foam is their specialty. Got it with a green tea. Thought the drink was ...   \n",
       "23      I was really unimpressed by the customer service I received from this store. I went to...   \n",
       "24      4.5*Oh boy,  this may be the first time where Yelp has lead me astray... I've lived by...   \n",
       "25      I've been to TOTGA location on King West before so I was excited to see this branch op...   \n",
       "26      I really wanted to like this place. I've been twice so far though and both times the f...   \n",
       "27      I have to agree with the over reviewers here; great staff but meh food. We ordered the...   \n",
       "28      This place is pretty good. Its small and there's not much seating. The staff are frien...   \n",
       "29      The service was good and friendly, and the food quite delicious.  I would want to go b...   \n",
       "...                                                                                           ...   \n",
       "187882  So happy that Butter Avenue opened on Queen St as it is more accessible for me then th...   \n",
       "187883  Don't waste your money for tiny stale macaroons !! $15 for a box of stale dessert !! R...   \n",
       "187884  Service was great, walked in around 6pm tonight and my friends and I were the only one...   \n",
       "187885  It may appear large in size especially seeing the photos, but this shop is actually ve...   \n",
       "187886  The Matcha Lattes keep bringing me back!  They're the only things that keep me sane du...   \n",
       "187887  best nutty dark chocolate mousse cake I've ever had.very strong and tasty chocolate fl...   \n",
       "187888  Bright and cozy place..a perfect place to sit back and relax. I love their macarons.. ...   \n",
       "187889  I've always wanted to try the Yonge location but never got a chance because you would ...   \n",
       "187890  a Japanese inspired dessert place with great macaroons and tarts. offers a variety of ...   \n",
       "187891  I'm giving this a 2 star solely on their macaroons.  First off, the pistachio macaroon...   \n",
       "187892  A simple designed dessert shop focusing on two main items, macarons and tarts/cakes wi...   \n",
       "187893  This rating is based solely on the dessert it self and not the customer service becaus...   \n",
       "187894  This is one of my favorite patisseries in the city. I have been a huge fan of Butter A...   \n",
       "187895  Their desserts are absolutely divine. Butter Avenue has some of the best macarons.. ye...   \n",
       "187896  Shortly after writing this review I was contacted directly by the owner to rectify the...   \n",
       "187897  I got the St. Honore Pistachio (pistachio tart) and the Terret et Neige for my sister'...   \n",
       "187898  Came for dessert for a girl's day. We had the Ontario Strawberry Tart, lychee strawber...   \n",
       "187899  I had tried BA ages ago but their Yonge location and I can't remember wanting to write...   \n",
       "187900  I was able to get myself to the Queen and Spadina location of Butter Avenue to pick up...   \n",
       "187901  We ventured to Butter Avenue on a whim when a food magazine brought them up as one go-...   \n",
       "187902  My friend bought the movember limited edition cake and pink lady cake as a surprise gi...   \n",
       "187903  Tried 2 pastries the matcha one (terre et neige) and the ube chestnut one. The matcha ...   \n",
       "187904  Pros:- Nice ambiance - Ok tasting foodCons:- Pricey for the quantity offered.- Tiny po...   \n",
       "187905  Wow this place is over priced. I bought some Earl Grey macarons here and they were rea...   \n",
       "187906  Their sea salt caramel macarons are my life! This is such a beautiful and inviting pla...   \n",
       "187907  This store is Butter Avenue's second location in Toronto. The store is slightly smalle...   \n",
       "187908  The first time I had a macaron, I was really confused. I didn't get the hype surroundi...   \n",
       "187909  I think Butter Avenue is wonderful! Not only are their macarons some of the very best ...   \n",
       "187910  One of the best macaroons I've ever had! If you're a dessert enthusiast you've got to ...   \n",
       "187911  Wonderful teas and macarons- this particular location is fairly new.  Grab some loose ...   \n",
       "\n",
       "       transactions                          ufc  \\\n",
       "0                []                    [1, 1, 1]   \n",
       "1                []                    [1, 0, 0]   \n",
       "2                []                    [0, 0, 0]   \n",
       "3                []                    [0, 0, 0]   \n",
       "4                []                    [2, 2, 1]   \n",
       "5                []                    [1, 2, 0]   \n",
       "6                []                    [5, 0, 0]   \n",
       "7                []                    [0, 0, 1]   \n",
       "8                []                    [1, 0, 2]   \n",
       "9                []                    [6, 1, 3]   \n",
       "10               []                    [1, 0, 0]   \n",
       "11               []                    [1, 0, 1]   \n",
       "12               []  [2, 0, 1, 0, 0, 1, 2, 1, 2]   \n",
       "13               []                    [3, 2, 6]   \n",
       "14               []                    [8, 5, 7]   \n",
       "15               []                    [1, 0, 1]   \n",
       "16               []                    [2, 2, 2]   \n",
       "17               []                    [1, 0, 2]   \n",
       "18               []                    [3, 0, 0]   \n",
       "19               []                    [2, 1, 2]   \n",
       "20               []                    [1, 1, 1]   \n",
       "21               []                    [1, 2, 3]   \n",
       "22               []                    [4, 3, 2]   \n",
       "23               []                    [3, 1, 1]   \n",
       "24               []                    [2, 0, 1]   \n",
       "25               []                    [5, 3, 2]   \n",
       "26               []                    [1, 0, 0]   \n",
       "27               []                    [0, 0, 0]   \n",
       "28               []                    [0, 0, 0]   \n",
       "29               []                    [0, 0, 0]   \n",
       "...             ...                          ...   \n",
       "187882           []                    [1, 0, 0]   \n",
       "187883           []                    [0, 0, 0]   \n",
       "187884           []                    [1, 1, 1]   \n",
       "187885           []                    [0, 1, 0]   \n",
       "187886           []                    [0, 1, 0]   \n",
       "187887           []           [0, 0, 0, 0, 0, 0]   \n",
       "187888           []                    [0, 0, 0]   \n",
       "187889           []                    [0, 0, 0]   \n",
       "187890           []                    [0, 0, 0]   \n",
       "187891           []                    [0, 0, 0]   \n",
       "187892           []                    [0, 0, 0]   \n",
       "187893           []                    [0, 0, 0]   \n",
       "187894           []                    [0, 0, 0]   \n",
       "187895           []                    [0, 0, 0]   \n",
       "187896           []           [0, 0, 1, 1, 0, 0]   \n",
       "187897           []          [11, 2, 7, 5, 0, 2]   \n",
       "187898           []                    [1, 0, 0]   \n",
       "187899           []                    [0, 1, 0]   \n",
       "187900           []                    [1, 0, 0]   \n",
       "187901           []                    [1, 0, 0]   \n",
       "187902           []                    [0, 0, 1]   \n",
       "187903           []                    [0, 0, 0]   \n",
       "187904           []                    [0, 0, 0]   \n",
       "187905           []                    [0, 0, 0]   \n",
       "187906           []                    [0, 0, 0]   \n",
       "187907           []                    [4, 0, 2]   \n",
       "187908           []                    [0, 1, 0]   \n",
       "187909           []                    [1, 0, 0]   \n",
       "187910           []                    [0, 0, 0]   \n",
       "187911           []                    [0, 0, 0]   \n",
       "\n",
       "                                                                                              url  \\\n",
       "0       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "1       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "2       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "3       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "4       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "5       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "6       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "7       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "8       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "9       https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "10      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "11      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "12      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "13      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "14      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "15      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "16      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "17      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "18      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "19      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "20      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "21      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "22      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "23      https://www.yelp.com/biz/happy-lemon-markham?adjust_creative=ZbO96qTvvfSmFTkvkUBjkQ&ut...   \n",
       "24      https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...   \n",
       "25      https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...   \n",
       "26      https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...   \n",
       "27      https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...   \n",
       "28      https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...   \n",
       "29      https://www.yelp.com/biz/the-one-that-got-away-toronto-2?adjust_creative=U9nPhxGL-EYET...   \n",
       "...                                                                                           ...   \n",
       "187882  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187883  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187884  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187885  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187886  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187887  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187888  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187889  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187890  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187891  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187892  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187893  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187894  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187895  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187896  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187897  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187898  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187899  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187900  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187901  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187902  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187903  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187904  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187905  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187906  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187907  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187908  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187909  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187910  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "187911  https://www.yelp.com/biz/butter-avenue-toronto-5?adjust_creative=9LfdvYfx0rVPnDmG5bc0i...   \n",
       "\n",
       "                       user_id                            user_loc  \\\n",
       "0       zsJFjhBQEFQ6gJ7BsNM_Ug                     Toronto, Canada   \n",
       "1       P7YuMh74-I2cDq7oU8frww  York Regional Municipality, Canada   \n",
       "2       C91it8b3odRg0503asUaJA                     Markham, Canada   \n",
       "3       dAB-v4B-5_8QgTcoVSnZOw                     Vaughan, Canada   \n",
       "4       UxwiJpYSqOZJQzUMF6Xl6A                     Toronto, Canada   \n",
       "5       0U52n_sqA9j6UmB4mNVT9A               Richmond Hill, Canada   \n",
       "6       Dt_h4Dt0lVblqRxLLV25YQ                     Markham, Canada   \n",
       "7       SAeScmq3cxbikwnjyTqjxQ               Saint-Laurent, Canada   \n",
       "8       XjkgUNYAqnVcuFmU53xP2Q                     Toronto, Canada   \n",
       "9       CxDOIDnH8gp9KXzpBHJYXw                     Markham, Canada   \n",
       "10      L_OxAt1gt9l1gokgGoW7Sg                     Markham, Canada   \n",
       "11      51_EJUsPW8NpsO8C9N4JqA                     Markham, Canada   \n",
       "12      nMAq9WizgiDkZA11GrGLbA        Scarborough, Toronto, Canada   \n",
       "13      DG1QPjVVsCcXiKP3xGh3pQ                     Markham, Canada   \n",
       "14      pn_flI3EBNugBEYFp9okxQ                        Cerritos, CA   \n",
       "15      Mql2iMhK_5rS0Co5uRctFQ                      Guelph, Canada   \n",
       "16      26WgdHfEjWj4BrN-cUNhVw                     Toronto, Canada   \n",
       "17      7HFkF9A2xaHxLqwcFnJ0JQ                     Markham, Canada   \n",
       "18      XbWP6vAli3waJ0iR_lcjOg                     Toronto, Canada   \n",
       "19      UC27mopi9fL9lVoSyonwSQ                     Toronto, Canada   \n",
       "20      Ylw1l9OqrzZEiltcEJly9Q                     Markham, Canada   \n",
       "21      EiT_pSuIb08oRn4CfwfMJg                       Rockville, MD   \n",
       "22      2e5V6M4GNufEnbGJpVdCjw                     Markham, Canada   \n",
       "23      ISbHIVNZQoeMchsQUiKQpg                     Toronto, Canada   \n",
       "24      fjNNUJS0dtMr7W0hHMiNVw                    Brampton, Canada   \n",
       "25      WXlxViTwXHPBvhioljN9PQ                     Toronto, Canada   \n",
       "26      QKHgPggBTlP00v3RR8FgRw          The Beach, Toronto, Canada   \n",
       "27      lJp8balcwfW95HnoFCHBBg                     Toronto, Canada   \n",
       "28      NAcOrPUT_8kze3cXhym_SQ                     Toronto, Canada   \n",
       "29      hqAr5h90By9XhU0JJaGqcQ                     Toronto, Canada   \n",
       "...                        ...                                 ...   \n",
       "187882  FlroRLQ6hWhRApL9tWSO5A               Richmond Hill, Canada   \n",
       "187883  E1hLHq6LZ6AoSJzW-oT4FQ                     Toronto, Canada   \n",
       "187884  Zu4jUcx8kTnFDiLIyGcLfg                     Toronto, Canada   \n",
       "187885  LQG9wFTmscbAATp8QWj1hg                           Hong Kong   \n",
       "187886  8EMxc1vnsLJG3bJuARMItg                     Toronto, Canada   \n",
       "187887  dayNT2ayiN_XoU_IWf5lTg                     Toronto, Canada   \n",
       "187888  HxgbvA05jmRxKyJSq4ZmrA                     Toronto, Canada   \n",
       "187889  46_hoG1edSoTrtfGvmQKRg                     Markham, Canada   \n",
       "187890  w60EUG_C6iDM5Xd2J-a0Ag                     Toronto, Canada   \n",
       "187891  2K58nkDk7Cp9_dezPeJaSA                     Toronto, Canada   \n",
       "187892  lXjgtWP8RdP7LmsZmosdxQ                   Thornhill, Canada   \n",
       "187893  qwvqOG9UoClcR4iFnmAPHw        Scarborough, Toronto, Canada   \n",
       "187894  eZeBuiVZWT7u3SktO7mv9w                     Markham, Canada   \n",
       "187895  AfiSqDmx7Q3qLLgAvhHSRQ                     Toronto, Canada   \n",
       "187896  9njVfLsRhJgKpJNSPvC38Q                     Toronto, Canada   \n",
       "187897  vs8aSP9ArwqAlb0LeCnFeQ                     Toronto, Canada   \n",
       "187898  2YRpKZgzi8rdW1rvaiSSMA                     Toronto, Canada   \n",
       "187899  L2QfL9m2TOqJLlGZA5M59A                     Toronto, Canada   \n",
       "187900  jwctwzboGhQmtC50Juxa9A                     Markham, Canada   \n",
       "187901  jsEzCXrpP4jiHVLiAmCwdA                     Markham, Canada   \n",
       "187902  pHUutGZOxIEARm27ODBgvw                        Ajax, Canada   \n",
       "187903  088ICGWrFMiVAzD5vS0cRQ                     Toronto, Canada   \n",
       "187904  Ko4y7jIissMR8ZGQlMdpaA                     Toronto, Canada   \n",
       "187905  NAcOrPUT_8kze3cXhym_SQ                     Toronto, Canada   \n",
       "187906  z0pcAfQINNCncw-YN4umxg                     Markham, Canada   \n",
       "187907  K-U4VE6zMtxrOuezSN0xCQ                     Toronto, Canada   \n",
       "187908  -MMPFsniPVNPT42Oigwmpg               Richmond Hill, Canada   \n",
       "187909  fOq1xpfj6lfKLq1WANOC_Q               St Catharines, Canada   \n",
       "187910  G-Ad4u9rdw2qkfXeQGm7Pw                     Toronto, Canada   \n",
       "187911  aBXJK7fk2GDhDmgJEKiBeA                     Toronto, Canada   \n",
       "\n",
       "        vote_count business_num_id user_num_id     timestamp  \n",
       "0              1.0            2169        6086  1.471925e+09  \n",
       "1              1.0            2169        2479  1.475381e+09  \n",
       "2              0.0            2169        1285  1.478405e+09  \n",
       "3              0.0            2169        3937  1.474776e+09  \n",
       "4              3.0            2169        3040  1.473134e+09  \n",
       "5              3.0            2169         135  1.474085e+09  \n",
       "6              5.0            2169        1446  1.530331e+09  \n",
       "7              1.0            2169        2785  1.546924e+09  \n",
       "8              2.0            2169        3323  1.527998e+09  \n",
       "9              7.0            2169        1364  1.521432e+09  \n",
       "10             1.0            2169        2169  1.517116e+09  \n",
       "11             2.0            2169         590  1.530850e+09  \n",
       "12             3.0            2169        4908  1.526616e+09  \n",
       "13             6.0            2169        1387  1.503202e+09  \n",
       "14            10.0            2169        5136  1.485320e+09  \n",
       "15             1.0            2169        2280  1.522901e+09  \n",
       "16             4.0            2169         297  1.479532e+09  \n",
       "17             2.0            2169         803  1.484543e+09  \n",
       "18             3.0            2169        3314  1.471147e+09  \n",
       "19             3.0            2169        2984  1.471234e+09  \n",
       "20             1.0            2169        3429  1.473653e+09  \n",
       "21             3.0            2169        1531  1.502338e+09  \n",
       "22             5.0            2169         354  1.474603e+09  \n",
       "23             3.0            2169        1877  1.491883e+09  \n",
       "24             2.0            1110        4189  1.434168e+09  \n",
       "25             8.0            1110        3189  1.378440e+09  \n",
       "26             1.0            1110        2587  1.400386e+09  \n",
       "27             0.0            1110        4723  1.410408e+09  \n",
       "28             0.0            1110        2308  1.429589e+09  \n",
       "29             0.0            1110        4388  1.418274e+09  \n",
       "...            ...             ...         ...           ...  \n",
       "187882         1.0             990        1623  1.416287e+09  \n",
       "187883         0.0             990        1462  1.458014e+09  \n",
       "187884         1.0             990        3538  1.414469e+09  \n",
       "187885         1.0             990        2149  1.425186e+09  \n",
       "187886         1.0             990         888  1.418620e+09  \n",
       "187887         0.0             990        3982  1.455426e+09  \n",
       "187888         0.0             990        1839  1.421471e+09  \n",
       "187889         0.0             990         495  1.422162e+09  \n",
       "187890         0.0             990        5721  1.485839e+09  \n",
       "187891         0.0             990         318  1.441944e+09  \n",
       "187892         0.0             990        4749  1.415164e+09  \n",
       "187893         0.0             990        5236  1.545023e+09  \n",
       "187894         0.0             990        4076  1.544072e+09  \n",
       "187895         0.0             990        1135  1.547615e+09  \n",
       "187896         1.0             990        1051  1.538539e+09  \n",
       "187897        11.0             990        5692  1.528171e+09  \n",
       "187898         1.0             990         344  1.531627e+09  \n",
       "187899         1.0             990        2131  1.524370e+09  \n",
       "187900         1.0             990        4580  1.515820e+09  \n",
       "187901         1.0             990        4574  1.513228e+09  \n",
       "187902         1.0             990        5097  1.511845e+09  \n",
       "187903         0.0             990          95  1.508040e+09  \n",
       "187904         0.0             990        2114  1.507954e+09  \n",
       "187905         0.0             990        2308  1.443845e+09  \n",
       "187906         0.0             990        5987  1.468814e+09  \n",
       "187907         4.0             990        2031  1.409976e+09  \n",
       "187908         1.0             990          38  1.428293e+09  \n",
       "187909         1.0             990        4150  1.417928e+09  \n",
       "187910         0.0             990        1647  1.430885e+09  \n",
       "187911         0.0             990        3656  1.428725e+09  \n",
       "\n",
       "[187912 rows x 44 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rating-UI matrix and timestepm-UI matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix, timestamp_matrix , I_C_matrix = get_rating_timestamp_matrix(df)\n",
    "\n",
    "# get ratingWuserAvg_matrix\n",
    "rating_array = rating_matrix.toarray()\n",
    "user_average_array = rating_array.sum(axis = 1)/np.count_nonzero(rating_array,axis = 1)\n",
    "init_UI = np.zeros(rating_array.shape)\n",
    "init_UI[rating_array.nonzero()] = 1\n",
    "for i in range(user_average_array.shape[0]):\n",
    "    init_UI[i] = init_UI[i] * (user_average_array[i]-0.001) \n",
    "user_average_array = init_UI\n",
    "ratingWuserAvg_array = rating_array - user_average_array\n",
    "ratingWuserAvg_matrix=sparse.csr_matrix(ratingWuserAvg_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to get rtrain-UI matrix and valid and test.. item_index_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  del sys.path[0]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6100/6100 [00:01<00:00, 4948.59it/s]\n"
     ]
    }
   ],
   "source": [
    "rtrain_implicit, rvalid_implicit, rtest_implicit, rtrain_userAvg_implicit, rvalid_userAvg_implicit, rtest_userAvg_implicit, nonzero_index, rtime, item_idx_matrix_train_implicit,item_idx_matrix_valid_implicit, item_idx_matrix_test_implicit = time_ordered_splitModified(rating_matrix=rating_matrix, ratingWuserAvg_matrix=ratingWuserAvg_matrix, timestamp_matrix=timestamp_matrix,\n",
    "                                                                     ratio=[0.5,0.2,0.3],\n",
    "                                                                     implicit=True,\n",
    "                                                                     remove_empty=False, threshold=3,sampling=False, \n",
    "                                                                     sampling_ratio=0.1, trainSampling=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6100/6100 [00:01<00:00, 3964.00it/s]\n"
     ]
    }
   ],
   "source": [
    "rtrain, rvalid, rtest, rtrain_userAvg, rvalid_userAvg, rtest_userAvg, nonzero_index, rtime, item_idx_matrix_train,item_idx_matrix_valid, item_idx_matrix_test = time_ordered_splitModified(rating_matrix=rating_matrix, ratingWuserAvg_matrix=ratingWuserAvg_matrix, timestamp_matrix=timestamp_matrix,\n",
    "                                                                     ratio=[0.5,0.2,0.3],\n",
    "                                                                     implicit=False,\n",
    "                                                                     remove_empty=False, threshold=3,\n",
    "                                                                     sampling=False, sampling_ratio=0.1, \n",
    "                                                                     trainSampling=0.95)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTENTION: I am combining rtrain+rvalid+rtest over here to use for user study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrain = rtrain + rvalid + rtest \n",
    "rtrain_implicit = rtrain_implicit + rvalid_implicit + rtest_implicit\n",
    "rtrain_userAvg = rtrain_userAvg + rvalid_userAvg + rtest_userAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_numpy(matrix, path, model):\n",
    "    save_npz('{}{}'.format(path, model), matrix)\n",
    "save_numpy(rtrain, \"..\\\\data\\\\userStudy\\\\\", \"Rtrain\")\n",
    "save_numpy(rtrain_implicit, \"..\\\\data\\\\userStudy\\\\\", \"Rtrain_implicit\")\n",
    "save_numpy(rtrain_userAvg, \"..\\\\data\\\\userStudy\\\\\", \"Rtrain_userAvg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I am modifing df_train to the whole df as well, since we are using the whole data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get df shrink to df_train for rtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Get the list of row index for the training set \n",
    "# lst_train = get_corpus_idx_list(df, item_idx_matrix_train)\n",
    "\n",
    "# # Get the training dataframe from the original dataframe\n",
    "# df_train = df.loc[lst_train]\n",
    "\n",
    "# #Resetting the index of the train data\n",
    "# df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3998"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_train['business_num_id'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using term frequency only to compute corpus and X(review vs. terms) CounterVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The entire corpus\n",
    "#corpus = preprocess(df_train)\n",
    "# X row: df_train row, column: key words frequency \n",
    "# When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
    "#cv=CountVectorizer(max_df=0.9,stop_words=stop_words, max_features=5000, ngram_range=(1,1))\n",
    "#X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If using TD-IDF to compute corpus and X (business vs. terms) TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_I_K(df_train, max_features_num = 5000):\n",
    "    corpus = preprocess(df_train)\n",
    "    dict_text = {}\n",
    "    for i in range(len(corpus)):\n",
    "        if df_train['business_num_id'][i] not in dict_text:\n",
    "            dict_text[df_train['business_num_id'][i]] = corpus[i]\n",
    "        else:\n",
    "            temp = dict_text[df_train['business_num_id'][i]]\n",
    "            temp = temp + corpus[i]\n",
    "            dict_text[df_train['business_num_id'][i]] = temp\n",
    "    list_text = []\n",
    "    for key in range(0,max(list(dict_text.keys()))+1) :\n",
    "        if key not in dict_text.keys():\n",
    "            list_text.extend([\"\"])\n",
    "        else:\n",
    "            list_text.extend([dict_text[key]])\n",
    "    vectorizer = TfidfVectorizer(max_df=0.9,stop_words=stop_words, max_features=max_features_num, ngram_range=(1,1))\n",
    "    X_cleaned = vectorizer.fit_transform(list_text).toarray()\n",
    "    return csr_matrix(X_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 187912/187912 [01:04<00:00, 2934.27it/s]\n"
     ]
    }
   ],
   "source": [
    "X_cleaned_sparse = get_I_K(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store initial similarity matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "UU_similarity_explicit = train(rtrain)\n",
    "UU_similarity_implicit = train(rtrain_implicit)\n",
    "II_similarity_usingUI = train(rtrain.T)\n",
    "#Get II from IK\n",
    "IK_MATRIX = X_cleaned_sparse\n",
    "II_similarity_usingIK = train(IK_MATRIX)\n",
    "II_similarity_usingIC = train(I_C_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Store similarity matrices\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\UU_explicit.npy\",UU_similarity_explicit)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\UU_implicit.npy\",UU_similarity_implicit)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\II_usingIU.npy\",II_similarity_usingUI)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\II_usingIK.npy\", II_similarity_usingIK)\n",
    "# np.save(\"..\\\\data\\\\userStudy\\\\II_usingIC.npy\",II_similarity_usingIC)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial User Input Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Popularity Metrics\n",
    "#### get the popular items in three ways\n",
    "1. avg stars\n",
    "2. number of reviews\n",
    "3. percentage liked\n",
    "\n",
    "The small analysis and the map are in the Analyse_3_ways_of_popularities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of reviews popularity list, redundent with the output of the next method\n",
    "dff_popular = df.copy()\n",
    "dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "#Get the list of restaurants accoridng to their popularity level\n",
    "popular_list = dff_popular[\"business_num_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3998/3998 [02:09<00:00, 30.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# get number of users and number of items\n",
    "numUsers = rtrain.shape[0]\n",
    "numItems = rtrain.shape[1]\n",
    "\n",
    "# get the 1d array of avg. stars, number of reviews and percentage liked ratio for the three popular metric\n",
    "popular_list_num_of_reviews,popular_list_avg_stars,popular_list_liked_ratio = get_three_popularity_matrix(df,rtrain)\n",
    "\n",
    "# transfer to a matrix(list * number of users)\n",
    "matrix_popular_list_num_of_reviews = np.tile(popular_list_num_of_reviews,(numUsers+1,1))\n",
    "#for propos, when taking in user data\n",
    "matrix_popular_list_avg_stars = np.tile(popular_list_avg_stars,(numUsers+1,1))\n",
    "#for recommendation\n",
    "matrix_popular_list_liked_ratio = np.tile(popular_list_liked_ratio,(numUsers+1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend 3 lists for three locations by using \"popular_list_liked_ratio\" method\n",
    "\n",
    "Note that the input of the geographical_dist method can only be list or n-d array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff = df.copy()\n",
    "# dff_popular = df.copy()\n",
    "# dff_popular = dff_popular.sort_values(by=[\"review_count_y\"], ascending=False).drop_duplicates(subset = 'business_id', keep = 'first')\n",
    "# popular_list = dff_popular[\"business_num_id\"].tolist()\n",
    "# dundas_and_yonge = Point(\"43.6561,-79.3802\")\n",
    "# bay_and_queens = Point(\"43.6518,-79.3802\")\n",
    "# king_and_jarvis = Point(\"43.650577,-79.371887\")\n",
    "# bloor_and_yonge = Point(\"43.670409,-79.386814\")\n",
    "# yonge_and_eglinton = Point(\"43.7064,-79.3986\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "isList\n",
      "3998\n",
      "<class 'list'>\n",
      "isList\n",
      "3998\n",
      "<class 'list'>\n",
      "isList\n",
      "3998\n"
     ]
    }
   ],
   "source": [
    "# get a copy of df\n",
    "df_location = df.copy()\n",
    "\n",
    "# three locations for user input\n",
    "yonge_and_finch = Point(\"43.779824, -79.415665\")\n",
    "bloor_and_bathurst = Point(\"43.665194,-79.411208\")\n",
    "queen_and_spadina = Point(\"43.648772,-79.396259\")\n",
    "\n",
    "# three locations for user recommendation\n",
    "bloor_and_yonge = Point(\"43.670409,-79.386814\")\n",
    "dundas_and_yonge = Point(\"43.6561,-79.3802\")\n",
    "spadina_and_dundas = Point(\"43.653004,-79.398082\")\n",
    "\n",
    "# list of percentage liked ratio (transfer the format in order to feed in to the geographical_dist method)\n",
    "list_popular_liked_ratio = popular_list_liked_ratio.tolist()\n",
    "\n",
    "# popularity list for input does not need to input the user_id\n",
    "# put user_id as 0 here but it does not matter\n",
    "# bus_indexRange = 15, gives a list of 15 restaurants per location\n",
    "bus_indexRange = 15\n",
    "yonge_and_finch_list = geographical_dist(list_popular_liked_ratio,yonge_and_finch,0, bus_indexRange)\n",
    "bloor_and_bathurst_list = geographical_dist(list_popular_liked_ratio,bloor_and_bathurst,0, bus_indexRange)\n",
    "queen_and_spadina_list = geographical_dist(list_popular_liked_ratio,queen_and_spadina,0, bus_indexRange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of restaurants for user demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# df_location_yonge_and_finch=df_location[df_location[\"business_num_id\"].isin(yonge_and_finch_list)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\", \"price\", \"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})\n",
    "# df_location_yonge_and_finch.head(2)\n",
    "# df_location_bloor_and_bathurst_list=df_location[df_location[\"business_num_id\"].isin(bloor_and_bathurst_list)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\",\"price\",\"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})\n",
    "# df_location_bloor_and_bathurst_list.head(2)\n",
    "# df_location_queen_and_spadina_list=df_location[df_location[\"business_num_id\"].isin(queen_and_spadina_list)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\",\"price\",\"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})\n",
    "# df_location_queen_and_spadina_list.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the dictionary to be used for UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\uff0c' in position 44: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-c1bf5ad49b8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\\\\data\\\\userStudy\\\\bloorBathurstResDict.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict2_bloorBathurst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\\\\data\\\\userStudy\\\\queenSpadinaResDict.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict3_queenSpadina\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\uff0c' in position 44: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "#Construct the dictionary to be used for UI \n",
    "#0 is hard coded, not used for now \n",
    "dict1_yongeFinch = constructResDictionary(0, bus_indexRange, yonge_and_finch_list)\n",
    "dict2_bloorBathurst = constructResDictionary(0, bus_indexRange, bloor_and_bathurst_list)\n",
    "dict3_queenSpadina = constructResDictionary(0, bus_indexRange, queen_and_spadina_list)\n",
    "\n",
    "#These construct the restaurant name : business id dictionary for initial user setting\n",
    "RestaurantBusId = {}\n",
    "\n",
    "# yonge_and_finch_list\n",
    "# bloor_and_bathurst_list\n",
    "# queen_and_spadina_list\n",
    "restYF = list(dict1_yongeFinch.keys())\n",
    "restBB = list(dict2_bloorBathurst.keys())\n",
    "restQS = list(dict3_queenSpadina.keys())\n",
    "\n",
    "#loop through all items\n",
    "for count in range(len(yonge_and_finch_list)):\n",
    "    RestaurantBusId[restYF[count]] = yonge_and_finch_list[count]\n",
    "    RestaurantBusId[restBB[count]] = bloor_and_bathurst_list[count]\n",
    "    RestaurantBusId[restQS[count]] = queen_and_spadina_list[count]\n",
    "\n",
    "#RestaurantBusId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation \n",
    "#Get the business information for the recommended business \n",
    "# businessSeries = df[df[\"business_num_id\"] == 1904].iloc[0]\n",
    "# #Get the business name \n",
    "# businessSeries['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial user setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected restaurants: ['Roll', 'Basil Box', \"Puck'N Wings\", 'Regal Garden', 'El Pocho Antojitos Bar', 'Krispy Kreme', 'UNIUN', 'Maison Close 1888', 'Stelvio']\n",
      "Your scores given to the restaurants ['5', '4', '4', '5', '5', '4', '5', '4', '4']\n",
      "Your final choice is : {'Roll': 5, 'Basil Box': 4, \"Puck'N Wings\": 4, 'Regal Garden': 5, 'El Pocho Antojitos Bar': 5, 'Krispy Kreme': 4, 'UNIUN': 5, 'Maison Close 1888': 4, 'Stelvio': 4}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Initiate a frame or master? \n",
    "    tk = Tk()\n",
    "    Label(tk, text='List of restaurants from 3 locations - choose 3 each').pack()\n",
    "    #Label(tk, text='List of restaurants from 3 locations - choose 3 each').grid()\n",
    "    \n",
    "    #Creating the multi-listbox object, pass in a tuple of tuple (lists), this will be the list objects\n",
    "    initialSetuUp = MultiListbox_Initialize(tk, (('Yonge & Finch Intersection', 20), ('Bloor & Bathurst Intersection', 20), \\\n",
    "                            ('Queen & Spadina Intersection', 20)),list(dict1_yongeFinch.keys()),list(dict2_bloorBathurst.keys()),\\\n",
    "                                 list(dict3_queenSpadina.keys()))\n",
    "\n",
    "    #loop through the length of recommend list, # = 5 \n",
    "    for index in range(len(dict1_yongeFinch)):\n",
    "        #First restaurant information to display \n",
    "        #Following the restaurants' name \n",
    "        restList1 = list(dict1_yongeFinch.keys())[index]\n",
    "        restList2 = list(dict2_bloorBathurst.keys())[index]\n",
    "        restList3 = list(dict3_queenSpadina.keys())[index]\n",
    "        \n",
    "        initialSetuUp.insert(END, (' ', ' ', ' '))\n",
    "        \n",
    "        #Inserting the restaurant names\n",
    "        initialSetuUp.insert(END, ('%d: %s' % (index + 1, restList1),'%d: %s' % (index + 1, restList2),\n",
    "                         '%d: %s' % (index + 1, restList3)))\n",
    "        \n",
    "        #Looping through each attribute keys - resinfo\n",
    "        for resinfo in dict1_yongeFinch.get(restList1).keys():\n",
    "            restList1Info = resinfo + ':' + str(dict1_yongeFinch.get(restList1).get(resinfo,''))\n",
    "            restList2Info = resinfo + ':' + str(dict2_bloorBathurst.get(restList2).get(resinfo,''))\n",
    "            restList3Info = resinfo + ':' + str(dict3_queenSpadina.get(restList3).get(resinfo,''))\n",
    "            \n",
    "            initialSetuUp.insert(END, (restList1Info, restList2Info, restList3Info))\n",
    "        \n",
    "        initialSetuUp.insert(END, ('----------------', '----------------', '----------------'))\n",
    "    \n",
    "    initialSetuUp.pack(expand=YES,fill=BOTH)\n",
    "    #initialSetuUp.grid(expand=YES,fill=BOTH)\n",
    "\n",
    "    tk.mainloop()\n",
    "    \n",
    "    #Get user response\n",
    "    UserInitialResponse = initialSetuUp.responseDict\n",
    "    \n",
    "    #store the user response into local file\n",
    "    #csv_fileName = \"UserTestResult{:d}.json\".format(userTestNumber)\n",
    "    #with open('userStudyResults//'+csv_fileName, 'w') as fp:\n",
    "        #json.dump(response, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0] [2235 3602 3858 2327 2684 1862 2312 2201 2706] [5 4 4 5 5 4 5 4 4]\n"
     ]
    }
   ],
   "source": [
    "#Process user inputs\n",
    "assert len(UserInitialResponse) ==9,\"User response has duplicates!\"\n",
    "\n",
    "import statistics \n",
    "#Get row lis\n",
    "rowList = [0] * len(UserInitialResponse)\n",
    "#Get col list\n",
    "colList = []\n",
    "#Get data list\n",
    "dataList = []\n",
    "\n",
    "for resName, rating in UserInitialResponse.items():\n",
    "    #Append the bus_num_id as column values\n",
    "    #RestaurantBusId mapps restuarnt names to business ids\n",
    "    colList.append(RestaurantBusId[resName])\n",
    "    dataList.append(rating)\n",
    "\n",
    "userAvg = statistics.mean(dataList) \n",
    "dataWuserAvgList = np.array(dataList) - np.array([userAvg] * len(UserInitialResponse))+ 0.001\n",
    "rows = np.array(rowList)\n",
    "cols = np.array(colList)\n",
    "data = np.array(dataList)\n",
    "dataWuser = np.array(dataWuserAvgList) \n",
    "print(rows, cols,data)\n",
    "\n",
    "#Get explicit data\n",
    "userSetUpMatrix = csr_matrix((data, (rows, cols)), shape=(1, rtrain.shape[1]))\n",
    "#Get with user rating\n",
    "userSetUpMatrix_WuserAvg = csr_matrix((dataWuser, (rows, cols)), shape=(1, rtrain.shape[1]))\n",
    "\n",
    "#Generate Implicit user rating vector\n",
    "implicitUserSetUpMtx = csr_matrix((data, (rows, cols)), shape=(1, rtrain.shape[1]))\n",
    "implicitUserSetUpMtx[(userSetUpMatrix > 3).nonzero()] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking new user data with original data, ONLY RUN ONCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6101x3998 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 180041 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This would overwrite rtrain,rtrain_implicit, and rtrain_WuserAvg\n",
    "csr_vappend(rtrain,userSetUpMatrix)\n",
    "csr_vappend(rtrain_implicit, implicitUserSetUpMtx)\n",
    "csr_vappend(rtrain_userAvg, userSetUpMatrix_WuserAvg)\n",
    "\n",
    "#User_index = #This should be the user index rtrain.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity score for new user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update rtrain similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6100 * 6100\n",
    "#should import \n",
    "initial_rtrain_similarity = np.load('..\\\\data\\\\userStudy\\\\UU_explicit.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the similarity vector for the new user 1*6101\n",
    "newSimilarityVector_explicit = cosine_similarity(X=userSetUpMatrix, Y=rtrain, dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new user similarity row\n",
    "# 1 * 6100\n",
    "newSimilarity_row = newSimilarityVector_explicit[0][:-1]\n",
    "newSimilarity_row = np.expand_dims(newSimilarity_row, axis=0)\n",
    "\n",
    "#new user similarity column\n",
    "# 6101 * 1\n",
    "newSimilarity_col = newSimilarityVector_explicit.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack the bottom row\n",
    "new_rtrain_similarity = np.vstack((initial_rtrain_similarity, newSimilarity_row))\n",
    "\n",
    "#stack the last column\n",
    "#new trains similarity: 6101 * 6100, new similarity_col: 6101 * 1\n",
    "new_rtrain_similarity = np.hstack((new_rtrain_similarity, newSimilarity_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "#(new_rtrain_similarity[-1,:] == newSimilarity_row).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update rtrain_implicit similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial rtrain implicit similarity: 6100 * 6100\n",
    "#should import \n",
    "initial_rtrainImplicit_similarity = np.load('..\\\\data\\\\userStudy\\\\UU_implicit.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the similarity vector for the new user 1*6101\n",
    "newSimilarityVector_implicit = cosine_similarity(X=implicitUserSetUpMtx, Y=rtrain_implicit, dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new user similarity row\n",
    "# 1 * 6100\n",
    "newSimilarity_implicit_row = newSimilarityVector_implicit[0][:-1]\n",
    "newSimilarity_implicit_row = np.expand_dims(newSimilarity_implicit_row, axis=0)\n",
    "\n",
    "#new user similarity column\n",
    "# 6101 * 1\n",
    "newSimilarity_implicit_col = newSimilarityVector_implicit.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack the bottom row\n",
    "new_rtrainImplicit_similarity = np.vstack((initial_rtrainImplicit_similarity, newSimilarity_implicit_row))\n",
    "\n",
    "#stack the last column\n",
    "#new trains similarity: 6101 * 6100, new similarity_col: 6101 * 1\n",
    "new_rtrainImplicit_similarity = np.hstack((new_rtrainImplicit_similarity, newSimilarity_implicit_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2, 7],\n",
       "       [0, 0, 3, 7],\n",
       "       [4, 5, 6, 7]], dtype=int32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row = np.array([0, 0, 1, 2, 2, 2])\n",
    "# col = np.array([0, 2, 2, 0, 1, 2])\n",
    "# data = np.array([1, 2, 3, 4, 5, 6])\n",
    "# sp = csr_matrix((data, (row, col)), shape=(3, 3))\n",
    "# sparse.hstack((sp,np.array([7,7,7])[:,None])).A\n",
    "\n",
    "#X  = np.array([1,2,3],[3,3,3],[2,2,2])\n",
    "#X  = np.array([1,2,3])\n",
    "#X = np.expand_dims(X, axis=0)\n",
    "#Y = np.array([1,1,4])\n",
    "#Y = np.expand_dims(Y, axis=0)\n",
    "#Y = np.array([[1, 2, 3], [4, 5, 6], [1,5,7]], np.int32)\n",
    "#similarity = cosine_similarity(X=X, Y=Y, dense_output=True)\n",
    "\n",
    "\n",
    "#dimension of X: 1*3, dimension of Y 3*3, \n",
    "# similarity = cosine_similarity(X=X, Y=Y.transpose(), dense_output=True)\n",
    "# Ynew = np.expand_dims(Y[:,1],axis=0)\n",
    "# cosine_similarity(X=X, Y=Ynew, dense_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-rating KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. With ratings that subtracts user average rating, cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:31<00:00, 195.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:02<00:00, 2893.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3655, 2235, 1819, 2396, 3489, 3115, 3414, 2726,  691,  753,  883,\n",
       "       2600, 1774, 3166, 3329,  324,  353, 1246,  631, 3909, 1923, 3974,\n",
       "        770, 2460, 1912, 2900, 3042, 3222, 1771, 1914,  918,  966,  593,\n",
       "       3249,  192, 2715, 3982,  292, 2525, 3430, 3882, 3237,  989,  572,\n",
       "        355, 1293, 2175, 2526, 3607, 2647], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UU similarity, using cosine similarity\n",
    "#similarity_1 = train(rtrain)\n",
    "#get a user-item matrix  UI prediction\n",
    "#Predict using UI matrix with ratings in it \n",
    "#UI_predictionScore_Explicit = predict(rtrain_userAvg, 100, similarity_1, item_similarity_en= False)\n",
    "#UI_predict_Explicit = prediction(UI_predictionScore_Explicit, 50, rtrain_userAvg)\n",
    "#user_item_res1 = evaluate(user_item_predict1, rvalid_userAvg)\n",
    "#UI_predict_Explicit[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implicit User-rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UU similarity, using cosine similarity\n",
    "#similarity_2 = train(rtrain_implicit)\n",
    "UI_predictionScore_Implicit = predict(rtrain_implicit, 100, new_rtrainImplicit_similarity, item_similarity_en= False)\n",
    "UI_predict_Implicit = prediction(UI_predictionScore_Implicit, 50, rtrain_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3489,  101, 3059, 2133, 1185,  301, 2579, 1112, 1956,  211, 2156,\n",
       "        248, 1618,  818, 2456, 2974, 3655,  576,  340, 3553, 2053,  687,\n",
       "       1819, 2153, 2760,  709,  792,  816,  829, 2934, 2396,  629, 1488,\n",
       "        753, 3414, 1013,  260,  953,  356, 1847,  741, 2571, 1950, 1299,\n",
       "        606, 1865, 3629, 1710, 3357, 1548], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UI_predict_Implicit[6100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implicit similarity, Explicit user-rating combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████                                                                  | 943/6101 [00:02<00:14, 354.41it/s]"
     ]
    }
   ],
   "source": [
    "#similarity_3 = train(rtrain_implicit)\n",
    "#get a user-item matrix  UI prediction\n",
    "#Predict using UI matrix with ratings in it \n",
    "UI_predictionScore_IECombined = predict(rtrain, 100, new_rtrainImplicit_similarity, item_similarity_en= False)\n",
    "UI_predict_IECombined = prediction(UI_predictionScore_IECombined, 50, rtrain)\n",
    "# user_item_res1 = evaluate(UI_predict_IECombined, rvalid)\n",
    "# user_item_res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. NO NEED Something random, to be filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:30<00:00, 179.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:02<00:00, 2929.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# similarity_4 = train(rtrain)\n",
    "# UI_predictionScore_random1 = predict(rtrain_implicit, 100, similarity_4, item_similarity_en= False)\n",
    "# UI_predict_random1 = prediction(UI_predictionScore_random1, 50, rtrain_implicit)\n",
    "# # user_item_res1 = evaluate(UI_predict_IECombined, rvalid)\n",
    "# # user_item_res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. something random, to be filled 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#userVisitMatrix = getImplicitMatrix(rtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity1 = train(rtrain)\n",
    "# similarity2 = train(rtrain_implicit)\n",
    "# similarity3 =train(userVisitMatrix)\n",
    "# similarity4 = train(rtrain_userAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:36<00:00, 167.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:02<00:00, 2815.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# UI_predictionScore_max = predictUU(rtrain, 100, 'max', similarity1, similarity2, similarity3, similarity4)\n",
    "# UI_predict_max = prediction(UI_predictionScore_max, 50, rtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. IU, Explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3998/3998 [00:32<00:00, 124.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6101/6101 [00:02<00:00, 2189.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#UU similarity, using cosine similarity\n",
    "#similarity_6 = train(rtrain.T)\n",
    "#similarity_2 = train(rtrain_implicit)\n",
    "#get a user-item matrix  UI prediction\n",
    "#Predict using UI matrix with ratings in it \n",
    "#IU_predictionScore_Explicit = predict(rtrain, 100, similarity_6, item_similarity_en= True)\n",
    "#IU_predict_Explicit = prediction(IU_predictionScore_Explicit, 50, rtrain)\n",
    "#user_item_res1 = evaluate(user_item_predict1, rvalid_userAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3655, 2396,  753, 3489,  691, 2235,  292,  883, 3947, 2018, 1450,\n",
       "       1592, 3222, 1340, 2600,  905,  355, 1520, 1162, 2728, 2663, 3388,\n",
       "       3237, 1147, 1874, 1547,  953, 3775,  728, 3629, 2080,  835, 1725,\n",
       "       2715, 3042, 2526, 3983, 2522, 2856, 1798,   36, 3175, 3245, 3564,\n",
       "       2726, 2887, 1246,  101, 1543, 3546], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IU_predict_Explicit[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Item_based TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "II_similarity_IK = np.load('..\\\\data\\\\userStudy\\\\II_usingIK.npy')\n",
    "item_based_prediction_score4 = predict(rtrain, 10, II_similarity_IK, item_similarity_en= True)\n",
    "#for each restuarant top50 users \n",
    "Item_predict_tfidf = prediction(item_based_prediction_score4, 50, rtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 863, 3631, 2728,  758,  135,   92, 3994, 3501, 1546, 2128,  223,\n",
       "       2938, 2666, 1747,  153, 1081,  769, 3663,  828,  227, 2600,   12,\n",
       "       2755, 3719, 3208, 3411, 3661, 1948, 1922, 2834,  699, 1869, 3164,\n",
       "        685, 2971,  145, 2153, 3951,  721,  207, 1000, 2877, 2630, 1340,\n",
       "       1564,  132,  676, 3426, 1960, 1880], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Item_predict_tfidf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Section: Produce the list of restaurants close to the set location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Remember to manually change this userIndex!!!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# three locations for user recommendation\n",
    "intersection = [bloor_and_yonge,dundas_and_yonge,spadina_and_dundas]\n",
    "# get 3 items for each location\n",
    "businessIndexRange = 3\n",
    "# 5 metrics and store them in a list\n",
    "metric = [UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf]\n",
    "\n",
    "# manually enter this number!!!!!!\n",
    "userIndex = rtrain.shape[0]\n",
    "\n",
    "#Need this number to perform the user test, so don't repeat, don't mess up\n",
    "userTestNumber = random.randint(1,1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6101 223\n"
     ]
    }
   ],
   "source": [
    "print(userIndex, userTestNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3489,  101, 3059, 2133, 1185,  301, 2579, 1112, 1956,  211, 2156,\n",
       "        248, 1618,  818, 2456, 2974, 3655,  576,  340, 3553, 2053,  687,\n",
       "       1819, 2153, 2760,  709,  792,  816,  829, 2934, 2396,  629, 1488,\n",
       "        753, 3414, 1013,  260,  953,  356, 1847,  741, 2571, 1950, 1299,\n",
       "        606, 1865, 3629, 1710, 3357, 1548], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UI_predict_Implicit[6100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the recommendations for each metric using loops, store in the res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "isList\n",
      "3998\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "isList\n",
      "3998\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "isList\n",
      "3998\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# get 3 top recommendations for each locations\n",
    "# store three locations in one list for each metric\n",
    "\n",
    "#loop through the 5 recommendation algorithms, initialize the res list \n",
    "res = [[] for i in range(len(metric))]\n",
    "#Loop through the intersections \n",
    "for i in range(len(intersection)):\n",
    "    #loop through each metric \n",
    "    for j in range(len(metric)):\n",
    "       \n",
    "        temp = geographical_dist(metric[j],intersection[i],userIndex-1,businessIndexRange-1)\n",
    "        res[j] += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2459, 3232, 2366, 1070, 2774,  554, 1132,  579,  519, 2014,  227,\n",
       "       1575,  558, 2839, 3125, 1104, 3790, 2569, 1799, 1164, 2138, 1816,\n",
       "        340, 1112,  668, 1226, 1532, 1062, 3763,  451, 3706, 3593, 1742,\n",
       "       3707,  241, 1437, 3045, 1311, 2950, 3614, 3300, 2261, 1023, 2020,\n",
       "        990, 1518, 1088, 1086,  656, 2674], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric[j][6100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[629, 2156, 3553, 211, 1618],\n",
       " [1253, 1248, 1795, 1798, 2934, 1488],\n",
       " [629, 1552, 2156, 3553, 1618, 211],\n",
       " [1795, 1658, 1724, 1618],\n",
       " [2459, 1742]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 recommendations for each metric\n",
    "# the sequence is -> [UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf]\n",
    "# get three recommendations for each location, so the len for each row is 3*3\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look back the the origal prediction matrix and rearrange the recommendations list, choose the top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = []\n",
    "#loop through the elements in the res list (5 recommend lists)\n",
    "for element in range(len(res)):\n",
    "    dic = {}\n",
    "    #loop through each element in the recomemndation list (order:element)\n",
    "    for i in range(len(res[element])):\n",
    "        #if the recommendation is a list \n",
    "        if isinstance(metric[element], list):\n",
    "            dic[metric[element].index(res[element][i])] = res[element][i]\n",
    "        #if the recommendation is a matrix \n",
    "        else:\n",
    "            dic[metric[element][userIndex-1].tolist().index(res[element][i])] = res[element][i]\n",
    "    temp = []\n",
    "    for j in sorted(dic.keys()):\n",
    "        temp.append(int(dic[j]))\n",
    "    res_final.append(temp[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[211, 2156, 1618],\n",
       " [1795, 2934, 1488],\n",
       " [2156, 1618, 211],\n",
       " [1795, 1724, 1618],\n",
       " [2459, 1742]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final recommendations for each metric\n",
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder!!!! manually adjust userIndex after inserting a new row of user preference!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce the list of restaurants close to the set location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #First list\n",
    "# UI_predict_Explicit = geographical_dist(UI_predict_Explicit,intersection,userIndex,businessIndexRange)\n",
    "\n",
    "# #Second list\n",
    "# UI_predict_Implicit = geographical_dist(UI_predict_Implicit,intersection,userIndex,businessIndexRange)\n",
    "\n",
    "# #Third list\n",
    "# UI_predict_IECombined = geographical_dist(UI_predict_IECombined,intersection,userIndex,businessIndexRange)\n",
    "\n",
    "# #Fourth lsit\n",
    "# UI_predict_popular = geographical_dist(popular_list,intersection,userIndex,businessIndexRange)\n",
    "\n",
    "# #Five list\n",
    "# UI_predict_max = geographical_dist(UI_predict_max,intersection,userIndex,businessIndexRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI_predict_Explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI_predict_Implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI_predict_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI_predict_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df[\"business_num_id\"] == UI_prediction[userIndex][busIndex]].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match restaurant information according to business_num_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current sequence: UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'userIndex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-ddfdbace9031>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#Add a for loop for the top recommended items\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdict1_ExplicitRecommend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstructResDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbusinessIndexRange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdict2_ImplicitRecommend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstructResDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbusinessIndexRange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdict3_EICombineRecommend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstructResDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbusinessIndexRange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'userIndex' is not defined"
     ]
    }
   ],
   "source": [
    "#Trying to recommend for user 0 for now \n",
    "dict1_ExplicitRecommend = {}\n",
    "dict2_ImplicitRecommend = {}\n",
    "dict3_EICombineRecommend = {}\n",
    "dict4_PopularityRecommend = {}\n",
    "dict5_maxRecommend = {}\n",
    "#User predict [user index] [item index]\n",
    "#Add a for loop for the top recommended items\n",
    "\n",
    "dict1_ExplicitRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[0])\n",
    "dict2_ImplicitRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[1])\n",
    "dict3_EICombineRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[2])\n",
    "dict4_PopularityRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[3])\n",
    "dict5_maxRecommend = constructResDictionary(userIndex, businessIndexRange, res_final[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence for now: UI_predict_Implicit, popular_list, UI_predict_IECombined, IU_predict_Explicit, Item_predict_tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tkinter.IntVar object at 0x00000222CF96B710>, <tkinter.IntVar object at 0x0000022301FDCA58>, <tkinter.IntVar object at 0x0000022302348080>, <tkinter.IntVar object at 0x00000222D0DACDD8>, <tkinter.IntVar object at 0x0000022300A3C128>]\n",
      "list: 1\n",
      "Like: \"lreason for like 1 \"\n",
      "Dislike: \"\"\n",
      "list: 2\n",
      "Like: \"reason like 2 \"\n",
      "Dislike: \"\"\n",
      "list: 3\n",
      "Like: \"okok\"\n",
      "Dislike: \"nto really good \"\n",
      "list: 4\n",
      "Like: \"good \"\n",
      "Dislike: \"\"\n",
      "list: 5\n",
      "Like: \"\"\n",
      "Dislike: \"\"\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Initiate a frame or master? \n",
    "    tk = Tk()\n",
    "    Label(tk, text='List of recommended restaurants').pack()\n",
    "    \n",
    "    #Creating the multi-listbox object, pass in a tuple of tuple (lists), this will be the list objects\n",
    "    mlb = MultiListbox_entries(tk, (('Implicit User-Rating', 20), ('Popularity List', 20), \\\n",
    "                            ('Explicit Implicit Combined', 20), ('Explicit Item-Rating', 20), ('TF-IDF Score of Item', 20)))\n",
    "\n",
    "    #loop through the length of recommend list, # = 5 \n",
    "    for index in range(len(dict1_ExplicitRecommend)):\n",
    "        #First restaurant information to display \n",
    "        #Following the restaurants' name \n",
    "        restList1 = list(dict1_ExplicitRecommend.keys())[index]\n",
    "        restList2 = list(dict2_ImplicitRecommend.keys())[index]\n",
    "        restList3 = list(dict3_EICombineRecommend.keys())[index]\n",
    "        restList4 = list(dict4_PopularityRecommend.keys())[index]\n",
    "        restList5 = list(dict5_maxRecommend.keys())[index]\n",
    "        \n",
    "        mlb.insert(END, (' ', ' ', ' ', ' ', ' '))\n",
    "        \n",
    "        #Inserting the restaurant names\n",
    "        mlb.insert(END, ('%d: %s' % (index + 1, restList1),'%d: %s' % (index + 1, restList2),\n",
    "                         '%d: %s' % (index + 1, restList3),'%d: %s' % (index + 1, restList4),\n",
    "                         '%d: %s' % (index + 1, restList5)))\n",
    "        \n",
    "        #Looping through each attribute keys - resinfo\n",
    "        for resinfo in dict1_ExplicitRecommend.get(restList1).keys():\n",
    "            restList1Info = resinfo + ':' + str(dict1_ExplicitRecommend.get(restList1).get(resinfo,''))\n",
    "            restList2Info = resinfo + ':' + str(dict2_ImplicitRecommend.get(restList2).get(resinfo,''))\n",
    "            restList3Info = resinfo + ':' + str(dict3_EICombineRecommend.get(restList3).get(resinfo,''))\n",
    "            restList4Info = resinfo + ':' + str(dict4_PopularityRecommend.get(restList4).get(resinfo,''))\n",
    "            restList5Info = resinfo + ':' + str(dict5_maxRecommend.get(restList5).get(resinfo,''))\n",
    "            \n",
    "            mlb.insert(END, (restList1Info, restList2Info, restList3Info, restList4Info, restList5Info))\n",
    "        \n",
    "        mlb.insert(END, ('----------------', '----------------', '----------------', '----------------', '----------------'))\n",
    "    \n",
    "    mlb.pack(expand=YES,fill=BOTH)\n",
    "\n",
    "    tk.mainloop()\n",
    "    \n",
    "    #Get user response\n",
    "    response = mlb.responseDict\n",
    "    \n",
    "    #store the user response into local file\n",
    "    csv_fileName = \"UserTestResult{:d}.json\".format(userTestNumber)\n",
    "    with open('userStudyResults//'+csv_fileName, 'w') as fp:\n",
    "        json.dump(response, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I get the user response information here, so please make sure the sequence for list names are correct when initializing our mlb object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_fileName = \"UserTestResult{:d}.json\".format(userTestNumber)\n",
    "# with open(csv_fileName, 'w') as fp:\n",
    "#     json.dump(response, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load the result file with json \n",
    "# with open(csv_fileName, 'r') as fp:\n",
    "#     test = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2074, 2584, 2628, 2656, 2661, 2666, 2681, 2809, 2939])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the 0th user review data \n",
    "rows, cols = rtrain[rtrain.shape[0]-1].nonzero()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_num_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39824</th>\n",
       "      <td>2939</td>\n",
       "      <td>Hot Star Large Fried Chicken</td>\n",
       "      <td>[{'alias': 'chickenshop', 'title': 'Chicken Shop'}]</td>\n",
       "      <td>3.5</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50209</th>\n",
       "      <td>2584</td>\n",
       "      <td>Sansotei Ramen</td>\n",
       "      <td>[{'alias': 'ramen', 'title': 'Ramen'}, {'alias': 'noodles', 'title': 'Noodles'}]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78288</th>\n",
       "      <td>2809</td>\n",
       "      <td>Kimchi House</td>\n",
       "      <td>[{'alias': 'korean', 'title': 'Korean'}]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110843</th>\n",
       "      <td>2628</td>\n",
       "      <td>La Palette</td>\n",
       "      <td>[{'alias': 'french', 'title': 'French'}, {'alias': 'desserts', 'title': 'Desserts'}, {'alias': 'bars', 'title': 'Bars'}]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125039</th>\n",
       "      <td>2074</td>\n",
       "      <td>Kevin's Taiyaki</td>\n",
       "      <td>[{'alias': 'gourmet', 'title': 'Specialty Food'}, {'alias': 'asianfusion', 'title': 'Asian Fusion'}, {'alias': 'japanese', 'title': 'Japanese'}]</td>\n",
       "      <td>4.5</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133837</th>\n",
       "      <td>2661</td>\n",
       "      <td>Sang-Ji Fried Bao</td>\n",
       "      <td>[{'alias': 'noodles', 'title': 'Noodles'}, {'alias': 'dimsum', 'title': 'Dim Sum'}, {'alias': 'soup', 'title': 'Soup'}]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173529</th>\n",
       "      <td>2666</td>\n",
       "      <td>Juicy Dumpling</td>\n",
       "      <td>[{'alias': 'chinese', 'title': 'Chinese'}]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173987</th>\n",
       "      <td>2681</td>\n",
       "      <td>El Pocho Antojitos Bar</td>\n",
       "      <td>[{'alias': 'bars', 'title': 'Bars'}, {'alias': 'breakfast_brunch', 'title': 'Breakfast &amp; Brunch'}, {'alias': 'mexican', 'title': 'Mexican'}]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181290</th>\n",
       "      <td>2656</td>\n",
       "      <td>Hong Kong Bistro Cafe</td>\n",
       "      <td>[{'alias': 'chinese', 'title': 'Chinese'}, {'alias': 'cafes', 'title': 'Cafes'}]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        business_num_id                          name  \\\n",
       "39824   2939             Hot Star Large Fried Chicken   \n",
       "50209   2584             Sansotei Ramen                 \n",
       "78288   2809             Kimchi House                   \n",
       "110843  2628             La Palette                     \n",
       "125039  2074             Kevin's Taiyaki                \n",
       "133837  2661             Sang-Ji Fried Bao              \n",
       "173529  2666             Juicy Dumpling                 \n",
       "173987  2681             El Pocho Antojitos Bar         \n",
       "181290  2656             Hong Kong Bistro Cafe          \n",
       "\n",
       "                                                                                                                                              categories  \\\n",
       "39824   [{'alias': 'chickenshop', 'title': 'Chicken Shop'}]                                                                                                \n",
       "50209   [{'alias': 'ramen', 'title': 'Ramen'}, {'alias': 'noodles', 'title': 'Noodles'}]                                                                   \n",
       "78288   [{'alias': 'korean', 'title': 'Korean'}]                                                                                                           \n",
       "110843  [{'alias': 'french', 'title': 'French'}, {'alias': 'desserts', 'title': 'Desserts'}, {'alias': 'bars', 'title': 'Bars'}]                           \n",
       "125039  [{'alias': 'gourmet', 'title': 'Specialty Food'}, {'alias': 'asianfusion', 'title': 'Asian Fusion'}, {'alias': 'japanese', 'title': 'Japanese'}]   \n",
       "133837  [{'alias': 'noodles', 'title': 'Noodles'}, {'alias': 'dimsum', 'title': 'Dim Sum'}, {'alias': 'soup', 'title': 'Soup'}]                            \n",
       "173529  [{'alias': 'chinese', 'title': 'Chinese'}]                                                                                                         \n",
       "173987  [{'alias': 'bars', 'title': 'Bars'}, {'alias': 'breakfast_brunch', 'title': 'Breakfast & Brunch'}, {'alias': 'mexican', 'title': 'Mexican'}]       \n",
       "181290  [{'alias': 'chinese', 'title': 'Chinese'}, {'alias': 'cafes', 'title': 'Cafes'}]                                                                   \n",
       "\n",
       "        business_stars  review_count  \n",
       "39824   3.5             52            \n",
       "50209   4.0             94            \n",
       "78288   4.0             36            \n",
       "110843  4.0             215           \n",
       "125039  4.5             56            \n",
       "133837  4.0             93            \n",
       "173529  4.0             73            \n",
       "173987  4.0             47            \n",
       "181290  4.0             87            "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the corresponding business information using the business num id \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df[df[\"business_num_id\"].isin(cols)].drop_duplicates(subset = 'business_num_id', keep = 'first')[[\"business_num_id\",\"name\",\"categories\",\"business_stars\",\"review_count_y\"]].rename(columns={'review_count_y': 'review_count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tkinter examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "#Multiple checkboxes example\n",
    "\n",
    "# from tkinter import *\n",
    "# class Checkbar(Frame):\n",
    "#    def __init__(self, parent=None, picks=[], side=LEFT, anchor=W):\n",
    "#       Frame.__init__(self, parent)\n",
    "#       self.vars = []\n",
    "    \n",
    "#       for pick in picks:\n",
    "#          var = IntVar()\n",
    "#          chk = Checkbutton(self, text=pick, variable=var)\n",
    "#          chk.pack(side=side, anchor=anchor, expand=YES)\n",
    "#          self.vars.append(var)\n",
    "            \n",
    "#    def state(self):\n",
    "#       return map((lambda var: var.get()), self.vars)\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#    root = Tk()\n",
    "#    lng = Checkbar(root, ['Python', 'Ruby', 'Perl', 'C++'])\n",
    "#    tgl = Checkbar(root, ['English','German'])\n",
    "#    lng.pack(side=TOP,  fill=X)\n",
    "#    tgl.pack(side=LEFT)\n",
    "#    lng.config(relief=GROOVE, bd=2)\n",
    "\n",
    "#    def allstates(): \n",
    "#       print(list(lng.state()), list(tgl.state()))\n",
    "#    Button(root, text='Quit', command=root.quit).pack(side=RIGHT)\n",
    "#    Button(root, text='Peek', command=allstates).pack(side=RIGHT)\n",
    "#    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #For checkbox demo \n",
    "# class checkBox(Frame):\n",
    "    \n",
    "#     def __init__(self, master):\n",
    "#             self.var = IntVar()\n",
    "            \n",
    "#             c = Checkbutton(master, text=\"Liked\", variable=self.var, command=self.cb)\n",
    "#             c.pack()\n",
    "\n",
    "#     def cb(self):\n",
    "#         print (\"variable is\", self.var.get())\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     #Initialize the root \n",
    "#     root = Tk()\n",
    "\n",
    "#     #Initialize the entries\n",
    "#     checkbox = checkBox(root)\n",
    "\n",
    "#     root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Demo for text boxes\n",
    "# fields = ['Like', 'Dislike']\n",
    "\n",
    "# def fetch(entries):\n",
    "#     for entry in entries:\n",
    "#         #index 0 is the field \n",
    "#         #index 1 is the entry data \n",
    "#         field = entry[0]\n",
    "#         text  = entry[1].get()\n",
    "#         print('%s: \"%s\"' % (field, text)) \n",
    "\n",
    "# def makeform(root, fields):\n",
    "#     entries = []\n",
    "#     #For each field, like \n",
    "#     for field in fields:\n",
    "#         row = Frame(root)\n",
    "#         lab = Label(row, width=15, text=field, anchor='w')\n",
    "#         ent = Entry(row)\n",
    "#         row.pack(side=TOP, fill=X, padx=5, pady=5)\n",
    "#         lab.pack(side=LEFT)\n",
    "#         ent.pack(side=RIGHT, expand=YES, fill=X)\n",
    "#         entries.append((field, ent))\n",
    "#     return entries\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     #Initialize the root \n",
    "#     root = Tk()\n",
    "    \n",
    "#     #Initialize the entries\n",
    "#     ents = makeform(root, fields)\n",
    "    \n",
    "#     #the buttons \n",
    "#     root.bind('<Button-1>', (lambda event, e=ents: fetch(e)))   \n",
    "#     b1 = Button(root, text='Show', command=(lambda e=ents: fetch(e)))\n",
    "#     b1.pack(side=LEFT, padx=5, pady=5)\n",
    "#     b2 = Button(root, text='Quit', command=root.quit)\n",
    "#     b2.pack(side=LEFT, padx=5, pady=5)\n",
    "#     root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Version\n",
    "# class MultiListbox(Frame):\n",
    "    \n",
    "#     def __init__(self, master, lists):\n",
    "#         Frame.__init__(self, master)\n",
    "#         self.lists = []\n",
    "        \n",
    "#         #Loop through the lists, l is the list label and widthW is the width \n",
    "#         for l,widthW in lists:\n",
    "            \n",
    "#             frame = Frame(self); frame.pack(side=LEFT, expand=YES, fill=BOTH)\n",
    "            \n",
    "#             Label(frame, text=l, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "            \n",
    "#             lb = Listbox(frame, width=widthW, borderwidth=0, selectborderwidth=0,\n",
    "#                  relief=FLAT, exportselection=FALSE)\n",
    "#             lb.pack(expand=YES, fill=BOTH)\n",
    "            \n",
    "#             self.lists.append(lb)\n",
    "            \n",
    "#             lb.bind('<B1-Motion>', lambda e, s=self: s._select(e.y))\n",
    "#             lb.bind('<Button-1>', lambda e, s=self: s._select(e.y))\n",
    "            \n",
    "#             lb.bind('<Leave>', lambda e: 'break')\n",
    "            \n",
    "#             lb.bind('<B2-Motion>', lambda e, s=self: s._b2motion(e.x, e.y))\n",
    "#             lb.bind('<Button-2>', lambda e, s=self: s._button2(e.x, e.y))\n",
    "            \n",
    "#         #pakcing the frame\n",
    "#         frame = Frame(self); frame.pack(side=LEFT, fill=Y)\n",
    "        \n",
    "#         #packing the label\n",
    "#         Label(frame, borderwidth=1, relief=RAISED).pack(fill=X)\n",
    "        \n",
    "#         #Setting a scrollbar \n",
    "# #         sb = Scrollbar(frame, orient=VERTICAL, command=self._scroll)\n",
    "        \n",
    "# #         sb.pack(expand=YES, fill=Y)\n",
    "        \n",
    "# #         self.lists[0]['yscrollcommand']=sb.set\n",
    "\n",
    "#     def _select(self, y):\n",
    "#         row = self.lists[0].nearest(y)\n",
    "#         self.selection_clear(0, END)\n",
    "#         self.selection_set(row)\n",
    "#         return 'break'\n",
    "\n",
    "#     def _button2(self, x, y):\n",
    "#         for l in self.lists: l.scan_mark(x, y)\n",
    "#         return 'break'\n",
    "\n",
    "#     def _b2motion(self, x, y):\n",
    "#         for l in self.lists: l.scan_dragto(x, y)\n",
    "#         return 'break'\n",
    "\n",
    "#     def _scroll(self, *args):\n",
    "#         for l in self.lists:\n",
    "#             apply(l.yview, args)\n",
    "\n",
    "#     def curselection(self):\n",
    "#         return self.lists[0].curselection()\n",
    "\n",
    "#     def delete(self, first, last=None):\n",
    "#         for l in self.lists:\n",
    "#             l.delete(first, last)\n",
    "\n",
    "# #     def get(self, first, last=None):\n",
    "# #         result = []\n",
    "# #         for l in self.lists:\n",
    "# #             result.append(l.get(first,last))\n",
    "# #         if last: return apply(map, [None] + result)\n",
    "# #         return result\n",
    "\n",
    "#     def index(self, index):\n",
    "#         self.lists[0].index(index)\n",
    "\n",
    "#     def insert(self, index, *elements):\n",
    "#         #Loop through the elements \n",
    "#         for element in elements:\n",
    "#             i = 0\n",
    "#             for l in self.lists:\n",
    "#                 l.insert(index, element[i])\n",
    "#                 i = i + 1\n",
    "\n",
    "#     def size(self):\n",
    "#         return self.lists[0].size()\n",
    "\n",
    "#     def see(self, index):\n",
    "#         for l in self.lists:\n",
    "#             l.see(index)\n",
    "\n",
    "#     def selection_anchor(self, index):\n",
    "#         for l in self.lists:\n",
    "#             l.selection_anchor(index)\n",
    "\n",
    "#     def selection_clear(self, first, last=None):\n",
    "#         for l in self.lists:\n",
    "#             l.selection_clear(first, last)\n",
    "\n",
    "#     def selection_includes(self, index):\n",
    "#         return self.lists[0].selection_includes(index)\n",
    "\n",
    "#     def selection_set(self, first, last=None):\n",
    "#         for l in self.lists:\n",
    "#             l.selection_set(first, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Dropdown mdemo\n",
    "# OPTIONS = [\n",
    "# \"Jan\",\n",
    "# \"Feb\",\n",
    "# \"Mar\"\n",
    "# ] #etc\n",
    "\n",
    "# master = Tk()\n",
    "\n",
    "# variable = StringVar(master)\n",
    "# variable.set(OPTIONS[0]) # default value\n",
    "\n",
    "# w = OptionMenu(master, variable, *OPTIONS)\n",
    "# w.pack()\n",
    "\n",
    "# def ok():\n",
    "#     print (\"value is:\" + variable.get())\n",
    "\n",
    "# #retrive the drop down value \n",
    "# button = Button(master, text=\"OK\", command=ok)\n",
    "# button.pack()\n",
    "\n",
    "# mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
